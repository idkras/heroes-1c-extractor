#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞ 1Cv8.1CD —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Docker
"""

import os
import sys
import subprocess
import csv
import json
import tempfile
import time
import logging
from pathlib import Path
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('1cd_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class OneCDAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–æ–≤ 1CD"""
    
    def __init__(self, ctool1cd_path=None, use_docker=True):
        self.ctool1cd_path = ctool1cd_path
        self.use_docker = use_docker
        self.results = {}
        
    def check_docker_available(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Docker"""
        try:
            result = subprocess.run(['docker', 'ps'], capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError):
            return False
    
    def extract_ctool1cd(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Ç–∏–ª–∏—Ç—ã ctool1cd –∏–∑ –∞—Ä—Ö–∏–≤–∞"""
        logger.info("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Ç–∏–ª–∏—Ç—ã ctool1cd...")
        
        template_path = Path("tools_ui_1c/src/–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã/src/CommonTemplates/–£–ò_ctool1cd/Template.bin")
        
        if not template_path.exists():
            logger.error("–ê—Ä—Ö–∏–≤ —Å —É—Ç–∏–ª–∏—Ç–æ–π ctool1cd –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
        import zipfile
        temp_dir = Path(tempfile.mkdtemp(prefix="ctool1cd_"))
        
        try:
            with zipfile.ZipFile(template_path, 'r') as zip_file:
                zip_file.extractall(temp_dir)
            
            logger.info(f"–£—Ç–∏–ª–∏—Ç–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∞ –≤: {temp_dir}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –∏—Å–ø–æ–ª–Ω—è–µ–º–æ–º—É —Ñ–∞–π–ª—É
            executable = temp_dir / "linux" / "ctool1cd"
            
            if executable.exists():
                logger.info(f"–ò—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω: {executable}")
                return executable
            else:
                logger.error(f"–ò—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {executable}")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏: {e}")
            return None
    
    def build_docker_image(self):
        """–°–±–æ—Ä–∫–∞ Docker –æ–±—Ä–∞–∑–∞ —Å ctool1cd"""
        logger.info("–°–±–æ—Ä–∫–∞ Docker –æ–±—Ä–∞–∑–∞...")
        
        try:
            result = subprocess.run([
                'docker', 'build', '-t', 'ctool1cd', '.'
            ], capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                logger.info("Docker –æ–±—Ä–∞–∑ —É—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω")
                return True
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ –æ–±—Ä–∞–∑–∞: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–±–æ—Ä–∫–µ Docker –æ–±—Ä–∞–∑–∞")
            return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ: {e}")
            return False
    
    def analyze_file_docker(self, file_path, output_csv=None):
        """–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ Docker"""
        logger.info(f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ Docker: {file_path}")
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        temp_csv = tempfile.NamedTemporaryFile(suffix='.csv', delete=False)
        temp_log = tempfile.NamedTemporaryFile(suffix='.txt', delete=False)
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É Docker
            cmd = [
                'docker', 'run', '--rm',
                '-v', f'{os.getcwd()}:/data',
                'ctool1cd',
                '-ne',  # –ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã
                '-sts', '/data/temp_output.csv',  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤ CSV
                '-q', f'/data/{Path(file_path).name}',  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É 1CD
                '-l', '/data/temp_log.txt'  # –õ–æ–≥ —Ñ–∞–π–ª
            ]
            
            logger.info(f"–ó–∞–ø—É—Å–∫ –∫–æ–º–∞–Ω–¥—ã: {' '.join(cmd)}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            start_time = time.time()
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)  # 1 —á–∞—Å —Ç–∞–π–º–∞—É—Ç
            end_time = time.time()
            
            logger.info(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            if result.returncode == 0:
                logger.info("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                
                # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                csv_path = Path("temp_output.csv")
                if csv_path.exists():
                    return self.parse_csv_results(csv_path, output_csv)
                else:
                    logger.error("CSV —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    return None
                    
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ (–∫–æ–¥: {result.returncode})")
                if result.stderr:
                    logger.error(f"–û—à–∏–±–∫–∞: {result.stderr}")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ª–æ–≥
                log_path = Path("temp_log.txt")
                if log_path.exists():
                    with open(log_path, 'r', encoding='utf-8') as logfile:
                        log_content = logfile.read()
                        if log_content:
                            logger.error(f"–õ–æ–≥ –æ—à–∏–±–∫–∏: {log_content}")
                
                return None
                
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            for temp_file in [temp_csv.name, temp_log.name]:
                try:
                    os.unlink(temp_file)
                except:
                    pass
    
    def analyze_file_native(self, file_path, output_csv=None):
        """–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –Ω–∞—Ç–∏–≤–Ω–æ–π —É—Ç–∏–ª–∏—Ç–æ–π"""
        logger.info(f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –Ω–∞—Ç–∏–≤–Ω–æ–π —É—Ç–∏–ª–∏—Ç–æ–π: {file_path}")
        
        if not self.ctool1cd_path:
            self.ctool1cd_path = self.extract_ctool1cd()
        
        if not self.ctool1cd_path:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —É—Ç–∏–ª–∏—Ç—É ctool1cd")
            return None
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        temp_csv = tempfile.NamedTemporaryFile(suffix='.csv', delete=False)
        temp_log = tempfile.NamedTemporaryFile(suffix='.txt', delete=False)
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É
            cmd = [
                str(self.ctool1cd_path),
                '-ne',  # –ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã
                '-sts', temp_csv.name,  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤ CSV
                '-q', str(file_path),    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É 1CD
                '-l', temp_log.name     # –õ–æ–≥ —Ñ–∞–π–ª
            ]
            
            logger.info(f"–ó–∞–ø—É—Å–∫ –∫–æ–º–∞–Ω–¥—ã: {' '.join(cmd)}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —É—Ç–∏–ª–∏—Ç—É
            start_time = time.time()
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)
            end_time = time.time()
            
            logger.info(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            if result.returncode == 0:
                logger.info("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                return self.parse_csv_results(Path(temp_csv.name), output_csv)
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ (–∫–æ–¥: {result.returncode})")
                if result.stderr:
                    logger.error(f"–û—à–∏–±–∫–∞: {result.stderr}")
                return None
                
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            for temp_file in [temp_csv.name, temp_log.name]:
                try:
                    os.unlink(temp_file)
                except:
                    pass
    
    def parse_csv_results(self, csv_path, output_csv=None):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ CSV"""
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑: {csv_path}")
        
        try:
            tables_info = []
            with open(csv_path, 'r', encoding='utf-8') as csvfile:
                reader = csv.DictReader(csvfile, delimiter='|')
                for row in reader:
                    tables_info.append(row)
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(tables_info)}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if output_csv:
                import shutil
                shutil.copy2(csv_path, output_csv)
                logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_csv}")
            
            return tables_info
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            return None
    
    def generate_report(self, results, output_file="1cd_analysis_report.json"):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞...")
        
        report = {
            "analysis_date": datetime.now().isoformat(),
            "file_analyzed": str(Path("1Cv8.1CD").absolute()),
            "total_tables": len(results),
            "tables": results,
            "summary": {
                "total_records": sum(int(table.get('records_count', 0)) for table in results),
                "total_data_size": sum(int(table.get('data_size', 0)) for table in results),
                "largest_table": max(results, key=lambda x: int(x.get('records_count', 0))) if results else None
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")
        return report
    
    def analyze_1cd_file(self, file_path, output_csv=None):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞ 1CD"""
        logger.info(f"–ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞: {file_path}")
        
        if not Path(file_path).exists():
            logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = Path(file_path).stat().st_size
        logger.info(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size / (1024**3):.2f} GB")
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞
        if self.use_docker and self.check_docker_available():
            logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º Docker –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            results = self.analyze_file_docker(file_path, output_csv)
        else:
            logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Ç–∏–≤–Ω—É—é —É—Ç–∏–ª–∏—Ç—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            results = self.analyze_file_native(file_path, output_csv)
        
        if results:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            report = self.generate_report(results)
            
            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            logger.info("=== –ö–†–ê–¢–ö–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===")
            logger.info(f"–í—Å–µ–≥–æ —Ç–∞–±–ª–∏—Ü: {len(results)}")
            logger.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {report['summary']['total_records']:,}")
            logger.info(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {report['summary']['total_data_size'] / (1024**2):.2f} MB")
            
            if report['summary']['largest_table']:
                largest = report['summary']['largest_table']
                logger.info(f"–°–∞–º–∞—è –±–æ–ª—å—à–∞—è —Ç–∞–±–ª–∏—Ü–∞: {largest.get('table_name', 'N/A')} "
                          f"({largest.get('records_count', 0):,} –∑–∞–ø–∏—Å–µ–π)")
            
            return results
        else:
            logger.error("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–∞–º–∏")
            return None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 analyze_1cd_structure.py <–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É_1cd> [–≤—ã—Ö–æ–¥–Ω–æ–π_csv]")
        sys.exit(1)
    
    file_path = sys.argv[1]
    output_csv = sys.argv[2] if len(sys.argv) > 2 else None
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = OneCDAnalyzer(use_docker=True)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª
    results = analyzer.analyze_1cd_file(file_path, output_csv)
    
    if results:
        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(results)}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: 1cd_analysis_report.json")
    else:
        print("\n‚ùå –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–∞–º–∏")
        sys.exit(1)

if __name__ == "__main__":
    main() 