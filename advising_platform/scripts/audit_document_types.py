#!/usr/bin/env python3
"""
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞—É–¥–∏—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
–ü–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã—è–≤–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ–∂–¥—É —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º —Ç–∏–ø–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏
–∏—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –≤ —Å–∏—Å—Ç–µ–º–µ in-memory –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è.
"""

import os
import sys
import re
import json
from collections import Counter
from typing import Dict, List, Tuple, Set, Optional, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä
from advising_platform.src.core.simple_indexer import indexer

def audit_standards_directory(standards_dir: str = "[standards .md]") -> Dict[str, List[str]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã.
    
    Returns:
        Dict —Å —Ç–∏–ø–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Å–ø–∏—Å–∫–∞–º–∏ –æ—Ç–Ω–æ—Å—è—â–∏—Ö—Å—è –∫ –Ω–∏–º —Ñ–∞–π–ª–æ–≤.
    """
    results = {
        "standards": [],              # –ê–∫—Ç–∏–≤–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
        "archived_standards": [],     # –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
        "drafts": [],                 # –ß–µ—Ä–Ω–æ–≤–∏–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
        "backups": [],                # –†–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
        "technical_files": [],        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã (.gitignore –∏ —Ç.–¥.)
        "unknown": []                 # –ù–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    }
    
    # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤
    backup_patterns = ['.bak', 'backup', 'copy', 'old']
    technical_patterns = ['.gitignore', 'README', '.DS_Store', 'Thumbs.db']
    
    for root, dirs, files in os.walk(standards_dir):
        for file in files:
            path = os.path.join(root, file)
            full_path = os.path.abspath(path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã –ø–æ –∏–º–µ–Ω–∏
            if any(pattern in file for pattern in technical_patterns):
                results["technical_files"].append(path)
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±—ç–∫–∞–ø—ã –ø–æ –∏–º–µ–Ω–∏
            if any(pattern in file for pattern in backup_patterns):
                results["backups"].append(path)
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä—Ö–∏–≤–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ –ø—É—Ç–∏
            if '/archive/' in path:
                results["archived_standards"].append(path)
                continue
                
            # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ —á–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ç–∞—Ç—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞
                    if 'status: Archived' in content:
                        results["archived_standards"].append(path)
                    elif 'status: Draft' in content:
                        results["drafts"].append(path)
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–µ–∫—Ü–∏–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
                    elif any(marker in content for marker in ['## üéØ –¶–µ–ª—å', '## –¶–µ–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞', '## üéØ –¶–µ–ª—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞']):
                        results["standards"].append(path)
                    else:
                        results["unknown"].append(path)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {path}: {e}")
                results["unknown"].append(path)
                
    return results

def check_indexer_classification(audit_results: Dict[str, List[str]]) -> Dict[str, Any]:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞—É–¥–∏—Ç–∞ —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –≤ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–µ.
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏.
    """
    results = {
        "total_files": sum(len(files) for files in audit_results.values()),
        "correctly_classified": 0,
        "misclassified": [],
        "errors": [],
        "type_stats": {}
    }
    
    # –û–∂–∏–¥–∞–µ–º—ã–µ —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∞—É–¥–∏—Ç–∞
    expected_types = {
        "standards": "standard",
        "archived_standards": "archived_standard",
        "drafts": "archived_standard",  # –ß–µ—Ä–Ω–æ–≤–∏–∫–∏ —Å—á–∏—Ç–∞–µ–º –∫–∞–∫ –∞—Ä—Ö–∏–≤–Ω—ã–µ
        "backups": "archived_document",
        "technical_files": "standard_related",
        "unknown": None  # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –Ω–µ –∑–∞–¥–∞–µ–º –æ–∂–∏–¥–∞–µ–º—ã–π —Ç–∏–ø
    }
    
    # –°—á–µ—Ç—á–∏–∫ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    type_counter = Counter()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
    for category, files in audit_results.items():
        expected_type = expected_types[category]
        
        for path in files:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞
            doc_type = None
            doc = indexer.get_document(path)
            
            if doc:
                doc_type = doc[0].doc_type
                type_counter[doc_type] += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–æ–≤
                if expected_type and doc_type != expected_type:
                    results["misclassified"].append({
                        "path": path,
                        "expected_type": expected_type,
                        "actual_type": doc_type,
                        "category": category
                    })
                elif expected_type:
                    results["correctly_classified"] += 1
            else:
                results["errors"].append({
                    "path": path,
                    "error": "–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∏–Ω–¥–µ–∫—Å–µ"
                })
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
    results["type_stats"] = dict(type_counter)
    
    return results

def generate_report(audit_results: Dict[str, List[str]], classification_results: Dict[str, Any]) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞—É–¥–∏—Ç–∞.
    
    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å –æ—Ç—á–µ—Ç–æ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
    """
    report = []
    report.append("# üìä –û—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    report.append("")
    report.append(f"–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {import_time.strftime('%d %B %Y, %H:%M')}")
    report.append("")
    
    report.append("## üìë –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–æ–≤")
    report.append("")
    report.append("| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ |")
    report.append("|-----------|-------------------|")
    
    for category, files in audit_results.items():
        report.append(f"| {category} | {len(files)} |")
    
    report.append("")
    report.append(f"**–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤**: {classification_results['total_files']}")
    report.append(f"**–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ**: {classification_results['correctly_classified']}")
    report.append(f"**–û—à–∏–±–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**: {len(classification_results['misclassified'])}")
    report.append(f"**–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∏–Ω–¥–µ–∫—Å–µ**: {len(classification_results['errors'])}")
    report.append("")
    
    report.append("## üîç –¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ")
    report.append("")
    report.append("| –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ |")
    report.append("|---------------|------------|")
    
    for doc_type, count in classification_results['type_stats'].items():
        report.append(f"| {doc_type} | {count} |")
    
    report.append("")
    
    if classification_results['misclassified']:
        report.append("## ‚ö†Ô∏è –û—à–∏–±–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        report.append("")
        report.append("| –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É | –û–∂–∏–¥–∞–µ–º—ã–π —Ç–∏–ø | –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ç–∏–ø | –ö–∞—Ç–µ–≥–æ—Ä–∏—è |")
        report.append("|--------------|---------------|-----------------|-----------|")
        
        for item in classification_results['misclassified']:
            report.append(f"| {item['path']} | {item['expected_type']} | {item['actual_type']} | {item['category']} |")
        
        report.append("")
    
    return "\n".join(report)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("–ó–∞–ø—É—Å–∫ –∞—É–¥–∏—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
    standards_dir = "[standards .md]"
    if not os.path.exists(standards_dir):
        print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {standards_dir}")
        return
    
    # –ê—É–¥–∏—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
    print(f"–ê–Ω–∞–ª–∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {standards_dir}...")
    audit_results = audit_standards_directory(standards_dir)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–µ
    print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–µ...")
    classification_results = check_indexer_classification(audit_results)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    print("–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...")
    report = generate_report(audit_results, classification_results)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report_path = "document_classification_report.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_path}")
    
    # –í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    total = classification_results['total_files']
    correct = classification_results['correctly_classified']
    incorrect = len(classification_results['misclassified'])
    errors = len(classification_results['errors'])
    
    print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞—É–¥–∏—Ç–∞:")
    print(f"- –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total}")
    print(f"- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {correct} ({correct/total*100:.1f}%)")
    print(f"- –û—à–∏–±–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {incorrect} ({incorrect/total*100:.1f}%)")
    print(f"- –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∏–Ω–¥–µ–∫—Å–µ: {errors} ({errors/total*100:.1f}%)")
    
    # –í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    if incorrect > 0:
        print("\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("1. –û–±–Ω–æ–≤–∏—Ç–µ –º–µ—Ç–æ–¥ _determine_doc_type –≤ src/core/simple_indexer.py")
        print("2. –î–æ–±–∞–≤—å—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print("3. –£—á–∏—Ç—ã–≤–∞–π—Ç–µ —Å—Ç–∞—Ç—É—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –µ–≥–æ —Ç–∏–ø–∞")
        print("4. –†–∞–∑–º–µ—Å—Ç–∏—Ç–µ –∞—Ä—Ö–∏–≤–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ /archive/")

if __name__ == "__main__":
    import time as import_time
    main()