#!/usr/bin/env python3
"""
–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–°–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–º–ø–ª–µ–∫—Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º, –≤–∫–ª—é—á–∞—è –ø—Ä–æ–≤–µ—Ä–∫—É –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è,
–º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  from scripts.lib.validation import validate_filename, validate_protected_sections
  
  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
  is_valid, reasons = validate_filename('example.md')
  
  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
  is_valid, errors, warnings = validate_protected_sections('example.md')
"""

__version__ = '1.0.0'
__author__ = 'AI Assistant'
__updated__ = '14 may 2025'
__status__ = 'active'

import os
import re
import json
from typing import Dict, List, Tuple, Optional, Union, Any, Pattern

# –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É TaskMaster
FILENAME_PATTERN = r'^(\d+)\.(\d+)\s+([a-z\s\-\_]+)\s+(\d{1,2}\s+[a-z]+\s+\d{4})\s+(\d{4})\s+([a-z]{2,4})\s+by\s+([a-z\s]+)\.md$'

# –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
PROTECTED_BEGIN = r'<!--\s*üîí\s*PROTECTED\s*SECTION:\s*BEGIN\s*-->'
PROTECTED_END = r'<!--\s*üîí\s*PROTECTED\s*SECTION:\s*END\s*-->'

# –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ
REQUIRED_METADATA = [
    'updated',
    'version',
    'status'
]

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ
OPTIONAL_METADATA = [
    'based on',
    'previous version',
    'integrated',
    'author'
]

def validate_filename(filename: str) -> Tuple[bool, List[str]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∏–º—è —Ñ–∞–π–ª–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É TaskMaster.
    
    Args:
        filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π:
        - –ë—É–ª–µ–≤–æ –∑–Ω–∞—á–µ–Ω–∏–µ, —É–∫–∞–∑—ã–≤–∞—é—â–µ–µ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É
        - –°–ø–∏—Å–æ–∫ –ø—Ä–∏—á–∏–Ω –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        
    Example:
        >>> is_valid, reasons = validate_filename("0.1 registry standard 14 may 2025 0350 cet by ai assistant.md")
        >>> is_valid
        True
    """
    reasons = []
    
    # –û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
    special_filenames = [
        "0.0 task master 10 may 2226 cet by ilya krasinsky.md"
    ]
    
    # –ï—Å–ª–∏ —Ñ–∞–π–ª –≤ —Å–ø–∏—Å–∫–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —à–∞–±–ª–æ–Ω–∞
    if filename in special_filenames:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞ —Å–∏–º–≤–æ–ª–æ–≤ (–∏—Å–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ —à–∞–±–ª–æ–Ω—É, –Ω–æ –Ω–µ –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É)
        if not filename.islower():
            reasons.append("–ò–º—è —Ñ–∞–π–ª–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã")
        return len(reasons) == 0, reasons
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —à–∞–±–ª–æ–Ω—É
    match = re.match(FILENAME_PATTERN, filename, re.IGNORECASE)
    if not match:
        reasons.append("–ò–º—è —Ñ–∞–π–ª–∞ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —à–∞–±–ª–æ–Ω—É [—Ä–∞–∑–¥–µ–ª].[–ø–æ–¥—Ä–∞–∑–¥–µ–ª] [—Ç–∏–ø] [–¥–∞—Ç–∞] [–≤—Ä–µ–º—è] [—á–∞—Å–æ–≤–æ–π –ø–æ—è—Å] by [–∞–≤—Ç–æ—Ä].md")
        return False, reasons
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞ —Å–∏–º–≤–æ–ª–æ–≤
    if not filename.islower():
        reasons.append("–ò–º—è —Ñ–∞–π–ª–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏
    date_part = match.group(4)
    time_part = match.group(5)
    timezone_part = match.group(6)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å DD month YYYY)
    date_match = re.match(r'^\d{1,2}\s+[a-z]+\s+\d{4}$', date_part, re.IGNORECASE)
    if not date_match:
        reasons.append(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: '{date_part}'. –û–∂–∏–¥–∞–µ—Ç—Å—è: 'DD month YYYY'")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å HHMM)
    time_match = re.match(r'^\d{4}$', time_part)
    if not time_match:
        reasons.append(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏: '{time_part}'. –û–∂–∏–¥–∞–µ—Ç—Å—è: 'HHMM'")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞
    if timezone_part.lower() not in ['cet', 'utc', 'et', 'pt']:
        reasons.append(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å: '{timezone_part}'. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ: 'cet', 'utc'")
    
    return len(reasons) == 0, reasons

def validate_protected_sections(file_path: str) -> Tuple[bool, List[str], List[str]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –≤ —Ñ–∞–π–ª–µ.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
    Returns:
        –ö–æ—Ä—Ç–µ–∂ –∏–∑ —Ç—Ä–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤:
        - –ë—É–ª–µ–≤–æ –∑–Ω–∞—á–µ–Ω–∏–µ, —É–∫–∞–∑—ã–≤–∞—é—â–µ–µ –Ω–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏
        - –°–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        - –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π (–µ—Å–ª–∏ –µ—Å—Ç—å)
            
    Raises:
        FileNotFoundError: –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            
    Example:
        >>> is_valid, errors, warnings = validate_protected_sections("example.md")
        >>> if not is_valid:
        ...     print(f"Found {len(errors)} errors")
    """
    errors = []
    warnings = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    if not os.path.exists(file_path):
        errors.append(f"–§–∞–π–ª {file_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return False, errors, warnings
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ markdown —Ñ–∞–π–ª–∞
    if not file_path.endswith('.md'):
        warnings.append(f"–§–∞–π–ª {file_path} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è markdown —Ñ–∞–π–ª–æ–º")
        return True, errors, warnings
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # –ü–æ–∏—Å–∫ –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
        begin_matches = list(re.finditer(PROTECTED_BEGIN, content, re.IGNORECASE))
        end_matches = list(re.finditer(PROTECTED_END, content, re.IGNORECASE))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
        if not begin_matches:
            errors.append(f"–í —Ñ–∞–π–ª–µ {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞—á–∞–ª–æ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞")
            return False, errors, warnings
            
        if not end_matches:
            errors.append(f"–í —Ñ–∞–π–ª–µ {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –æ–∫–æ–Ω—á–∞–Ω–∏–µ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞")
            return False, errors, warnings
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –º–∞—Ä–∫–µ—Ä–æ–≤ –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞
        if len(begin_matches) != len(end_matches):
            errors.append(f"–í —Ñ–∞–π–ª–µ {file_path} –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Ä–∫–µ—Ä–æ–≤ –Ω–∞—á–∞–ª–∞ ({len(begin_matches)}) –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –º–∞—Ä–∫–µ—Ä–æ–≤ –∫–æ–Ω—Ü–∞ ({len(end_matches)})")
            return False, errors, warnings
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –º–∞—Ä–∫–µ—Ä–æ–≤ (–Ω–∞—á–∞–ª–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–µ—Ä–µ–¥ –∫–æ–Ω—Ü–æ–º)
        for i in range(len(begin_matches)):
            begin_pos = begin_matches[i].start()
            end_pos = end_matches[i].start()
            
            if begin_pos >= end_pos:
                errors.append(f"–í —Ñ–∞–π–ª–µ {file_path} –º–∞—Ä–∫–µ—Ä –Ω–∞—á–∞–ª–∞ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ—Å–ª–µ –º–∞—Ä–∫–µ—Ä–∞ –∫–æ–Ω—Ü–∞")
                return False, errors, warnings
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–µ—Ä–≤–æ–≥–æ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
        if begin_matches:
            protected_content = content[begin_matches[0].end():end_matches[0].start()].strip()
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            for metadata in REQUIRED_METADATA:
                if not re.search(rf'{metadata}:', protected_content, re.IGNORECASE):
                    errors.append(f"–í —Ñ–∞–π–ª–µ {file_path} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ '{metadata}' –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞ –ø–æ–ª–µ–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
            metadata_lines = protected_content.split('\n')
            for line in metadata_lines:
                if ':' in line:
                    field = line.split(':', 1)[0].strip()
                    if not field.islower():
                        errors.append(f"–í —Ñ–∞–π–ª–µ {file_path} –ø–æ–ª–µ '{field}' –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏—Ü–µ–Ω–∑–∏–∏ (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ)
        license_begin = None
        
        if len(begin_matches) >= 2:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ª–∏—Ü–µ–Ω–∑–∏–∏
            last_protected_content = content[begin_matches[-1].end():end_matches[-1].start()].strip()
            if "–ª–∏—Ü–µ–Ω–∑–∏—è" in last_protected_content.lower() or "license" in last_protected_content.lower():
                license_begin = begin_matches[-1]
        
        if not license_begin:
            warnings.append(f"–í —Ñ–∞–π–ª–µ {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª —Å –ª–∏—Ü–µ–Ω–∑–∏–µ–π")
        
        return len(errors) == 0, errors, warnings
        
    except Exception as e:
        errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {str(e)}")
        return False, errors, warnings

def scan_directory(directory: str, validator_func: Any, recursive: bool = False) -> Dict[str, Any]:
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –Ω–∞ –Ω–∞–ª–∏—á–∏–µ markdown —Ñ–∞–π–ª–æ–≤ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö —Å –ø–æ–º–æ—â—å—é —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞.
    
    Args:
        directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        validator_func: –§—É–Ω–∫—Ü–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –ø—Ä–∏–Ω–∏–º–∞—é—â–∞—è –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        recursive: –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –≤–æ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
        
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    results = {"valid": [], "invalid": {}}
    
    for root, dirs, files in os.walk(directory):
        # –ï—Å–ª–∏ –Ω–µ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if not recursive and root != directory:
            continue
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ markdown —Ñ–∞–π–ª—ã
        for file in files:
            if file.endswith('.md'):
                file_path = os.path.join(root, file)
                
                if validator_func == validate_filename:
                    is_valid, reasons = validator_func(file)
                    if is_valid:
                        results["valid"].append(file_path)
                    else:
                        results["invalid"][file_path] = reasons
                elif validator_func == validate_protected_sections:
                    is_valid, errors, warnings = validator_func(file_path)
                    if is_valid:
                        results["valid"].append(file_path)
                    else:
                        results["invalid"][file_path] = {
                            "errors": errors,
                            "warnings": warnings
                        }
    
    return results

def validate_case_in_headers(file_path: str) -> Tuple[bool, List[str]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂ –∏–∑ –¥–≤—É—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤:
        - –ë—É–ª–µ–≤–æ –∑–Ω–∞—á–µ–Ω–∏–µ, —É–∫–∞–∑—ã–≤–∞—é—â–µ–µ, –≤—Å–µ –ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        - –°–ø–∏—Å–æ–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å –∑–∞–≥–ª–∞–≤–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏
    """
    errors = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    if not os.path.exists(file_path):
        errors.append(f"–§–∞–π–ª {file_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return False, errors
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ markdown —Ñ–∞–π–ª–∞
    if not file_path.endswith('.md'):
        return True, []  # –ù–µ markdown —Ñ–∞–π–ª, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ò—â–µ–º –≤—Å–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (—Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å #)
        header_pattern = r'^(#{1,6})\s+(.+)$'
        headers = re.findall(header_pattern, content, re.MULTILINE)
        
        for level, header_text in headers:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Å–µ–∫—Ü–∏—è—Ö
            in_protected = False
            protected_begin_pos = [m.start() for m in re.finditer(PROTECTED_BEGIN, content, re.IGNORECASE)]
            protected_end_pos = [m.start() for m in re.finditer(PROTECTED_END, content, re.IGNORECASE)]
            
            header_pos = content.find(level + ' ' + header_text)
            for i in range(len(protected_begin_pos)):
                if i < len(protected_end_pos) and protected_begin_pos[i] < header_pos < protected_end_pos[i]:
                    in_protected = True
                    break
            
            if in_protected:
                continue
            
            # –û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ —Ä–∞–∑—Ä–µ—à–∏—Ç—å:
            # 1. –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
            # 2. –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å —á–∏—Å–ª–∞–º–∏ –≤ –Ω–∞—á–∞–ª–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '1. –ó–∞–≥–æ–ª–æ–≤–æ–∫')
            # 3. –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å–æ —Å–∫–æ–±–∫–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ó–∞–≥–æ–ª–æ–≤–æ–∫ (–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π)')
            # 4. –ó–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä—É—Å—Å–∫–æ–º)
            
            # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å–ª–∞ –∏ —Ç–æ—á–∫–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å–æ–±—ã–º –æ–±—Ä–∞–∑–æ–º
            if re.match(r'^\d+\.\s', header_text):
                # –£–¥–∞–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∏ —Ç–æ—á–∫—É
                text_after_number = re.sub(r'^\d+\.\s', '', header_text)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫
                if text_after_number.strip():
                    header_to_check = text_after_number
                else:
                    continue  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–æ–ª—å–∫–æ –∏–∑ —á–∏—Å–ª–∞, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
            else:
                header_to_check = header_text
            
            # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ –¥—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            clean_header = re.sub(r'[^\w\s\(\)\[\]]', '', header_to_check)
            
            # –£–¥–∞–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫–æ–±–æ–∫ (–∫–∞–∫ –∫—Ä—É–≥–ª—ã—Ö, —Ç–∞–∫ –∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö)
            clean_header = re.sub(r'\([^)]*\)', '', clean_header)
            clean_header = re.sub(r'\[[^\]]*\]', '', clean_header)
            
            # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            clean_header = clean_header.strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±—É–∫–≤—ã –ª–∞—Ç–∏–Ω—Å–∫–æ–≥–æ –∞–ª—Ñ–∞–≤–∏—Ç–∞
            latin_letters = ''.join(c for c in clean_header if c.isalpha() and 'a' <= c.lower() <= 'z')
            
            # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã –∏ –µ—Å—Ç—å –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã
            if latin_letters and latin_letters != latin_letters.lower():
                # –ò—Å–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω—è—Ç–æ –ø–∏—Å–∞—Ç—å —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã
                technical_terms = [
                    "API", "URL", "HTML", "JSON", "HTTP", "XML", "REST",
                    "SQL", "NoSQL", "OAuth", "JWT", "WebSocket", "GraphQL",
                    "Workflow", "Action Plan", "CI/CD", "DevOps", "TaskMaster",
                    "Auto", "Output"
                ]
                
                # –û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                special_terms = [
                    "Task Master", "TaskMaster", "Auto-", "Output", 
                    "Registry Standard", "JTBD", "ProductHeroes",
                    "Registry", "Goal Map", "Closed Loop Incident Resolution",
                    "CLIR", "Advising", "AI", "Context", "Customer Development",
                    "CET", "End-to-End", "Page Object", "App Actions",
                    "Agile", "Follow-up", "Shadowing", "Rick.ai", "Pull",
                    "@heroesGPT_bot", "Release Notes", "Enterprise Suite"
                ]
                
                contains_tech_term = False
                for term in special_terms:
                    if term in header_text:
                        contains_tech_term = True
                        break
                
                # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏, —Ä–∞–∑—Ä–µ—à–∞–µ–º –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã –≤–Ω—É—Ç—Ä–∏ –Ω–∏—Ö
                if re.search(r'\[[^\]]*[A-Z][^\]]*\]', header_text):
                    contains_tech_term = True
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –Ω–µ –Ω–∞—à–ª–∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                if not contains_tech_term:
                    for term in technical_terms:
                        if term.lower() in clean_header.lower():
                            term_pos = clean_header.lower().find(term.lower())
                            term_end = term_pos + len(term)
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ—Ä–º–∏–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —á–∞—Å—Ç—å—é –¥—Ä—É–≥–æ–≥–æ —Å–ª–æ–≤–∞
                            if (term_pos == 0 or not clean_header[term_pos-1].isalpha()) and \
                               (term_end == len(clean_header) or not clean_header[term_end].isalpha()):
                                contains_tech_term = True
                                break
                
                # –û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏: –∞–∫—Ä–æ–Ω–∏–º—ã –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                if not all(c.isupper() for c in latin_letters) and latin_letters.upper() != latin_letters and not contains_tech_term:
                    errors.append(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫ '{header_text}' —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã")
    
    except Exception as e:
        errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {str(e)}")
    
    return len(errors) == 0, errors

def validate_header_structure(file_path: str, template_file: str) -> Tuple[bool, List[str]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –∑–∞–¥–∞–Ω–Ω–æ–º—É —à–∞–±–ª–æ–Ω—É.
    
    Args:
        file_path: –ü—É—Ç—å –∫ –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ–º—É —Ñ–∞–π–ª—É
        template_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É-—à–∞–±–ª–æ–Ω—É —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        
    Returns:
        –ö–æ—Ä—Ç–µ–∂ –∏–∑ –¥–≤—É—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤:
        - –ë—É–ª–µ–≤–æ –∑–Ω–∞—á–µ–Ω–∏–µ, —É–∫–∞–∑—ã–≤–∞—é—â–µ–µ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        - –°–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
    """
    errors = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
    if not os.path.exists(file_path):
        errors.append(f"–§–∞–π–ª {file_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return False, errors
    
    if not os.path.exists(template_file):
        errors.append(f"–§–∞–π–ª —à–∞–±–ª–æ–Ω–∞ {template_file} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return False, errors
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏–∑ —Ñ–∞–π–ª–æ–≤
    try:
        # –ò–∑ –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ–≥–æ —Ñ–∞–π–ª–∞
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        file_headers = extract_headers(content)
        
        # –ò–∑ —Ñ–∞–π–ª–∞-—à–∞–±–ª–æ–Ω–∞
        with open(template_file, 'r', encoding='utf-8') as f:
            template_content = f.read()
            
        template_headers = extract_headers(template_content)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if len(file_headers) == 0:
            errors.append(f"–í —Ñ–∞–π–ª–µ {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–∏")
            return False, errors
        
        if len(template_headers) == 0:
            errors.append(f"–í —Ñ–∞–π–ª–µ —à–∞–±–ª–æ–Ω–∞ {template_file} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–∏")
            return False, errors
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏–∑ —à–∞–±–ª–æ–Ω–∞
        for level, header_text in template_headers:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å —Ç–∞–∫–∏–º –∂–µ —É—Ä–æ–≤–Ω–µ–º –∏ —Ç–µ–∫—Å—Ç–æ–º –≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º–æ–º —Ñ–∞–π–ª–µ
            found = False
            for file_level, file_header_text in file_headers:
                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                if level == file_level and clean_header_text(header_text) == clean_header_text(file_header_text):
                    found = True
                    break
            
            if not found:
                errors.append(f"–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ '{header_text}' —É—Ä–æ–≤–Ω—è {level} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {file_path}")
    
    except Exception as e:
        errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞ {file_path}: {str(e)}")
    
    return len(errors) == 0, errors

def extract_headers(content: str) -> List[Tuple[str, str]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ markdown.
    
    Args:
        content: –¢–µ–∫—Å—Ç markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—É—Ä–æ–≤–µ–Ω—å_–∑–∞–≥–æ–ª–æ–≤–∫–∞, —Ç–µ–∫—Å—Ç_–∑–∞–≥–æ–ª–æ–≤–∫–∞)
    """
    header_pattern = r'^(#{1,6})\s+(.+)$'
    headers = re.findall(header_pattern, content, re.MULTILINE)
    return headers

def clean_header_text(header_text: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, —É–¥–∞–ª—è—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É.
    
    Args:
        header_text: –¢–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞
        
    Returns:
        –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞
    """
    # –£–¥–∞–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∏ –¥—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    clean_text = re.sub(r'[^\w\s]', '', header_text)
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    clean_text = clean_text.lower().strip()
    return clean_text