#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∑–∞–¥–∞—á –∏ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤ –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã.
–ù–∞—Ö–æ–¥–∏—Ç –∏ –∞—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤.

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 21 –º–∞—è 2025
"""

import os
import re
import shutil
import logging
import hashlib
from typing import List, Dict, Tuple, Set, Any
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    filename='consolidate_remaining.log'
)
logger = logging.getLogger(__name__)

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
TODO_FILE = "todo/todo.md"
INCIDENTS_FILE = "incidents/ai.incidents.md"
ARCHIVE_DIR = "archive"
TASKS_DIR = "todo"
INCIDENTS_DIR = "incidents"

def ensure_dir_exists(directory: str) -> None:
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    if not os.path.exists(directory):
        os.makedirs(directory)
        logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {directory}")

def get_file_hash(file_path: str) -> str:
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞."""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def find_duplicate_files(directory: str) -> Dict[str, List[str]]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    
    Args:
        directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {—Ö–µ—à: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º}
    """
    hashes: Dict[str, List[str]] = {}
    
    for root, _, files in os.walk(directory):
        for filename in files:
            if not filename.endswith(".md"):
                continue
                
            file_path = os.path.join(root, filename)
            file_hash = get_file_hash(file_path)
            
            if file_hash not in hashes:
                hashes[file_hash] = []
            
            hashes[file_hash].append(file_path)
    
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ö–µ—à–∏ —Å –±–æ–ª–µ–µ —á–µ–º –æ–¥–Ω–∏–º —Ñ–∞–π–ª–æ–º
    return {h: files for h, files in hashes.items() if len(files) > 1}

def find_tasks_incidents_files() -> Tuple[List[str], List[str]]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Ñ–∞–π–ª—ã –∑–∞–¥–∞—á –∏ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤ –≤–Ω–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.
    
    Returns:
        –ö–æ—Ä—Ç–µ–∂ (—Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∑–∞–¥–∞—á, —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤)
    """
    task_files = []
    incident_files = []
    
    # –ò—â–µ–º —Ñ–∞–π–ª—ã –∑–∞–¥–∞—á
    for root, _, files in os.walk("."):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ .git, node_modules, __pycache__ –∏ —Ç.–¥.
        if any(ignore in root for ignore in [".git", "node_modules", "__pycache__", ARCHIVE_DIR]):
            continue
            
        for filename in files:
            if not filename.endswith(".md"):
                continue
                
            file_path = os.path.join(root, filename)
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã
            if file_path == TODO_FILE or file_path == INCIDENTS_FILE:
                continue
                
            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–≥–æ —Ç–∏–ø
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∑–∞–¥–∞—á–µ–π –∏–ª–∏ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–º
                if "# –ó–∞–¥–∞—á–∞:" in content or "# Task:" in content:
                    task_files.append(file_path)
                elif "# –ò–Ω—Ü–∏–¥–µ–Ω—Ç:" in content or "# Incident:" in content:
                    incident_files.append(file_path)
    
    return task_files, incident_files

def extract_task_info(file_path: str) -> Dict[str, str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–µ –∏–∑ —Ñ–∞–π–ª–∞.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∑–∞–¥–∞—á–∏
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∑–∞–¥–∞—á–µ
    """
    task_info = {"file_path": file_path}
    
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        content = f.read()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
        title_match = re.search(r"# –ó–∞–¥–∞—á–∞:(.+)|# Task:(.+)", content)
        if title_match:
            task_info["title"] = (title_match.group(1) or title_match.group(2)).strip()
        else:
            task_info["title"] = os.path.basename(file_path)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
        status_match = re.search(r"–°—Ç–∞—Ç—É—Å:(.+)|Status:(.+)", content)
        if status_match:
            task_info["status"] = (status_match.group(1) or status_match.group(2)).strip()
        else:
            task_info["status"] = "–ù–µ –Ω–∞—á–∞—Ç–æ"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
        task_info["content"] = content
    
    return task_info

def extract_incident_info(file_path: str) -> Dict[str, str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Ü–∏–¥–µ–Ω—Ç–µ –∏–∑ —Ñ–∞–π–ª–∞.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–Ω—Ü–∏–¥–µ–Ω—Ç–µ
    """
    incident_info = {"file_path": file_path}
    
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        content = f.read()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞
        title_match = re.search(r"# –ò–Ω—Ü–∏–¥–µ–Ω—Ç:(.+)|# Incident:(.+)", content)
        if title_match:
            incident_info["title"] = (title_match.group(1) or title_match.group(2)).strip()
        else:
            incident_info["title"] = os.path.basename(file_path)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç—É—Å –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞
        status_match = re.search(r"–°—Ç–∞—Ç—É—Å:(.+)|Status:(.+)", content)
        if status_match:
            incident_info["status"] = (status_match.group(1) or status_match.group(2)).strip()
        else:
            incident_info["status"] = "–û—Ç–∫—Ä—ã—Ç"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞
        incident_info["content"] = content
    
    return incident_info

def consolidate_tasks(task_files: List[str]) -> int:
    """
    –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä—É–µ—Ç –∑–∞–¥–∞—á–∏ –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª todo.md.
    
    Args:
        task_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –∑–∞–¥–∞—á
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
    """
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏
    archive_dir = os.path.join(ARCHIVE_DIR, "tasks")
    ensure_dir_exists(archive_dir)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –∑–∞–¥–∞—á
    if os.path.exists(TODO_FILE):
        with open(TODO_FILE, "r", encoding="utf-8", errors="ignore") as f:
            todo_content = f.read()
    else:
        todo_content = "# –ó–∞–¥–∞—á–∏\n\n"
        ensure_dir_exists(os.path.dirname(TODO_FILE))
    
    count = 0
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –∑–∞–¥–∞—á
    for file_path in task_files:
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–µ
            task_info = extract_task_info(file_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–∞ –∑–∞–¥–∞—á–∞ —É–∂–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ñ–∞–π–ª–µ
            if f"# –ó–∞–¥–∞—á–∞: {task_info['title']}" in todo_content or f"# Task: {task_info['title']}" in todo_content:
                logger.info(f"–ó–∞–¥–∞—á–∞ '{task_info['title']}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ñ–∞–π–ª–µ. –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º {file_path}")
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
                todo_content += f"\n\n## {task_info['title']}\n\n{task_info['content']}\n\n"
                count += 1
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ '{task_info['title']}' –∏–∑ —Ñ–∞–π–ª–∞ {file_path}")
            
            # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Ñ–∞–π–ª
            archive_path = os.path.join(archive_dir, os.path.basename(file_path))
            shutil.move(file_path, archive_path)
            logger.info(f"–§–∞–π–ª {file_path} –ø–µ—Ä–µ–º–µ—â–µ–Ω –≤ {archive_path}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
    with open(TODO_FILE, "w", encoding="utf-8") as f:
        f.write(todo_content)
    
    return count

def consolidate_incidents(incident_files: List[str]) -> int:
    """
    –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä—É–µ—Ç –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª ai.incidents.md.
    
    Args:
        incident_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤
    """
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏
    archive_dir = os.path.join(ARCHIVE_DIR, "incidents")
    ensure_dir_exists(archive_dir)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤
    if os.path.exists(INCIDENTS_FILE):
        with open(INCIDENTS_FILE, "r", encoding="utf-8", errors="ignore") as f:
            incidents_content = f.read()
    else:
        incidents_content = "# –ò–Ω—Ü–∏–¥–µ–Ω—Ç—ã\n\n"
        ensure_dir_exists(os.path.dirname(INCIDENTS_FILE))
    
    count = 0
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤
    for file_path in incident_files:
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Ü–∏–¥–µ–Ω—Ç–µ
            incident_info = extract_incident_info(file_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–æ—Ç –∏–Ω—Ü–∏–¥–µ–Ω—Ç —É–∂–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ñ–∞–π–ª–µ
            if f"# –ò–Ω—Ü–∏–¥–µ–Ω—Ç: {incident_info['title']}" in incidents_content or f"# Incident: {incident_info['title']}" in incidents_content:
                logger.info(f"–ò–Ω—Ü–∏–¥–µ–Ω—Ç '{incident_info['title']}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ñ–∞–π–ª–µ. –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º {file_path}")
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ü–∏–¥–µ–Ω—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
                incidents_content += f"\n\n## {incident_info['title']}\n\n{incident_info['content']}\n\n"
                count += 1
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –∏–Ω—Ü–∏–¥–µ–Ω—Ç '{incident_info['title']}' –∏–∑ —Ñ–∞–π–ª–∞ {file_path}")
            
            # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Ñ–∞–π–ª
            archive_path = os.path.join(archive_dir, os.path.basename(file_path))
            shutil.move(file_path, archive_path)
            logger.info(f"–§–∞–π–ª {file_path} –ø–µ—Ä–µ–º–µ—â–µ–Ω –≤ {archive_path}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
    with open(INCIDENTS_FILE, "w", encoding="utf-8") as f:
        f.write(incidents_content)
    
    return count

def archive_duplicates(duplicates: Dict[str, List[str]]) -> int:
    """
    –ê—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤.
    
    Args:
        duplicates: –°–ª–æ–≤–∞—Ä—å {—Ö–µ—à: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º}
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    """
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏
    archive_dir = os.path.join(ARCHIVE_DIR, "duplicates")
    ensure_dir_exists(archive_dir)
    
    count = 0
    
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –≥—Ä—É–ø–ø–∞–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    for file_hash, files in duplicates.items():
        # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª
        original = files[0]
        
        # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
        for file_path in files[1:]:
            try:
                # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏
                base_name = os.path.basename(file_path)
                dir_name = os.path.basename(os.path.dirname(file_path))
                archive_name = f"{dir_name}_{base_name}"
                archive_path = os.path.join(archive_dir, archive_name)
                
                # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É
                if os.path.exists(archive_path):
                    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
                    archive_name = f"{dir_name}_{timestamp}_{base_name}"
                    archive_path = os.path.join(archive_dir, archive_name)
                
                # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º —Ñ–∞–π–ª
                shutil.move(file_path, archive_path)
                logger.info(f"–î—É–±–ª–∏–∫–∞—Ç {file_path} –ø–µ—Ä–µ–º–µ—â–µ–Ω –≤ {archive_path} (–æ—Ä–∏–≥–∏–Ω–∞–ª: {original})")
                count += 1
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–∞ {file_path}: {e}")
    
    return count

def fix_urls_in_report_messages():
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç URLs –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –æ—Ç—á–µ—Ç–æ–≤, —á—Ç–æ–±—ã –æ–Ω–∏ —É–∫–∞–∑—ã–≤–∞–ª–∏ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—Ç.
    """
    files_to_check = [
        "direct_chat_message.py",
        "demo_all_objects.py",
        "integrate_replit_chat.py"
    ]
    
    replacements = [
        ("http://localhost:5000", "http://0.0.0.0:5000"),
        ("localhost:5000", "0.0.0.0:5000")
    ]
    
    for file_path in files_to_check:
        if not os.path.exists(file_path):
            continue
            
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                
            modified = False
            
            for old, new in replacements:
                if old in content:
                    content = content.replace(old, new)
                    modified = True
            
            if modified:
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(content)
                logger.info(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã URLs –≤ —Ñ–∞–π–ª–µ {file_path}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ URLs –≤ —Ñ–∞–π–ª–µ {file_path}: {e}")

def update_todo_file_with_summary(tasks_count: int, incidents_count: int, duplicates_count: int) -> None:
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç —Ñ–∞–π–ª todo.md —Å –∏—Ç–æ–≥–∞–º–∏ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏.
    
    Args:
        tasks_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
        incidents_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤
        duplicates_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    """
    if not os.path.exists(TODO_FILE):
        return
        
    with open(TODO_FILE, "r", encoding="utf-8", errors="ignore") as f:
        content = f.read()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report = f"""
## –û—Ç—á–µ—Ç –æ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤ ({timestamp})

- –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–¥–∞—á: {tasks_count}
- –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤: {incidents_count}
- –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}

–í—Å–µ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –∑–∞–¥–∞—á –∏ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤ –±—ã–ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –≤ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–π–ª—ã.
–î—É–±–ª–∏–∫–∞—Ç—ã –±—ã–ª–∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã –≤ –∞—Ä—Ö–∏–≤.
URLs –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –æ—Ç—á–µ—Ç–æ–≤ –±—ã–ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã.
"""
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    if "# –ó–∞–¥–∞—á–∏" in content:
        content = content.replace("# –ó–∞–¥–∞—á–∏", f"# –ó–∞–¥–∞—á–∏\n{report}")
    else:
        content = f"# –ó–∞–¥–∞—á–∏\n{report}\n\n{content}"
    
    with open(TODO_FILE, "w", encoding="utf-8") as f:
        f.write(content)
    
    logger.info("–§–∞–π–ª todo.md –æ–±–Ω–æ–≤–ª–µ–Ω —Å –æ—Ç—á–µ—Ç–æ–º –æ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    print("\n=== –ö–û–ù–°–û–õ–ò–î–ê–¶–ò–Ø –û–°–¢–ê–í–®–ò–•–°–Ø –ó–ê–î–ê–ß –ò –ò–ù–¶–ò–î–ï–ù–¢–û–í ===\n")
    
    # –®–∞–≥ 1: –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã –∑–∞–¥–∞—á –∏ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤
    task_files, incident_files = find_tasks_incidents_files()
    print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∑–∞–¥–∞—á: {len(task_files)}")
    print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤: {len(incident_files)}")
    
    # –®–∞–≥ 2: –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤
    duplicates = {}
    for directory in [TASKS_DIR, INCIDENTS_DIR]:
        if os.path.exists(directory):
            dir_duplicates = find_duplicate_files(directory)
            duplicates.update(dir_duplicates)
    
    print(f"–ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
    
    # –®–∞–≥ 3: –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏
    tasks_count = consolidate_tasks(task_files)
    print(f"–ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–¥–∞—á: {tasks_count}")
    
    # –®–∞–≥ 4: –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä—É–µ–º –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã
    incidents_count = consolidate_incidents(incident_files)
    print(f"–ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤: {incidents_count}")
    
    # –®–∞–≥ 5: –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates_count = archive_duplicates(duplicates)
    print(f"–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count}")
    
    # –®–∞–≥ 6: –ò—Å–ø—Ä–∞–≤–ª—è–µ–º URLs –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –æ—Ç—á–µ—Ç–æ–≤
    fix_urls_in_report_messages()
    print("URLs –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –æ—Ç—á–µ—Ç–æ–≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã")
    
    # –®–∞–≥ 7: –û–±–Ω–æ–≤–ª—è–µ–º todo.md —Å –∏—Ç–æ–≥–∞–º–∏ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏
    update_todo_file_with_summary(tasks_count, incidents_count, duplicates_count)
    
    print("\n‚úÖ –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("üìã –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª todo.md –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –æ—Ç—á–µ—Ç–∞ –æ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏")
    
    return 0

if __name__ == "__main__":
    main()