"""
TDD —Ç–µ—Å—Ç—ã –¥–ª—è HeroesGPT MCP Workflow
–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤—Å–µ–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º –≥–∏–ø–æ—Ç–µ–∑—ã
"""

import pytest
import asyncio
from datetime import datetime
from pathlib import Path

from advising_platform.src.mcp.heroes.heroes_workflow_orchestrator import (
    HeroesWorkflowOrchestrator,
    analyze_landing
)

class TestHeroesWorkflowTDD:
    """TDD —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≥–∏–ø–æ—Ç–µ–∑—ã heroesGPT workflow"""
    
    def setup_method(self):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –∫–∞–∂–¥–æ–º—É —Ç–µ—Å—Ç—É"""
        self.orchestrator = HeroesWorkflowOrchestrator()
        
    # === RED PHASE TESTS (–∫—Ä–∏—Ç–µ—Ä–∏–∏ —Ñ–∞–ª—å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏) ===
    
    @pytest.mark.asyncio
    async def test_analysis_time_under_5_minutes(self):
        """–ö–†–ò–¢–ï–†–ò–ô –§–ê–õ–¨–°–ò–§–ò–ö–ê–¶–ò–ò: –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞ >10 –º–∏–Ω—É—Ç"""
        start_time = datetime.now()
        
        report = await analyze_landing(
            url="https://example.com/test-landing"
        )
        
        analysis_time = (datetime.now() - start_time).total_seconds()
        
        # –ö–†–ò–¢–ò–ß–ù–û: –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å <5 –º–∏–Ω—É—Ç (300 —Å–µ–∫—É–Ω–¥)
        assert analysis_time < 300, f"–ê–Ω–∞–ª–∏–∑ –∑–∞–Ω—è–ª {analysis_time:.1f}—Å > 5 –º–∏–Ω—É—Ç"
        
        # –ñ–ï–õ–ê–¢–ï–õ–¨–ù–û: <2 –º–∏–Ω—É—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ feedback
        if analysis_time < 120:
            print(f"üöÄ –û—Ç–ª–∏—á–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å: {analysis_time:.1f}—Å")
        
    @pytest.mark.asyncio
    async def test_offers_extraction_over_90_percent(self):
        """–ö–†–ò–¢–ï–†–ò–ô –§–ê–õ–¨–°–ò–§–ò–ö–ê–¶–ò–ò: –ø—Ä–æ–ø—É—â–µ–Ω–æ >10% –æ—Ñ–µ—Ä–æ–≤"""
        report = await analyze_landing(
            content="–¢–µ—Å—Ç–æ–≤—ã–π –ª–µ–Ω–¥–∏–Ω–≥ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –æ—Ñ–µ—Ä–æ–≤..."
        )
        
        offers = report.offers_table
        
        # –ú–∏–Ω–∏–º—É–º 20 –æ—Ñ–µ—Ä–æ–≤ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–µ–Ω–¥–∏–Ω–≥–∞
        assert len(offers) >= 20, f"–ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {len(offers)} –æ—Ñ–µ—Ä–æ–≤ < 20"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        valid_offers = [o for o in offers if o.offer_text and o.offer_type]
        quality_ratio = len(valid_offers) / len(offers)
        
        assert quality_ratio >= 0.9, f"–ö–∞—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è {quality_ratio:.1%} < 90%"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Ç–∏–ø–æ–≤
        offer_types = set(o.offer_type for o in offers)
        assert len(offer_types) >= 3, f"–ú–∞–ª–æ —Ç–∏–ø–æ–≤ –æ—Ñ–µ—Ä–æ–≤: {offer_types}"
        
    @pytest.mark.asyncio 
    async def test_auto_save_100_percent(self):
        """–ö–†–ò–¢–ï–†–ò–ô –§–ê–õ–¨–°–ò–§–ò–ö–ê–¶–ò–ò: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ"""
        report = await analyze_landing(
            url="https://example.com/autosave-test"
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã
        output_dir = Path("[projects]/[heroes-gpt-bot]/review-results/")
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –æ—Ç—á–µ—Ç
        report_files = list(output_dir.glob(f"analysis_landing_*_{report.id}.md"))
        assert len(report_files) == 1, "–û—Ç—á–µ—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ markdown"
        
        # JSON –¥–∞–Ω–Ω—ã–µ
        data_files = list(output_dir.glob(f"data_*_{report.id}.json"))
        assert len(data_files) == 1, "–î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON"
        
        # –ò–Ω–¥–µ–∫—Å –æ–±–Ω–æ–≤–ª–µ–Ω
        index_file = output_dir / "analysis_index.json"
        assert index_file.exists(), "–ò–Ω–¥–µ–∫—Å –∞–Ω–∞–ª–∏–∑–æ–≤ –Ω–µ —Å–æ–∑–¥–∞–Ω"
        
    @pytest.mark.asyncio
    async def test_heroesgpt_standard_compliance(self):
        """–ö–†–ò–¢–ï–†–ò–ô –§–ê–õ–¨–°–ò–§–ò–ö–ê–¶–ò–ò: –Ω–∞—Ä—É—à–µ–Ω–∏–µ >20% —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞"""
        report = await analyze_landing(
            url="https://example.com/standard-test"
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–µ–∫—Ü–∏–π –≥–µ—Ä–æ–µ—ÅGPT —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
        required_sections = [
            'landing_analysis',  # –û–±—â–∏–π –æ–±–∑–æ—Ä
            'offers_table',      # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ñ–µ—Ä–æ–≤  
            'jtbd_scenarios',    # –ó–∞–¥–∞—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (JTBD)
            'segments',          # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
            'rating',            # –†–µ–π—Ç–∏–Ω–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
            'recommendations'    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        ]
        
        missing_sections = []
        for section in required_sections:
            if not hasattr(report, section) or getattr(report, section) is None:
                missing_sections.append(section)
        
        compliance_ratio = (len(required_sections) - len(missing_sections)) / len(required_sections)
        assert compliance_ratio >= 0.8, f"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É {compliance_ratio:.1%} < 80%"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü—ã –æ—Ñ–µ—Ä–æ–≤
        if report.offers_table:
            offer = report.offers_table[0]
            required_offer_fields = [
                'offer_text', 'offer_type', 'quantitative_data',
                'target_segment', 'emotional_trigger', 'value_tax_rating'
            ]
            
            for field in required_offer_fields:
                assert hasattr(offer, field), f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {field} –≤ –∞–Ω–∞–ª–∏–∑–µ –æ—Ñ–µ—Ä–æ–≤"
    
    @pytest.mark.asyncio
    async def test_jtbd_table_creation(self):
        """–ö–†–ò–¢–ï–†–ò–ô –§–ê–õ–¨–°–ò–§–ò–ö–ê–¶–ò–ò: –Ω–µ —Å–æ–∑–¥–∞–µ—Ç—Å—è JTBD —Ç–∞–±–ª–∏—Ü–∞ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É v4.0"""
        report = await analyze_landing(
            url="https://example.com/jtbd-test"
        )
        
        jtbd_scenarios = report.jtbd_scenarios
        
        # –ú–∏–Ω–∏–º—É–º 8-12 Big JTBD –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É
        assert len(jtbd_scenarios) >= 8, f"JTBD —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ {len(jtbd_scenarios)} < 8"
        assert len(jtbd_scenarios) <= 15, f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ JTBD: {len(jtbd_scenarios)} > 15"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–∞–∂–¥–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
        required_jtbd_fields = [
            'big_jtbd', 'when_trigger', 'medium_jtbd', 
            'small_jtbd', 'implementing_files', 'status'
        ]
        
        for scenario in jtbd_scenarios:
            for field in required_jtbd_fields:
                assert hasattr(scenario, field), f"JTBD —Å—Ü–µ–Ω–∞—Ä–∏–π –±–µ–∑ –ø–æ–ª—è {field}"
                assert getattr(scenario, field), f"–ü—É—Å—Ç–æ–µ –ø–æ–ª–µ {field} –≤ JTBD"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤
        triggers = [s.when_trigger for s in jtbd_scenarios]
        unique_triggers = set(triggers)
        assert len(unique_triggers) >= len(triggers) * 0.8, "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤"
    
    # === –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ï –¢–ï–°–¢–´ ===
    
    @pytest.mark.asyncio
    async def test_value_tax_analysis_quality(self):
        """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ –í—ã–≥–æ–¥–∞/–ù–∞–ª–æ–≥ –ø–æ Tone-Style Standard"""
        report = await analyze_landing(
            content="–ò–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–∞—à–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π 100%"
        )
        
        offers = report.offers_table
        
        # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏ –≤—ã–≥–æ–¥—ã, –∏ –Ω–∞–ª–æ–≥–∏
        benefits = [o for o in offers if o.value_tax_rating == "–í—ã–≥–æ–¥–∞"]
        taxes = [o for o in offers if o.value_tax_rating == "–ù–∞–ª–æ–≥"]
        
        assert len(benefits) > 0, "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –≤—ã–≥–æ–¥—ã"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç–∏ –≤ –≤—ã–≥–æ–¥–∞—Ö
        quantitative_benefits = [o for o in benefits if o.quantitative_data]
        if benefits:
            concrete_ratio = len(quantitative_benefits) / len(benefits)
            assert concrete_ratio >= 0.3, f"–ú–∞–ª–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –≤—ã–≥–æ–¥: {concrete_ratio:.1%}"
    
    @pytest.mark.asyncio
    async def test_segment_grouping_logic(self):
        """–¢–µ—Å—Ç –ª–æ–≥–∏–∫–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ —Ç—Ä–∏–≥–≥–µ—Ä–∞–º"""
        report = await analyze_landing(
            url="https://example.com/segments-test"
        )
        
        segments = report.segments
        
        # –ú–∏–Ω–∏–º—É–º 3 —Å–µ–≥–º–µ–Ω—Ç–∞
        assert len(segments) >= 3, f"–°–µ–≥–º–µ–Ω—Ç–æ–≤ {len(segments)} < 3"
        
        # –ö–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –∏ —Ç—Ä–∏–≥–≥–µ—Ä—ã
        for segment_name, segment_data in segments.items():
            assert 'description' in segment_data, f"–°–µ–≥–º–µ–Ω—Ç {segment_name} –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è"
            assert 'triggers' in segment_data, f"–°–µ–≥–º–µ–Ω—Ç {segment_name} –±–µ–∑ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤"
            assert 'motivations' in segment_data, f"–°–µ–≥–º–µ–Ω—Ç {segment_name} –±–µ–∑ –º–æ—Ç–∏–≤–∞—Ü–∏–π"
    
    @pytest.mark.asyncio
    async def test_rating_calculation_logic(self):
        """–¢–µ—Å—Ç –ª–æ–≥–∏–∫–∏ —Ä–∞—Å—á–µ—Ç–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ 1-5"""
        report = await analyze_landing(
            url="https://example.com/rating-test"
        )
        
        rating = report.rating
        
        # –†–µ–π—Ç–∏–Ω–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 1-5
        assert 1 <= rating <= 5, f"–†–µ–π—Ç–∏–Ω–≥ {rating} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 1-5"
        assert isinstance(rating, int), f"–†–µ–π—Ç–∏–Ω–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ü–µ–ª—ã–º —á–∏—Å–ª–æ–º, –ø–æ–ª—É—á–µ–Ω {type(rating)}"
    
    @pytest.mark.asyncio
    async def test_recommendations_relevance(self):
        """–¢–µ—Å—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        report = await analyze_landing(
            url="https://example.com/recommendations-test"
        )
        
        recommendations = report.recommendations
        
        # –ú–∏–Ω–∏–º—É–º 5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        assert len(recommendations) >= 5, f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π {len(recommendations)} < 5"
        
        # –ú–∞–∫—Å–∏–º—É–º 10 (—á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å)
        assert len(recommendations) <= 10, f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(recommendations)}"
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–º–∏
        meaningful_recs = [r for r in recommendations if len(r) > 20]
        assert len(meaningful_recs) >= len(recommendations) * 0.8, "–ú–Ω–æ–≥–æ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"
    
    # === –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ï –¢–ï–°–¢–´ ===
    
    @pytest.mark.asyncio
    async def test_different_input_types(self):
        """–¢–µ—Å—Ç —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        
        # –¢–µ—Å—Ç —Å URL
        report_url = await analyze_landing(url="https://example.com")
        assert report_url.landing_analysis.url == "https://example.com"
        
        # –¢–µ—Å—Ç —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        test_content = "–¢–µ—Å—Ç–æ–≤—ã–π –ª–µ–Ω–¥–∏–Ω–≥ —Å –æ—Ñ–µ—Ä–∞–º–∏"
        report_content = await analyze_landing(content=test_content)
        assert report_content.landing_analysis.content_length > 0
        
        # –¢–µ—Å—Ç —Å–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–º
        report_screenshot = await analyze_landing(screenshot="/path/to/screenshot.png")
        assert report_screenshot.landing_analysis.url == "/path/to/screenshot.png"
    
    @pytest.mark.asyncio 
    async def test_error_handling(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
        
        # –¢–µ—Å—Ç —Å –ø—É—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        with pytest.raises(Exception):
            await analyze_landing()  # –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã None
        
        # –¢–µ—Å—Ç —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º URL (–¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è gracefully)
        try:
            report = await analyze_landing(url="invalid-url")
            # –ï—Å–ª–∏ –Ω–µ —É–ø–∞–ª–æ - –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–æ–∑–¥–∞–Ω –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
            assert report is not None
            assert hasattr(report, 'rating')
        except Exception as e:
            # –û—à–∏–±–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π
            assert len(str(e)) > 10
    
    # === PERFORMANCE –¢–ï–°–¢–´ ===
    
    @pytest.mark.asyncio
    async def test_batch_processing_capability(self):
        """–¢–µ—Å—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ batch –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        
        urls = [
            "https://example1.com",
            "https://example2.com", 
            "https://example3.com"
        ]
        
        start_time = datetime.now()
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        tasks = [analyze_landing(url=url) for url in urls]
        reports = await asyncio.gather(*tasks)
        
        total_time = (datetime.now() - start_time).total_seconds()
        
        # Batch –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±—ã—Å—Ç—Ä–µ–µ —á–µ–º 3 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞
        assert total_time < 600, f"Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–Ω—è–ª–∞ {total_time:.1f}—Å > 10 –º–∏–Ω—É—Ç"
        assert len(reports) == 3, "–ù–µ –≤—Å–µ –æ—Ç—á–µ—Ç—ã —Å–æ–∑–¥–∞–Ω—ã"
        
        # –í—Å–µ –æ—Ç—á–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º–∏
        for report in reports:
            assert report.rating >= 1
            assert len(report.offers_table) > 0

def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö TDD —Ç–µ—Å—Ç–æ–≤"""
    print("üß™ –ó–ê–ü–£–°–ö TDD –¢–ï–°–¢–û–í HERO–ïSGPT WORKFLOW")
    print("="*60)
    
    # –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ pytest
    exit_code = pytest.main([__file__, "-v", "--tb=short"])
    
    if exit_code == 0:
        print("‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ - –ì–ò–ü–û–¢–ï–ó–ê –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ê")
        print("üéâ HeroesGPT MCP Workflow –≥–æ—Ç–æ–≤ –∫ –ø—Ä–æ–¥–∞–∫—à–Ω—É!")
    else:
        print("‚ùå –¢–ï–°–¢–´ –ù–ï –ü–†–û–ô–î–ï–ù–´ - –ì–ò–ü–û–¢–ï–ó–ê –û–ü–†–û–í–ï–†–ì–ù–£–¢–ê")
        print("üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ workflow")
    
    return exit_code == 0

if __name__ == "__main__":
    run_all_tests()