#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –≤ DuckDB –∫–µ—à
"""

import duckdb
from pathlib import Path
import hashlib
from datetime import datetime

def create_simple_cache():
    """–ü—Ä–æ—Å—Ç–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–µ—à–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏"""
    print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ DuckDB –∫–µ—à–∞...")
    
    # –°–æ–∑–¥–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    conn = duckdb.connect('standards_system.duckdb')
    
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
    conn.execute("""
        CREATE TABLE IF NOT EXISTS standards (
            id VARCHAR PRIMARY KEY,
            name VARCHAR NOT NULL,
            path VARCHAR NOT NULL,
            content TEXT,
            category VARCHAR,
            description TEXT,
            word_count INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞
    test_files = [
        Path("todo.md"),
        Path("README.md"),
        Path("advising_platform/src/standards_system.py")
    ]
    
    loaded_count = 0
    for file_path in test_files:
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                file_id = str(file_path).replace('/', '_').replace('\\', '_')
                word_count = len(content.split())
                description = content[:200] + '...' if len(content) > 200 else content
                
                conn.execute("""
                    INSERT OR REPLACE INTO standards 
                    (id, name, path, content, category, description, word_count, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, [
                    file_id,
                    file_path.stem,
                    str(file_path),
                    content,
                    str(file_path.parent),
                    description,
                    word_count,
                    datetime.now().isoformat()
                ])
                
                loaded_count += 1
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {file_path} ({word_count} —Å–ª–æ–≤)")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path}: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    count = conn.execute('SELECT COUNT(*) FROM standards').fetchone()[0]
    print(f"\nüìä –í—Å–µ–≥–æ –≤ –∫–µ—à–µ: {count} —Ñ–∞–π–ª–æ–≤")
    
    if count > 0:
        samples = conn.execute('SELECT name, category, word_count FROM standards LIMIT 3').fetchall()
        print("üìã –ü—Ä–∏–º–µ—Ä—ã –≤ –∫–µ—à–µ:")
        for row in samples:
            print(f"  - {row[0]} ({row[1]}) - {row[2]} —Å–ª–æ–≤")
    
    conn.close()
    return count > 0

def test_cache_reading():
    """–¢–µ—Å—Ç —á—Ç–µ–Ω–∏—è –∏–∑ –∫–µ—à–∞"""
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á—Ç–µ–Ω–∏—è –∏–∑ –∫–µ—à–∞...")
    
    conn = duckdb.connect('standards_system.duckdb')
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –∏–∑ –∫–µ—à–∞ –≤–º–µ—Å—Ç–æ –¥–∏—Å–∫–∞
    result = conn.execute("""
        SELECT name, content, word_count 
        FROM standards 
        WHERE name = 'todo' 
        LIMIT 1
    """).fetchone()
    
    if result:
        print(f"‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω –≤ –∫–µ—à–µ: {result[0]} ({result[2]} —Å–ª–æ–≤)")
        print(f"üìÑ –ü–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤: {result[1][:100]}...")
        return True
    else:
        print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–µ—à–µ")
        return False

if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º –∫–µ—à
    cache_created = create_simple_cache()
    
    if cache_created:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —á—Ç–µ–Ω–∏–µ
        test_cache_reading()
        print("\n‚úÖ DuckDB –∫–µ—à —Ä–∞–±–æ—Ç–∞–µ—Ç!")
    else:
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–µ—à")