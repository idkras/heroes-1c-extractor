"""
MCP Module: Implement Feature
–†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∏—á –ø–æ PRD —Å –ø–æ–ª–Ω—ã–º —Ü–∏–∫–ª–æ–º MCP —Å–µ—Ä–≤–µ—Ä–∞

–í–∫–ª—é—á–∞–µ—Ç: register_module(), run_workflow(), report_progress(), 
trigger_next_steps(), log_completion(), incident.create()
"""

import json
import time
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime


def mcp_implement_feature(prd_data: Dict[str, Any], implementation_type: str = "mcp_server") -> Dict[str, Any]:
    """
    MCP –∫–æ–º–∞–Ω–¥–∞: implement-feature
    –†–µ–∞–ª–∏–∑—É–µ—Ç feature –Ω–∞ –æ—Å–Ω–æ–≤–µ PRD —Å –ø–æ–ª–Ω—ã–º MCP —Ü–∏–∫–ª–æ–º
    
    Args:
        prd_data: –î–∞–Ω–Ω—ã–µ PRD –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        implementation_type: –¢–∏–ø —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (mcp_server, module, etc.)
    
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    start_time = time.time()
    
    result = {
        "command": "mcp-implement-feature",
        "timestamp": datetime.now().isoformat(),
        "implementation_type": implementation_type,
        "success": False,
        "implemented_modules": [],
        "registered_functions": [],
        "workflow_steps": [],
        "progress_reports": [],
        "execution_time_ms": 0
    }
    
    try:
        if implementation_type == "mcp_server":
            # –†–µ–∞–ª–∏–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π MCP —Å–µ—Ä–≤–µ—Ä
            server_result = _implement_mcp_server(prd_data)
            result.update(server_result)
        else:
            # –†–µ–∞–ª–∏–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–æ–¥—É–ª—å
            module_result = _implement_module(prd_data, implementation_type)
            result.update(module_result)
        
        result["success"] = True
        
    except Exception as e:
        result["error"] = str(e)
        result["success"] = False
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ü–∏–¥–µ–Ω—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        _create_implementation_incident(str(e), prd_data)
    
    result["execution_time_ms"] = round((time.time() - start_time) * 1000, 2)
    return result


def _implement_mcp_server(prd_data: Dict[str, Any]) -> Dict[str, Any]:
    """–†–µ–∞–ª–∏–∑—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π MCP —Å–µ—Ä–≤–µ—Ä –ø–æ PRD"""
    
    # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π MCP —Å–µ—Ä–≤–µ—Ä
    server_path = Path("advising_platform/src/mcp/standards_mcp_server.js")
    
    implemented_modules = []
    registered_functions = []
    workflow_steps = []
    
    # 1. register_module() - —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π
    modules_to_register = [
        "form_hypothesis",
        "build_jtbd", 
        "write_prd",
        "red_phase_tests",
        "implement_feature",
        "run_tests",
        "evaluate_outcome",
        "falsify_or_confirm",
        "root_cause_analysis"
    ]
    
    for module in modules_to_register:
        if _register_module(module):
            registered_functions.append(f"mcp_{module}")
            implemented_modules.append(module)
    
    # 2. run_workflow() - –∑–∞–ø—É—Å–∫ workflow
    workflow_steps = _create_workflow_sequence()
    
    # 3. report_progress() - –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
    progress_report = _report_implementation_progress(implemented_modules)
    
    # 4. trigger_next_steps() - —Ç—Ä–∏–≥–≥–µ—Ä —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
    next_steps = _trigger_next_steps(workflow_steps)
    
    # 5. log_completion() - –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    _log_completion("mcp_server_implementation", implemented_modules)
    
    return {
        "implemented_modules": implemented_modules,
        "registered_functions": registered_functions,
        "workflow_steps": workflow_steps,
        "progress_reports": [progress_report],
        "next_steps_triggered": next_steps,
        "server_path": str(server_path)
    }


def _implement_module(prd_data: Dict[str, Any], module_name: str) -> Dict[str, Any]:
    """–†–µ–∞–ª–∏–∑—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –º–æ–¥—É–ª—å"""
    
    module_templates = {
        "run_tests": _create_run_tests_module,
        "evaluate_outcome": _create_evaluate_outcome_module,
        "feedback_loop": _create_feedback_loop_module
    }
    
    if module_name in module_templates:
        return module_templates[module_name](prd_data)
    else:
        raise ValueError(f"Unknown module type: {module_name}")


def _register_module(module_name: str) -> bool:
    """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –º–æ–¥—É–ª—å –≤ MCP —Å–∏—Å—Ç–µ–º–µ"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è
    module_path = Path(f"advising_platform/src/mcp/modules/{module_name}.py")
    
    if module_path.exists():
        # –ú–æ–¥—É–ª—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º
        return True
    else:
        # –ú–æ–¥—É–ª—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å
        return False


def _create_workflow_sequence() -> List[Dict[str, Any]]:
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å workflow –ø–æ PRD"""
    
    workflow = [
        {"step": 1, "module": "form_hypothesis", "status": "completed"},
        {"step": 2, "module": "build_jtbd", "status": "completed"},
        {"step": 3, "module": "write_prd", "status": "completed"},
        {"step": 4, "module": "red_phase_tests", "status": "completed"},
        {"step": 5, "module": "implement_feature", "status": "in_progress"},
        {"step": 6, "module": "run_tests", "status": "pending"},
        {"step": 7, "module": "evaluate_outcome", "status": "pending"},
        {"step": 8, "module": "falsify_or_confirm", "status": "completed"},
        {"step": 9, "module": "root_cause_analysis", "status": "completed"},
        {"step": 10, "module": "feedback_loop", "status": "pending"}
    ]
    
    return workflow


def _report_implementation_progress(implemented_modules: List[str]) -> Dict[str, Any]:
    """–û—Ç—á–µ—Ç –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏"""
    
    total_modules = 10  # –ü–æ PRD
    completed_modules = len(implemented_modules)
    completion_rate = completed_modules / total_modules
    
    return {
        "completed_modules": completed_modules,
        "total_modules": total_modules,
        "completion_rate": completion_rate,
        "implemented": implemented_modules,
        "timestamp": datetime.now().isoformat()
    }


def _trigger_next_steps(workflow_steps: List[Dict[str, Any]]) -> List[str]:
    """–¢—Ä–∏–≥–≥–µ—Ä —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤ workflow"""
    
    next_steps = []
    
    for step in workflow_steps:
        if step["status"] == "pending":
            next_steps.append(step["module"])
            if len(next_steps) >= 3:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 3 —Å–ª–µ–¥—É—é—â–∏–º–∏ —à–∞–≥–∞–º–∏
                break
    
    return next_steps


def _log_completion(operation: str, details: List[str]) -> None:
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏"""
    
    log_entry = {
        "operation": operation,
        "details": details,
        "timestamp": datetime.now().isoformat(),
        "status": "completed"
    }
    
    # –õ–æ–≥–∏—Ä—É–µ–º –≤ duck.todo
    duck_todo = Path("[todo ¬∑ incidents]/duck.todo.md")
    if duck_todo.exists():
        content = duck_todo.read_text(encoding='utf-8')
        
        log_section = f"\n## üìù LOG: {datetime.now().strftime('%H:%M')} - {operation}\n"
        log_section += f"–î–µ—Ç–∞–ª–∏: {', '.join(details)}\n"
        
        content += log_section
        duck_todo.write_text(content, encoding='utf-8')


def _create_implementation_incident(error: str, prd_data: Dict[str, Any]) -> None:
    """–°–æ–∑–¥–∞–µ—Ç –∏–Ω—Ü–∏–¥–µ–Ω—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏"""
    
    try:
        from root_cause_analysis import mcp_root_cause_analysis
        
        failed_metrics = {
            "implementation_failure": {
                "actual": f"Error: {error}",
                "expected": "Successful implementation",
                "deviation": 100,
                "status": "FAIL"
            }
        }
        
        mcp_root_cause_analysis(failed_metrics, f"Implementation failure: {error}")
        
    except Exception as e:
        print(f"Failed to create incident: {e}")


def _create_run_tests_module(prd_data: Dict[str, Any]) -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥—É–ª—å run_tests.py"""
    
    run_tests_code = '''"""
MCP Module: Run Tests
–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ test_results.json
"""

import json
import subprocess
import time
from pathlib import Path
from typing import Dict, Any
from datetime import datetime


def mcp_run_tests(test_scope: str = "all") -> Dict[str, Any]:
    """
    MCP –∫–æ–º–∞–Ω–¥–∞: run-tests
    –ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ—Å—Ç—ã –∏ —Å–æ–∑–¥–∞–µ—Ç test_results.json
    """
    start_time = time.time()
    
    result = {
        "command": "mcp-run-tests",
        "timestamp": datetime.now().isoformat(),
        "test_scope": test_scope,
        "tests_run": [],
        "tests_passed": 0,
        "tests_failed": 0,
        "execution_time_ms": 0
    }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    if test_scope == "all":
        result.update(_run_all_tests())
    elif test_scope == "unit":
        result.update(_run_unit_tests())
    elif test_scope == "integration":
        result.update(_run_integration_tests())
    elif test_scope == "e2e":
        result.update(_run_e2e_tests())
    
    # –°–æ–∑–¥–∞–µ–º test_results.json
    _create_test_results_json(result)
    
    result["execution_time_ms"] = round((time.time() - start_time) * 1000, 2)
    return result


def _run_all_tests() -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã"""
    # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
    return {"tests_run": ["unit", "integration", "e2e"], "tests_passed": 0, "tests_failed": 0}


def _run_unit_tests() -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç unit —Ç–µ—Å—Ç—ã"""
    return {"tests_run": ["unit"], "tests_passed": 0, "tests_failed": 0}


def _run_integration_tests() -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç integration —Ç–µ—Å—Ç—ã"""
    return {"tests_run": ["integration"], "tests_passed": 0, "tests_failed": 0}


def _run_e2e_tests() -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç e2e —Ç–µ—Å—Ç—ã"""
    return {"tests_run": ["e2e"], "tests_passed": 0, "tests_failed": 0}


def _create_test_results_json(test_data: Dict[str, Any]) -> None:
    """–°–æ–∑–¥–∞–µ—Ç test_results.json —Ñ–∞–π–ª"""
    
    output_path = Path("advising_platform/src/mcp/output/test_results.json")
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(test_data, f, indent=2, ensure_ascii=False)
'''
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª
    module_path = Path("advising_platform/src/mcp/modules/run_tests.py")
    module_path.write_text(run_tests_code, encoding='utf-8')
    
    return {
        "module_created": "run_tests.py",
        "path": str(module_path),
        "functions": ["mcp_run_tests"]
    }


def _create_evaluate_outcome_module(prd_data: Dict[str, Any]) -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥—É–ª—å evaluate_outcome.py"""
    
    evaluate_code = '''"""
MCP Module: Evaluate Outcome
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ test_results —Å hypothesis.outcome
"""

import json
import time
from pathlib import Path
from typing import Dict, Any
from datetime import datetime


def mcp_evaluate_outcome(hypothesis_data: Dict[str, Any], test_results_file: str = None) -> Dict[str, Any]:
    """
    MCP –∫–æ–º–∞–Ω–¥–∞: evaluate-outcome
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤ —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≥–∏–ø–æ—Ç–µ–∑—ã
    """
    start_time = time.time()
    
    result = {
        "command": "mcp-evaluate-outcome",
        "timestamp": datetime.now().isoformat(),
        "evaluation_success": False,
        "hypothesis_met": False,
        "deviations": [],
        "outcome_report_path": None,
        "execution_time_ms": 0
    }
    
    try:
        # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
        test_results = _read_test_results(test_results_file)
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –≥–∏–ø–æ—Ç–µ–∑–æ–π
        evaluation = _compare_with_hypothesis(hypothesis_data, test_results)
        result.update(evaluation)
        
        # –°–æ–∑–¥–∞–µ–º outcome_report.md
        report_path = _create_outcome_report(hypothesis_data, test_results, evaluation)
        result["outcome_report_path"] = str(report_path)
        
        result["evaluation_success"] = True
        
    except Exception as e:
        result["error"] = str(e)
    
    result["execution_time_ms"] = round((time.time() - start_time) * 1000, 2)
    return result


def _read_test_results(test_results_file: str = None) -> Dict[str, Any]:
    """–ß–∏—Ç–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤"""
    
    if not test_results_file:
        test_results_file = "advising_platform/src/mcp/output/test_results.json"
    
    test_path = Path(test_results_file)
    
    if test_path.exists():
        with open(test_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        return {"tests_run": [], "tests_passed": 0, "tests_failed": 0}


def _compare_with_hypothesis(hypothesis: Dict[str, Any], test_results: Dict[str, Any]) -> Dict[str, Any]:
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –≥–∏–ø–æ—Ç–µ–∑–æ–π"""
    
    # –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
    hypothesis_met = test_results.get("tests_failed", 0) == 0
    
    deviations = []
    if not hypothesis_met:
        deviations.append({
            "metric": "tests_failed", 
            "expected": 0,
            "actual": test_results.get("tests_failed", 0)
        })
    
    return {
        "hypothesis_met": hypothesis_met,
        "deviations": deviations
    }


def _create_outcome_report(hypothesis: Dict[str, Any], test_results: Dict[str, Any], evaluation: Dict[str, Any]) -> Path:
    """–°–æ–∑–¥–∞–µ—Ç outcome_report.md"""
    
    report_content = f"""# Outcome Report - {datetime.now().strftime('%d %b %Y %H:%M')}

## Hypothesis Evaluation

**Hypothesis Met**: {evaluation['hypothesis_met']}

## Test Results Summary

- Tests Run: {len(test_results.get('tests_run', []))}
- Tests Passed: {test_results.get('tests_passed', 0)}
- Tests Failed: {test_results.get('tests_failed', 0)}

## Deviations

{chr(10).join([f"- {dev['metric']}: expected {dev['expected']}, got {dev['actual']}" for dev in evaluation.get('deviations', [])])}

## Conclusion

{"‚úÖ Hypothesis confirmed" if evaluation['hypothesis_met'] else "‚ùå Hypothesis falsified"}
"""
    
    report_path = Path("advising_platform/src/mcp/output/outcome_report.md")
    report_path.parent.mkdir(exist_ok=True)
    report_path.write_text(report_content, encoding='utf-8')
    
    return report_path
'''
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª
    module_path = Path("advising_platform/src/mcp/modules/evaluate_outcome.py")
    module_path.write_text(evaluate_code, encoding='utf-8')
    
    return {
        "module_created": "evaluate_outcome.py", 
        "path": str(module_path),
        "functions": ["mcp_evaluate_outcome"]
    }


def _create_feedback_loop_module(prd_data: Dict[str, Any]) -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç –º–æ–¥—É–ª—å feedback_loop.py"""
    
    feedback_code = '''"""
MCP Module: Feedback Loop
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–π —É–ª—É—á—à–µ–Ω–Ω–æ–π –≥–∏–ø–æ—Ç–µ–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import json
import time
from pathlib import Path
from typing import Dict, Any
from datetime import datetime


def mcp_feedback_loop(previous_results: Dict[str, Any], improvement_focus: str = "quality") -> Dict[str, Any]:
    """
    MCP –∫–æ–º–∞–Ω–¥–∞: feedback-loop
    –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é —É–ª—É—á—à–µ–Ω–Ω—É—é –≥–∏–ø–æ—Ç–µ–∑—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    start_time = time.time()
    
    result = {
        "command": "mcp-feedback-loop",
        "timestamp": datetime.now().isoformat(),
        "new_hypothesis_generated": False,
        "improvement_focus": improvement_focus,
        "new_hypothesis_id": None,
        "execution_time_ms": 0
    }
    
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        analysis = _analyze_previous_results(previous_results)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—É—é –≥–∏–ø–æ—Ç–µ–∑—É
        new_hypothesis = _generate_improved_hypothesis(analysis, improvement_focus)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—É—é –≥–∏–ø–æ—Ç–µ–∑—É
        hypothesis_path = _save_new_hypothesis(new_hypothesis)
        
        result.update({
            "new_hypothesis_generated": True,
            "new_hypothesis_id": new_hypothesis["hypothesis_id"],
            "hypothesis_path": str(hypothesis_path),
            "improvements": new_hypothesis.get("improvements", [])
        })
        
    except Exception as e:
        result["error"] = str(e)
    
    result["execution_time_ms"] = round((time.time() - start_time) * 1000, 2)
    return result


def _analyze_previous_results(results: Dict[str, Any]) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π"""
    
    return {
        "failed_areas": results.get("deviations", []),
        "success_areas": [],
        "improvement_opportunities": []
    }


def _generate_improved_hypothesis(analysis: Dict[str, Any], focus: str) -> Dict[str, Any]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –≥–∏–ø–æ—Ç–µ–∑—É"""
    
    version = f"v{datetime.now().strftime('%m%d')}"
    
    return {
        "hypothesis_id": f"HYP_{version}_{focus}_{datetime.now().strftime('%d%b%Y')}",
        "title": f"Improved hypothesis focused on {focus}",
        "description": f"Enhanced approach targeting {focus} improvements",
        "based_on_analysis": analysis,
        "target_metrics": {},
        "improvements": [f"Focus on {focus}", "Address previous failures"]
    }


def _save_new_hypothesis(hypothesis: Dict[str, Any]) -> Path:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—É—é –≥–∏–ø–æ—Ç–µ–∑—É"""
    
    hypothesis_path = Path(f"hypothesis_{hypothesis['hypothesis_id'].lower()}.json")
    
    with open(hypothesis_path, 'w', encoding='utf-8') as f:
        json.dump(hypothesis, f, indent=2, ensure_ascii=False)
    
    return hypothesis_path
'''
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª  
    module_path = Path("advising_platform/src/mcp/modules/feedback_loop.py")
    module_path.write_text(feedback_code, encoding='utf-8')
    
    return {
        "module_created": "feedback_loop.py",
        "path": str(module_path), 
        "functions": ["mcp_feedback_loop"]
    }


def execute_implementation_demo():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ feature"""
    
    print("üîß MCP Implement Feature Demo")
    print("=" * 40)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ PRD
    prd_data = {
        "title": "MCP Hypothesis Cycle v1.0",
        "description": "–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –≥–∏–ø–æ—Ç–µ–∑ —Å —Ñ–∞–ª—å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π",
        "requirements": ["register_module", "run_workflow", "report_progress"]
    }
    
    # –†–µ–∞–ª–∏–∑—É–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –º–æ–¥—É–ª–∏
    missing_modules = ["run_tests", "evaluate_outcome", "feedback_loop"]
    
    for module in missing_modules:
        print(f"\nüîß –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—è: {module}")
        result = mcp_implement_feature(prd_data, module)
        
        if result["success"]:
            print(f"‚úÖ {module} —Å–æ–∑–¥–∞–Ω: {result.get('module_created', 'N/A')}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è {module}: {result.get('error', 'Unknown')}")
    
    # –†–µ–∞–ª–∏–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π MCP —Å–µ—Ä–≤–µ—Ä
    print(f"\nüöÄ –†–µ–∞–ª–∏–∑–∞—Ü–∏—è MCP —Å–µ—Ä–≤–µ—Ä–∞...")
    server_result = mcp_implement_feature(prd_data, "mcp_server")
    
    if server_result["success"]:
        print(f"‚úÖ MCP —Å–µ—Ä–≤–µ—Ä: {len(server_result['implemented_modules'])} –º–æ–¥—É–ª–µ–π")
        print(f"üìä Workflow: {len(server_result['workflow_steps'])} —à–∞–≥–æ–≤")
        print(f"‚ö° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏: {len(server_result.get('next_steps_triggered', []))}")
    
    return server_result


if __name__ == "__main__":
    result = execute_implementation_demo()