#!/usr/bin/env python3
"""
–ê–ù–¢–ò-–ü–ò–ó–î–ï–ñ –í–ê–õ–ò–î–ê–¢–û–† v4.0 —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –†–ï–ê–õ–¨–ù–û–°–¢–ò –¥–∞–Ω–Ω—ã—Ö
–ü—Ä–∏–º–µ–Ω—è–µ—Ç –≤—Å–µ CRITICAL ANTI-BULLSHIT CHECKPOINTS –∏–∑ sales-injury standard v1.1
"""

import gspread
from google.oauth2.service_account import Credentials
import json
import logging
import argparse
import sys
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AntiBullshitValidator:
    """
    –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –ø—Ä–æ—Ç–∏–≤ —Å–∞–º–æ–æ–±–º–∞–Ω–∞
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –≤—Å–µ MANDATORY checkpoints –∏–∑ sales-injury standard
    """
    
    def __init__(self):
        self.mandatory_failures = []
        self.critical_errors = []
        
    def validate_data_reality(self, worksheet, tsv_data, column_mappings):
        """
        CHECKPOINT 1: DATA REALITY VALIDATION
        """
        logger.info("üîç CHECKPOINT 1: DATA REALITY VALIDATION")
        
        critical_columns = ['sale_blockers', 'root_cause_5why', 'stop_words_patterns', 'recommended_phrases']
        
        for col_name in critical_columns:
            if col_name not in column_mappings:
                self.mandatory_failures.append(f"Critical column '{col_name}' not found in mapping")
                continue
                
            mapping = column_mappings[col_name]
            sheets_col = mapping['sheets_column']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –†–ï–ê–õ–¨–ù–û–ì–û —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
            empty_count = 0
            content_count = 0
            
            for row_num in range(2, 7):  # rows 2-6
                try:
                    cell_value = worksheet.cell(row_num, sheets_col).value or ""
                    if len(str(cell_value).strip()) >= 10:  # –ú–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤
                        content_count += 1
                        logger.info(f"‚úÖ {col_name} row {row_num}: {len(str(cell_value))} chars")
                    else:
                        empty_count += 1
                        logger.warning(f"‚ùå {col_name} row {row_num}: EMPTY or <10 chars")
                except Exception as e:
                    empty_count += 1
                    logger.error(f"‚ùå {col_name} row {row_num}: ERROR - {e}")
            
            # MANDATORY: –í –ø–µ—Ä–≤—ã—Ö 5 —Å—Ç—Ä–æ–∫–∞—Ö –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
            if content_count < 2:  # –ú–∏–Ω–∏–º—É–º 2 –∏–∑ 5 —Å—Ç—Ä–æ–∫ –¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
                self.mandatory_failures.append(f"CRITICAL: Column '{col_name}' has <2 content rows in first 5 rows")
        
        return len(self.mandatory_failures) == 0
    
    def validate_processor_output(self, tsv_file):
        """
        CHECKPOINT 2: PROCESSOR OUTPUT VALIDATION
        """
        logger.info("üîç CHECKPOINT 2: PROCESSOR OUTPUT VALIDATION")
        
        with open(tsv_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        tsv_data = []
        for line in lines:
            if line.strip():
                row_data = line.strip().split('\t')
                tsv_data.append(row_data)
        
        if len(tsv_data) < 2:
            self.mandatory_failures.append("TSV file has no data rows")
            return False
        
        header = tsv_data[0]
        data_rows = tsv_data[1:]
        
        critical_columns = ['sale blockers', 'root cause 5why', 'stop_words_patterns', 'recommended_phrases']
        
        for col_name in critical_columns:
            col_index = None
            for i, h in enumerate(header):
                if h.strip() == col_name.strip():
                    col_index = i
                    break
            
            if col_index is None:
                self.mandatory_failures.append(f"Column '{col_name}' not found in TSV")
                continue
            
            # –°—á–∏—Ç–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            empty_count = 0
            content_count = 0
            
            for row in data_rows:
                if col_index < len(row):
                    value = row[col_index].strip()
                    if len(value) >= 10:  # –ú–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                        content_count += 1
                    else:
                        empty_count += 1
                else:
                    empty_count += 1
            
            total_rows = len(data_rows)
            empty_percentage = (empty_count / total_rows) * 100
            
            logger.info(f"üìä {col_name}: {content_count} content / {empty_count} empty ({empty_percentage:.1f}% empty)")
            
            # MANDATORY: –ù–µ –±–æ–ª–µ–µ 50% –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫
            if empty_percentage > 50:
                self.mandatory_failures.append(f"CRITICAL: Column '{col_name}' has {empty_percentage:.1f}% empty rows (>50% threshold)")
        
        return len(self.mandatory_failures) == 0
    
    def validate_honest_metrics(self, total_matches, total_expected, visual_reality):
        """
        CHECKPOINT 3: VALIDATOR HONESTY CHECK
        """
        logger.info("üîç CHECKPOINT 3: VALIDATOR HONESTY CHECK")
        
        calculated_percentage = (total_matches / total_expected) * 100 if total_expected > 0 else 0
        
        # MANDATORY: Success rate –¥–æ–ª–∂–µ–Ω –æ—Ç—Ä–∞–∂–∞—Ç—å –†–ï–ê–õ–¨–ù–û–ï –∫–∞—á–µ—Å—Ç–≤–æ
        if calculated_percentage > 90 and visual_reality['has_mostly_empty_columns']:
            self.mandatory_failures.append(f"DISHONEST METRICS: Claiming {calculated_percentage:.1f}% success but visually seeing mostly empty data")
        
        # MANDATORY: –ù–µ —Å—á–∏—Ç–∞–µ–º –ø—É—Å—Ç—ã–µ —è—á–µ–π–∫–∏ –∫–∞–∫ success
        if visual_reality['empty_matches_counted_as_success']:
            self.mandatory_failures.append("DISHONEST VALIDATION: Empty cells counted as successful matches")
        
        return len(self.mandatory_failures) == 0
    
    def final_honesty_reflection(self, spreadsheet_id, worksheet_id):
        """
        CHECKPOINT 4: FINAL HONESTY REFLECTION
        """
        logger.info("üîç CHECKPOINT 4: FINAL HONESTY REFLECTION")
        
        # –≠—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–¥–µ–ª–∞–Ω–æ –ß–ï–õ–û–í–ï–ö–û–ú, –Ω–æ –º—ã –º–æ–∂–µ–º –Ω–∞–ø–æ–º–Ω–∏—Ç—å
        questions = [
            "–î–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ —è –≤–∏–∂—É –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–µ–º —Ñ–∞–π–ª–µ?",
            "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –º–æ–π –∑–∞—è–≤–ª–µ–Ω–Ω—ã–π success rate —Ç–æ–º—É, —á—Ç–æ —è –≤–∏–∑—É–∞–ª—å–Ω–æ –Ω–∞–±–ª—é–¥–∞—é?", 
            "–ú–æ–≥—É –ª–∏ —è –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞?",
            "–ù–µ –æ–±–º–∞–Ω—ã–≤–∞—é –ª–∏ —è —Å–µ–±—è confirmation bias-–æ–º?"
        ]
        
        logger.info("ü§î MANDATORY HONESTY QUESTIONS:")
        for i, question in enumerate(questions, 1):
            logger.info(f"   {i}. {question}")
        
        logger.info(f"üîó –í–ò–ó–£–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê: https://docs.google.com/spreadsheets/d/{spreadsheet_id}/edit#gid={worksheet_id}")
        logger.info("‚ö†Ô∏è  –ë–ï–ó –í–ò–ó–£–ê–õ–¨–ù–û–ô –ü–†–û–í–ï–†–ö–ò –†–ï–ó–£–õ–¨–¢–ê–¢ –ù–ï–î–ï–ô–°–¢–í–ò–¢–ï–õ–ï–ù")
        
        return True  # –≠—Ç–æ—Ç checkpoint —Ç—Ä–µ–±—É–µ—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏

def validate_with_reality_check(spreadsheet_id, worksheet_name, tsv_file, target_columns=None):
    """
    –ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
    """
    
    validator = AntiBullshitValidator()
    
    # DEFAULT TARGET COLUMNS
    if target_columns is None:
        target_columns = [
            "sale_blockers",
            "root_cause_5why", 
            "stop_words_patterns",
            "recommended_phrases"
        ]
    
    try:
        # Authenticate
        with open("advising_platform/config/google_service_account.json", 'r') as f:
            creds_data = json.load(f)
        
        scopes = [
            'https://www.googleapis.com/auth/spreadsheets',
            'https://www.googleapis.com/auth/drive'
        ]
        credentials = Credentials.from_service_account_info(creds_data, scopes=scopes)
        gc = gspread.authorize(credentials)
        
        # Open spreadsheet and find worksheet BY NAME
        sheet = gc.open_by_key(spreadsheet_id)
        target_worksheet = None
        
        for ws in sheet.worksheets():
            if ws.title.strip() == worksheet_name.strip():
                target_worksheet = ws
                break
        
        if not target_worksheet:
            logger.error(f"‚ùå Worksheet '{worksheet_name}' not found")
            return False
        
        logger.info(f"‚úÖ Found worksheet: {worksheet_name}")
        
        # Get Google Sheets header
        sheets_header = target_worksheet.row_values(1)
        
        # Build column mappings
        column_mappings = {}
        for target_col in target_columns:
            sheets_column = None
            for i, header in enumerate(sheets_header):
                if header.strip().lower() == target_col.strip().lower():
                    sheets_column = i + 1  # 1-based for gspread
                    break
            
            if sheets_column:
                column_mappings[target_col] = {
                    'sheets_column': sheets_column
                }
        
        # CHECKPOINT 1: DATA REALITY VALIDATION
        reality_check_passed = validator.validate_data_reality(target_worksheet, None, column_mappings)
        
        # CHECKPOINT 2: PROCESSOR OUTPUT VALIDATION  
        processor_check_passed = validator.validate_processor_output(tsv_file)
        
        # CHECKPOINT 3: VALIDATOR HONESTY CHECK (simplified)
        visual_reality = {
            'has_mostly_empty_columns': len(validator.mandatory_failures) > 0,
            'empty_matches_counted_as_success': False  # Would need more complex logic
        }
        honesty_check_passed = validator.validate_honest_metrics(0, 0, visual_reality)
        
        # CHECKPOINT 4: FINAL HONESTY REFLECTION
        reflection_completed = validator.final_honesty_reflection(spreadsheet_id, target_worksheet.id)
        
        # FINAL RESULT
        all_mandatory_passed = (
            reality_check_passed and 
            processor_check_passed and 
            honesty_check_passed and
            reflection_completed
        )
        
        logger.info("")
        logger.info("=" * 70)
        logger.info("üö® ANTI-BULLSHIT VALIDATION SUMMARY")
        logger.info("=" * 70)
        
        logger.info(f"CHECKPOINT 1 - Data Reality: {'‚úÖ PASSED' if reality_check_passed else '‚ùå FAILED'}")
        logger.info(f"CHECKPOINT 2 - Processor Output: {'‚úÖ PASSED' if processor_check_passed else '‚ùå FAILED'}")
        logger.info(f"CHECKPOINT 3 - Honest Metrics: {'‚úÖ PASSED' if honesty_check_passed else '‚ùå FAILED'}")
        logger.info(f"CHECKPOINT 4 - Final Reflection: {'ü§î REQUIRES HUMAN VERIFICATION' if reflection_completed else '‚ùå FAILED'}")
        
        if validator.mandatory_failures:
            logger.error("üí• MANDATORY FAILURES:")
            for failure in validator.mandatory_failures:
                logger.error(f"   ‚ùå {failure}")
        
        if all_mandatory_passed and not validator.mandatory_failures:
            logger.info("Status: ‚úÖ REALITY CHECK PASSED")
            logger.info("‚ö†Ô∏è  –í–ò–ó–£–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –í–°–ï –ï–©–ï –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê!")
            return True
        else:
            logger.error("Status: ‚ùå REALITY CHECK FAILED - –ë–†–ê–ö –û–ë–ù–ê–†–£–ñ–ï–ù")
            logger.error("üõë AUTOMATIC REJECTION - –ù–ï –î–û–°–¢–ê–í–õ–Ø–¢–¨ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Æ")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå Reality check failed: {e}")
        return False

def main():
    """Main function with reality check validation"""
    parser = argparse.ArgumentParser(description="–ê–Ω—Ç–∏-–ø–∏–∑–¥–µ–∂ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö")
    parser.add_argument("--spreadsheet-id", required=True, help="ID Google Sheets –¥–æ–∫—É–º–µ–Ω—Ç–∞")
    parser.add_argument("--worksheet-name", required=True, help="–ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞")
    parser.add_argument("--tsv-file", required=True, help="–ü—É—Ç—å –∫ TSV —Ñ–∞–π–ª—É")
    parser.add_argument("--columns", nargs='+', help="–°–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
    
    args = parser.parse_args()
    
    success = validate_with_reality_check(
        spreadsheet_id=args.spreadsheet_id,
        worksheet_name=args.worksheet_name,
        tsv_file=args.tsv_file,
        target_columns=args.columns
    )
    
    if success:
        logger.info("üéâ ANTI-BULLSHIT VALIDATION PASSED")
        logger.info("‚ö†Ô∏è  –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê –í–ò–ó–£–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –ó–ê–Ø–í–õ–ï–ù–ò–ï–ú –û –£–°–ü–ï–•–ï")
        sys.exit(0)
    else:
        logger.error("üí• ANTI-BULLSHIT VALIDATION FAILED")
        logger.error("üõë –ü–†–û–î–£–ö–¢ –ó–ê–ë–†–ê–ö–û–í–ê–ù - –ù–ï –î–û–°–¢–ê–í–õ–Ø–¢–¨")
        sys.exit(1)

if __name__ == "__main__":
    main()