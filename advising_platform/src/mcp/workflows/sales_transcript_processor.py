#!/usr/bin/env python3
"""
Sales JTBD Transcript Analysis MCP Workflow
Based on: [standards .md]/6. advising ¬∑ review ¬∑ supervising/ü§ù sales-injury-jtbd-standard.md
Implementation of: sales-injury-jtbd-standard for processing call transcripts
"""

import time
import logging
import pandas as pd
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

# STEP 0: Standard —á–∏—Ç–∞–µ—Ç—Å—è –ø–µ—Ä–≤—ã–º —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é MCP workflow
STANDARD_PATH = "[standards .md]/6. advising ¬∑ review ¬∑ supervising/ü§ù sales-injury-jtbd-standard.md"
TSV_DATA_PATH = "[rick.ai] clients/avtoall.ru/[4] whatsapp-jtbd-tracktion/raw/HeroesGPT JTBD. avtoall.ru - call_transcriptions_all 17.07.tsv"

@dataclass
class SalesAnalysisResult:
    """
    JTBD: –ö–æ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –ø—Ä–æ–¥–∞–∂,
    –Ω—É–∂–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞,
    —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å consistent –æ–±—Ä–∞–±–æ—Ç–∫—É –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è Google Docs
    """
    transcript: str  # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
    lead_inquiry: str  # –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞
    root_cause_5why: str  # —á—Ç–æ —Å–µ–∏–ª–∑ –Ω–µ —Ç–∞–∫ —Å–¥–µ–ª–∞–ª, —á—Ç–æ –ø—Ä–æ–¥–∞–∂–∞ –Ω–µ —Å–ª—É—á–∏–ª–∞—Å—å
    sales_blockers: str  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏—è –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è —Å–¥–µ–ª–∫–∏
    segment: str  # B2B/B2C
    stop_words: str  # "–∫–∞–∫ –Ω–µ –Ω—É–∂–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç—å, —á—Ç–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞"
    power_words: str  # "–∫–∞–∫ —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã –≥–æ–≤–æ—Ä–∏–ª–∏" 
    understanding_criteria: str  # "–≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –∫–∞–∂–¥–æ–π —Å—Ç–∞–¥–∏–∏, —á—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å –∫–ª–∏–µ–Ω—Ç"
    when_trigger: str  # "when —Å–∏—Ç—É–∞—Ü–∏—è –≤ big_jtbd"
    big_jtbd: str
    medium_jtbd: str
    small_jtbd: str
    qualified_triggers: str  # —Å—Ä–æ—á–Ω–æ—Å—Ç—å, –±—é–¥–∂–µ—Ç, –∫–∞—á–µ—Å—Ç–≤–æ
    processing_time: float
    validation_passed: bool = False
    quality_score: float = 0.0

@dataclass 
class BatchSalesResults:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç—ã batch –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ø–∞—Ç—Ç–µ—Ä–Ω-–∞–Ω–∞–ª–∏–∑–æ–º"""
    individual_results: List[SalesAnalysisResult]
    patterns: Dict[str, Any]
    training_materials: Dict[str, List[str]]
    implementation_roadmap: Dict[str, Any]
    total_processing_time: float
    success_rate: float
    output_tsv_path: str

class SalesReflectionValidator:
    """
    JTBD: –ö–æ–≥–¥–∞ –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω,
    –Ω—É–∂–Ω–æ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞,
    —á—Ç–æ–±—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å 90%+ pass rate —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
    
    ENHANCED v4.0: –î–æ–±–∞–≤–ª–µ–Ω—ã ANTI-BULLSHIT CHECKPOINTS –∏–∑ sales-injury standard v1.1
    """
    
    @staticmethod
    def validate_analysis(result: SalesAnalysisResult) -> tuple[bool, float, Dict[str, str]]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ reflection checkpoints + ANTI-BULLSHIT –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        validation_issues = {}
        score = 0.0
        max_score = 100.0
        
        # CRITICAL ANTI-BULLSHIT CHECKPOINTS (MANDATORY BEFORE ANY OTHER VALIDATION)
        critical_failures = []
        
        # CHECKPOINT 2: PROCESSOR OUTPUT VALIDATION
        critical_columns = {
            'sales_blockers': result.sales_blockers,
            'root_cause_5why': result.root_cause_5why,
            'stop_words': result.stop_words if hasattr(result, 'stop_words') else None,
            'power_words': result.power_words if hasattr(result, 'power_words') else None
        }
        
        for col_name, col_value in critical_columns.items():
            if not col_value or len(str(col_value).strip()) < 10:
                critical_failures.append(f"MANDATORY FAIL: {col_name} has <10 characters - not real analysis")
            elif str(col_value).strip() in ["", "N/A", "None", "null", "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ", "—Ç—Ä–µ–±—É–µ—Ç—Å—è AI"]:
                critical_failures.append(f"MANDATORY FAIL: {col_name} contains placeholder/empty data")
        
        # AUTOMATIC REJECTION if critical failures
        if critical_failures:
            return False, 0.0, {
                "anti_bullshit_status": "FAILED - AUTOMATIC REJECTION",
                "critical_failures": critical_failures,
                "rejection_reason": "Generated empty/placeholder data instead of real analysis"
            }
        
        # Original validation logic (only if critical checks pass)
        # 1. Root Cause Analysis validation (20 points)
        if result.root_cause_5why and len(result.root_cause_5why.split("Why #")) >= 5:
            score += 20
        else:
            validation_issues["5why"] = "–ù–µ–ø–æ–ª–Ω–∞—è 5-why —Ü–µ–ø–æ—á–∫–∞ –ø—Ä–∏—á–∏–Ω"
            
        # 2. Sales Blockers validation (15 points)  
        if result.sales_blockers and len(result.sales_blockers) > 50:
            score += 15
        else:
            validation_issues["blockers"] = "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã sales blockers"
            
        # 3. Communication Pattern Analysis (20 points)
        if result.stop_words and result.power_words:
            score += 20
        else:
            validation_issues["communication"] = "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–º–µ—Ä—ã stop/power words"
            
        # 4. JTBD Hierarchy validation (25 points)
        if all([result.when_trigger, result.big_jtbd, result.medium_jtbd, result.small_jtbd]):
            score += 25
        else:
            validation_issues["jtbd"] = "–ù–µ–ø–æ–ª–Ω–∞—è JTBD –∏–µ—Ä–∞—Ä—Ö–∏—è"
            
        # 5. Decision Journey mapping (20 points)
        if result.understanding_criteria and result.segment in ["B2B", "B2C"]:
            score += 20
        else:
            validation_issues["journey"] = "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç decision journey mapping"
            
        result.quality_score = score
        result.validation_passed = score >= 90.0
        
        return result.validation_passed, score, validation_issues

class SalesBlockersAnalyzer:
    """
    JTBD: –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –≤—ã—è–≤–∏—Ç—å –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏—è –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è —Å–¥–µ–ª–∫–∏,
    –Ω—É–∂–µ–Ω –∞–Ω–∞–ª–∏–∑ –ø–æ —Å—Ç–∞–¥–∏—è–º –ø—Ä–æ–¥–∞–∂,
    —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–æ—á–∫–∏ —É—Ç–µ—á–∫–∏ conversion
    """
    
    SALES_STAGES = [
        "–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞",
        "—É—Ç–æ—á–Ω–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π",
        "–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ –Ω–∞–ª–∏—á–∏–∏", 
        "–ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–≤–µ—Ä–∏—è",
        "–ø–æ–¥–±–æ—Ä –ø—Ä–æ–¥—É–∫—Ç–∞",
        "–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
        "–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–π",
        "–∑–∞–∫—Ä—ã—Ç–∏–µ —Å–¥–µ–ª–∫–∏"
    ]
    
    @staticmethod
    def analyze_blockers(transcript: str, lead_inquiry: str) -> str:
        """5-why –∞–Ω–∞–ª–∏–∑ —á—Ç–æ —Å–µ–∏–ª–∑ –Ω–µ —Ç–∞–∫ —Å–¥–µ–ª–∞–ª"""
        # Simplified implementation - –≤ production –±—É–¥–µ—Ç AI analysis
        blockers = []
        
        if "–Ω–µ—Ç" in transcript.lower() and "–µ—Å—Ç—å" not in transcript.lower():
            blockers.append("–ù–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Ç–æ–≤–∞—Ä–∞")
            
        if "–¥–∞–ª–µ–∫–æ" in transcript.lower() or "–¥–∞–ª–µ–∫–∏–π" in transcript.lower():
            blockers.append("–ù–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –¥–æ—Å—Ç–∞–≤–∫—É –∏–ª–∏ —É–¥–æ–±–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–ª—É—á–µ–Ω–∏—è")
            
        if "–¥–æ—Ä–æ–≥–æ" in transcript.lower() or "—Ü–µ–Ω–∞" in transcript.lower():
            blockers.append("–ù–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª —Ü–µ–Ω–æ–≤—ã–µ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è")
            
        return "; ".join(blockers) if blockers else "–ë–ª–æ–∫–µ—Ä—ã –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã"

class CommunicationPatternAnalyzer:
    """
    JTBD: –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—é –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤,
    –Ω—É–∂–µ–Ω –∞–Ω–∞–ª–∏–∑ —Å—Ç–æ–ø-—Å–ª–æ–≤ vs power words,
    —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å training materials –¥–ª—è –∫–æ–º–∞–Ω–¥—ã
    """
    
    @staticmethod
    def extract_stop_words(transcript: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —Ñ—Ä–∞–∑"""
        stop_patterns = [
            "–Ω–µ –∑–Ω–∞—é",
            "–≥–¥–µ-—Ç–æ",
            "–º–æ–∂–µ—Ç –±—ã—Ç—å",
            "–Ω–∞–≤–µ—Ä–Ω–æ–µ",
            "—ç—Ç–æ –≤—Å–µ –¥–∞–ª–µ–∫–æ",
            "—Ç–∞–∫–æ–π —É–∂–µ –Ω–µ—Ç"
        ]
        
        found_patterns = []
        for pattern in stop_patterns:
            if pattern in transcript.lower():
                found_patterns.append(f'"{pattern}"')
                
        return "; ".join(found_patterns) if found_patterns else "–°—Ç–æ–ø-—Å–ª–æ–≤–∞ –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã"
    
    @staticmethod
    def generate_power_words(stop_words: str, lead_inquiry: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤"""
        if "–Ω–µ –∑–Ω–∞—é" in stop_words:
            return "–î–∞–≤–∞–π—Ç–µ —É—Ç–æ—á–Ω–∏–º –¥–µ—Ç–∞–ª–∏, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç"
        elif "–¥–∞–ª–µ–∫–æ" in stop_words:
            return "–ü–æ–Ω–∏–º–∞—é –≤–∞—à–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —É–¥–æ–±—Å—Ç–≤—É. –ü—Ä–µ–¥–ª–∞–≥–∞—é –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–æ–ª—É—á–µ–Ω–∏—è"
        elif "–Ω–µ—Ç" in stop_words:
            return "–ï—Å—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è —Å –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏"
        
        return "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ —Ä–µ—à–µ–Ω–∏—è"

class JTBDHierarchyConstructor:
    """
    JTBD: –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—é Big/Medium/Small JTBD,
    –Ω—É–∂–Ω–∞ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—è–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏,
    —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å –∏—Å—Ç–∏–Ω–Ω—ã–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–∞
    """
    
    @staticmethod
    def construct_hierarchy(transcript: str, lead_inquiry: str, segment: str) -> Dict[str, str]:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ 4-—É—Ä–æ–≤–Ω–µ–≤–æ–π JTBD —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        
        # When Trigger –∞–Ω–∞–ª–∏–∑
        when_trigger = "–∫–æ–≥–¥–∞ –∫–ª–∏–µ–Ω—Ç —Å—Ç–∞–ª–∫–∏–≤–∞–µ—Ç—Å—è —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å—é —Ä–µ—à–∏—Ç—å –ø—Ä–æ–±–ª–µ–º—É"
        if "—Å—Ä–æ—á–Ω–æ" in transcript.lower() or "–∑–∞–≤—Ç—Ä–∞" in transcript.lower():
            when_trigger = "–∫–æ–≥–¥–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å—Ä–æ—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º"
            
        # Big JTBD –ø–æ —Å–µ–≥–º–µ–Ω—Ç—É
        if segment == "B2B":
            big_jtbd = "–æ–±–µ—Å–ø–µ—á–∏—Ç—å –±–µ—Å–ø–µ—Ä–µ–±–æ–π–Ω—É—é —Ä–∞–±–æ—Ç—É –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤"
        else:
            big_jtbd = "–±—ã—Å—Ç—Ä–æ —Ä–µ—à–∏—Ç—å –ª–∏—á–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ —É—Å–∏–ª–∏—è–º–∏"
            
        # Medium JTBD - —Ç–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å
        medium_jtbd = "–Ω–∞–π—Ç–∏ –∏ –ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏ –Ω—É–∂–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞"
        
        # Small JTBD - –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å  
        small_jtbd = "–ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é, —É–∑–Ω–∞—Ç—å —Ü–µ–Ω—É –∏ —Å–ø–æ—Å–æ–±—ã –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞"
        
        # Qualified Triggers
        qualified_triggers = "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞—á–µ—Å—Ç–≤—É –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏"
        if "–¥–æ—Ä–æ–≥–æ" in transcript.lower():
            qualified_triggers += "; –±—é–¥–∂–µ—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è"
        if "—Å—Ä–æ—á–Ω–æ" in transcript.lower():
            qualified_triggers += "; –≤—ã—Å–æ–∫–∞—è —Å—Ä–æ—á–Ω–æ—Å—Ç—å"
            
        return {
            "when_trigger": when_trigger,
            "big_jtbd": big_jtbd, 
            "medium_jtbd": medium_jtbd,
            "small_jtbd": small_jtbd,
            "qualified_triggers": qualified_triggers
        }

class DecisionJourneyMapper:
    """
    JTBD: –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å decision journey,
    –Ω—É–∂–Ω–æ mapping –ø–æ 8 —Å—Ç–∞–¥–∏—è–º B2C/B2B,
    —á—Ç–æ–±—ã –≤—ã—è–≤–∏—Ç—å gaps –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è
    """
    
    B2C_STAGES = [
        "Problem Recognition", "Solution Possibility", "Personal Relevance",
        "Feasibility", "Social Validation", "Risk Evaluation", "Urgency", "Action Simplification"
    ]
    
    B2B_STAGES = [
        "Business Impact", "Solution-Problem Fit", "Internal Champion", 
        "Stakeholder Alignment", "Risk Mitigation", "Budget Justification",
        "Implementation", "Vendor Reliability"
    ]
    
    @staticmethod
    def map_understanding_criteria(transcript: str, segment: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–∞–¥–∏–∏"""
        
        criteria = []
        
        if segment == "B2C":
            stages = DecisionJourneyMapper.B2C_STAGES
            if "–ø–æ–Ω—è–ª" in transcript.lower():
                criteria.append("Problem Recognition: –∫–ª–∏–µ–Ω—Ç —á—É–≤—Å—Ç–≤—É–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã")
            if "–ø–æ–¥—Ö–æ–¥–∏—Ç" in transcript.lower():
                criteria.append("Personal Relevance: –∫–ª–∏–µ–Ω—Ç –≤–∏–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏—è")
            if "—Ü–µ–Ω–∞" in transcript.lower():
                criteria.append("Feasibility: –∫–ª–∏–µ–Ω—Ç –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—É—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å")
        else:
            stages = DecisionJourneyMapper.B2B_STAGES
            if "–±–∏–∑–Ω–µ—Å" in transcript.lower():
                criteria.append("Business Impact: –ø–æ–Ω–∏–º–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –Ω–∞ –±–∏–∑–Ω–µ—Å")
            if "–∫–∞—á–µ—Å—Ç–≤–æ" in transcript.lower():
                criteria.append("Risk Mitigation: –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞")
                
        return "; ".join(criteria) if criteria else "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏"

class SalesTranscriptProcessor:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤ –ø—Ä–æ–¥–∞–∂
    
    JTBD: –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å 600+ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤ –∑–≤–æ–Ω–∫–æ–≤,
    –Ω—É–∂–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π pipeline —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º,
    —á—Ç–æ–±—ã —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å 30-45 –º–∏–Ω –¥–æ ‚â§5 –º–∏–Ω –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å —á—Ç–µ–Ω–∏–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ (STEP 0)"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        self.standard_config = self._load_standard_config()
        self.validator = SalesReflectionValidator()
        self.blockers_analyzer = SalesBlockersAnalyzer()
        self.communication_analyzer = CommunicationPatternAnalyzer()
        self.jtbd_constructor = JTBDHierarchyConstructor()
        self.journey_mapper = DecisionJourneyMapper()
        
    def _load_standard_config(self) -> Dict[str, Any]:
        """STEP 0: –ß—Ç–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–≤—ã–π —à–∞–≥)"""
        config = {
            'processing_time_limit': 45 * 60,  # 45 minutes max
            'batch_size': 10,
            'quality_threshold': 90.0,
            'reflection_checkpoints': True
        }
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç
        if os.path.exists(STANDARD_PATH):
            self.logger.info(f"‚úÖ Standard loaded from: {STANDARD_PATH}")
            # –í production –∑–¥–µ—Å—å –±—É–¥–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
        else:
            self.logger.warning(f"Standard not found at {STANDARD_PATH}, using defaults")
            
        return config
    
    def process_single_transcript(self, row: pd.Series) -> SalesAnalysisResult:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å–æ–≥–ª–∞—Å–Ω–æ 6-—ç—Ç–∞–ø–Ω–æ–º—É workflow –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
        
        JTBD: –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∑–≤–æ–Ω–æ–∫,
        –Ω—É–∂–µ–Ω systematic approach –ø–æ –≤—Å–µ–º —ç—Ç–∞–ø–∞–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞,
        —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å complete analysis –¥–ª—è Google Docs —Ç–∞–±–ª–∏—Ü—ã
        """
        start_time = time.time()
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        transcript = str(row.get('transcript', ''))
        lead_inquiry = str(row.get('lead_inquiry', ''))
        
        # 1Ô∏è‚É£ Root Cause Analysis (5-Why)
        root_cause_5why = self._perform_5why_analysis(transcript, lead_inquiry)
        
        # 2Ô∏è‚É£ Sales Blockers Identification  
        sales_blockers = self.blockers_analyzer.analyze_blockers(transcript, lead_inquiry)
        
        # 3Ô∏è‚É£ Communication Pattern Analysis
        stop_words = self.communication_analyzer.extract_stop_words(transcript)
        power_words = self.communication_analyzer.generate_power_words(stop_words, lead_inquiry)
        
        # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        segment = "B2B" if any(word in transcript.lower() for word in ["–±–∏–∑–Ω–µ—Å", "–ø–∞—Ä–∫", "—Ñ–ª–æ—Ç"]) else "B2C"
        
        # 4Ô∏è‚É£ JTBD Hierarchy Construction
        jtbd_hierarchy = self.jtbd_constructor.construct_hierarchy(transcript, lead_inquiry, segment)
        
        # 5Ô∏è‚É£ Decision Journey Stage Mapping
        understanding_criteria = self.journey_mapper.map_understanding_criteria(transcript, segment)
        
        processing_time = time.time() - start_time
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = SalesAnalysisResult(
            transcript=transcript,
            lead_inquiry=lead_inquiry,
            root_cause_5why=root_cause_5why,
            sales_blockers=sales_blockers,
            segment=segment,
            stop_words=stop_words,
            power_words=power_words,
            understanding_criteria=understanding_criteria,
            when_trigger=jtbd_hierarchy["when_trigger"],
            big_jtbd=jtbd_hierarchy["big_jtbd"],
            medium_jtbd=jtbd_hierarchy["medium_jtbd"],
            small_jtbd=jtbd_hierarchy["small_jtbd"],
            qualified_triggers=jtbd_hierarchy["qualified_triggers"],
            processing_time=processing_time
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        self.validator.validate_analysis(result)
        
        return result
    
    def _perform_5why_analysis(self, transcript: str, lead_inquiry: str) -> str:
        """5-why –∞–Ω–∞–ª–∏–∑ —á—Ç–æ —Å–µ–∏–ª–∑ –Ω–µ —Ç–∞–∫ —Å–¥–µ–ª–∞–ª"""
        why_chain = []
        
        # Why #1: Surface problem
        if "–Ω–µ –∫—É–ø–∏–ª" in transcript.lower() or not any(word in transcript.lower() for word in ["–∑–∞–∫–∞–∑", "–ø–æ–∫—É–ø–∞—é", "–±–µ—Ä—É"]):
            why_chain.append("Why #1: –ü–æ—á–µ–º—É –∫–ª–∏–µ–Ω—Ç –Ω–µ —Å–æ–≤–µ—Ä—à–∏–ª –ø–æ–∫—É–ø–∫—É? ‚Üí –ù–µ –ø–æ–ª—É—á–∏–ª –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        
        # Why #2: Process limitation  
        if "–Ω–µ—Ç" in transcript.lower():
            why_chain.append("Why #2: –ü–æ—á–µ–º—É –Ω–µ –ø–æ–ª—É—á–∏–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è? ‚Üí –û–ø–µ—Ä–∞—Ç–æ—Ä —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–ª—Å—è –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏, –∞ –Ω–µ –Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞—Ö")
        
        # Why #3: UX gap
        if "–¥–∞–ª–µ–∫–æ" in transcript.lower():
            why_chain.append("Why #3: –ü–æ—á–µ–º—É –Ω–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã? ‚Üí –ù–µ –≤—ã—è—Å–Ω–∏–ª –∫—Ä–∏—Ç–µ—Ä–∏–∏ —É–¥–æ–±—Å—Ç–≤–∞ –∫–ª–∏–µ–Ω—Ç–∞")
            
        # Why #4: Information architecture
        if len(why_chain) > 2:
            why_chain.append("Why #4: –ü–æ—á–µ–º—É –Ω–µ –≤—ã—è—Å–Ω–∏–ª –∫—Ä–∏—Ç–µ—Ä–∏–∏? ‚Üí –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ qualification –≤–æ–ø—Ä–æ—Å–æ–≤")
            
        # Why #5: Root cause
        if len(why_chain) > 3:
            why_chain.append("Why #5: –ü–æ—á–µ–º—É –Ω–µ—Ç –ø—Ä–æ—Ü–µ–¥—É—Ä—ã? ‚Üí –û–ø–µ—Ä–∞—Ç–æ—Ä—ã –Ω–µ –æ–±—É—á–µ–Ω—ã consultative selling –ø–æ–¥—Ö–æ–¥—É")
        
        return "\n".join(why_chain) if why_chain else "5-why –∞–Ω–∞–ª–∏–∑: —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã"
    
    def process_tsv_batch(self, tsv_path: str, output_path: str = None) -> BatchSalesResults:
        """
        Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ TSV —Ñ–∞–π–ª–∞ —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º Google Docs ready —Ç–∞–±–ª–∏—Ü—ã
        
        JTBD: –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–ª–Ω—É—é TSV —Ç–∞–±–ª–∏—Ü—É,
        –Ω—É–∂–µ–Ω parallel processing —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π,
        —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –≥–æ—Ç–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Docs
        """
        start_time = time.time()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        if not os.path.exists(tsv_path):
            self.logger.error(f"TSV file not found: {tsv_path}")
            return None
            
        df = pd.read_csv(tsv_path, sep='\t')
        self.logger.info(f"Loaded {len(df)} rows from {tsv_path}")
        
        # Parallel processing
        results = []
        batch_size = self.standard_config['batch_size']
        
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = []
            
            for index, row in df.iterrows():
                future = executor.submit(self.process_single_transcript, row)
                futures.append(future)
                
                # Process in batches
                if len(futures) >= batch_size:
                    for future in as_completed(futures):
                        try:
                            result = future.result(timeout=300)  # 5 min timeout
                            results.append(result)
                        except Exception as e:
                            self.logger.error(f"Processing failed: {e}")
                    futures = []
            
            # Process remaining
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=300)
                    results.append(result)
                except Exception as e:
                    self.logger.error(f"Processing failed: {e}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ output TSV –¥–ª—è Google Docs
        output_df = self._create_output_tsv(results)
        
        if output_path is None:
            output_path = tsv_path.replace('.tsv', '_analyzed.tsv')
        
        output_df.to_csv(output_path, sep='\t', index=False, encoding='utf-8')
        
        total_time = time.time() - start_time
        success_rate = sum(1 for r in results if r.validation_passed) / len(results) if results else 0
        
        self.logger.info(f"‚úÖ Batch processing complete:")
        self.logger.info(f"   Processed: {len(results)} transcripts")
        self.logger.info(f"   Success rate: {success_rate:.1%}")
        self.logger.info(f"   Total time: {total_time/60:.1f} minutes")
        self.logger.info(f"   Output saved: {output_path}")
        
        return BatchSalesResults(
            individual_results=results,
            patterns={},
            training_materials={},
            implementation_roadmap={},
            total_processing_time=total_time,
            success_rate=success_rate,
            output_tsv_path=output_path
        )
    
    def _create_output_tsv(self, results: List[SalesAnalysisResult]) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ TSV —Ç–∞–±–ª–∏—Ü—ã –≥–æ—Ç–æ–≤–æ–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Docs
        –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç column mapping –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
        """
        
        output_data = []
        
        for result in results:
            row = {
                'transcript': result.transcript,
                'lead_inquiry': result.lead_inquiry,
                'root cause 5why': result.root_cause_5why,
                'sales_blockers': result.sales_blockers,
                'segment': result.segment,
                '–∫–∞–∫ –Ω–µ –Ω—É–∂–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç—å, —á—Ç–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞': result.stop_words,
                '–∫–∞–∫ —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã –≥–æ–≤–æ—Ä–∏–ª–∏': result.power_words,
                '–≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –∫–∞–∂–¥–æ–π —Å—Ç–∞–¥–∏–∏, —á—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å –∫–ª–∏–µ–Ω—Ç': result.understanding_criteria,
                'when —Å–∏—Ç—É–∞—Ü–∏—è –≤ big_jtbd': result.when_trigger,
                'big_jtbd': result.big_jtbd,
                'medium_jtbd': result.medium_jtbd,
                'small_jtbd': result.small_jtbd,
                'qualified_triggers': result.qualified_triggers,
                'processing_time_sec': round(result.processing_time, 2),
                'quality_score': round(result.quality_score, 1),
                'validation_passed': result.validation_passed
            }
            output_data.append(row)
        
        return pd.DataFrame(output_data)

# MCP Integration Functions
def mcp_process_sales_transcripts(tsv_path: str = None, output_path: str = None) -> Dict[str, Any]:
    """
    MCP-compatible function –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å HTTP adapter
    
    JTBD: –ö–æ–≥–¥–∞ MCP —Å–∏—Å—Ç–µ–º–∞ –≤—ã–∑—ã–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤,
    –Ω—É–∂–µ–Ω standardized interface —Å error handling,
    —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –Ω–∞–¥–µ–∂–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å workflow orchestration
    """
    
    processor = SalesTranscriptProcessor()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º default path –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
    if tsv_path is None:
        tsv_path = TSV_DATA_PATH
    
    try:
        results = processor.process_tsv_batch(tsv_path, output_path)
        
        return {
            "status": "success",
            "processed_count": len(results.individual_results),
            "success_rate": results.success_rate,
            "processing_time_minutes": results.total_processing_time / 60,
            "output_file": results.output_tsv_path,
            "ready_for_google_docs": True,
            "quality_metrics": {
                "average_score": sum(r.quality_score for r in results.individual_results) / len(results.individual_results),
                "validation_pass_rate": results.success_rate
            }
        }
    
    except Exception as e:
        return {
            "status": "error",
            "error_message": str(e),
            "ready_for_google_docs": False
        }

if __name__ == "__main__":
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫
    processor = SalesTranscriptProcessor()
    print("üéØ Sales Transcript Processor initialized")
    print("üìä Ready for MCP workflow integration")
    print(f"üìã Standard: {STANDARD_PATH}")
    print(f"üìÅ Data source: {TSV_DATA_PATH}")
    
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    # results = processor.process_tsv_batch(TSV_DATA_PATH)
    # print(f"‚úÖ Processed {len(results.individual_results)} transcripts")
    # print(f"üìà Success rate: {results.success_rate:.1%}")