#!/usr/bin/env python3
"""
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞—É–¥–∏—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∏ —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π,
–ø–æ–∑–≤–æ–ª—è—è –≤—ã—è–≤–∏—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∏ –ø—Ä–æ–±–ª–µ–º—ã –≤ –∞–ª–≥–æ—Ä–∏—Ç–º–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.
"""

import os
import re
import sys
import json
import csv
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
ROOT_DIR = Path(__file__).parent.parent.parent.parent.parent

# –ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
STANDARDS_DIR = ROOT_DIR / "[standards .md]"
TASKS_DIR = ROOT_DIR / "[todo ¬∑ incidents]"

# –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
# –ë–æ–ª–µ–µ —Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ TaskMaster
DOCUMENT_CRITERIA = {
    "standard": {
        "required_sections": ["–û–ø–∏—Å–∞–Ω–∏–µ", "–¶–µ–ª–∏", "–ü—Ä–æ—Ü–µ–¥—É—Ä–∞"],
        "required_metadata": ["–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä", "–í–µ—Ä—Å–∏—è", "–°—Ç–∞—Ç—É—Å", "–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"],
        "title_patterns": [r"–°—Ç–∞–Ω–¥–∞—Ä—Ç", r"Standard"],
        "content_patterns": [
            r"status:\s*(Active|–ê–∫—Ç–∏–≤–µ–Ω|–î–µ–π—Å—Ç–≤—É—é—â–∏–π)",
            r"version:\s*\d+\.\d+",
            r"updated:\s*\d{1,2}\s+\w+\s+\d{4}",
            r"based on:\s*.*?Standard"
        ],
        "path_patterns": [r"standards\.md", r"standard[s]?/", r"standard[s]?\."]
    },
    "task": {
        "required_sections": ["–°–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è", "–ê—Ä—Ö–∏–≤ –∑–∞–¥–∞—á"],
        "required_metadata": [],
        "title_patterns": [r"ToDo", r"Todo", r"–ó–∞–¥–∞—á[–∞–∏]"],
        "content_patterns": [
            r"^\s*#{1,3}\s+(?:üîú|üìã)\s+.*(?:ToDo|Todo|–°–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è|–ó–∞–¥–∞—á–∏)",
            r"\[(?:alarm|asap|blocker|research|small task|exciter)\]"
        ],
        "path_patterns": [r"todo", r"task[s]?/", r"task[s]?\."]
    },
    "incident": {
        "required_sections": ["–û–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞", "–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è", "–†–µ—à–µ–Ω–∏–µ"],
        "required_metadata": [],
        "title_patterns": [r"–ò–Ω—Ü–∏–¥–µ–Ω—Ç", r"Incident"],
        "content_patterns": [
            r"^\s*#{1,3}\s+(?:üö®|üîç)\s+.*(?:–ò–Ω—Ü–∏–¥–µ–Ω—Ç|Incident)",
            r"^\s*#{1,3}\s+(?:‚ùå|üßë‚Äçüîß)\s+.*(?:–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è|–ö–æ—Ä–Ω–µ–≤—ã–µ –ø—Ä–∏—á–∏–Ω—ã)"
        ],
        "path_patterns": [r"incident[s]?/", r"incident[s]?\."]
    }
}

# –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞
ARCHIVE_CRITERIA = {
    "path_patterns": [r"archive", r"–∞—Ä—Ö–∏–≤"],
    "content_patterns": [
        r"(?:status|—Å—Ç–∞—Ç—É—Å):\s*(?:Archived|–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω|–ù–µ–∞–∫—Ç–∏–≤–µ–Ω)",
        r"–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ",
        r"^\s*#{1,3}\s+.*?(?:–ê—Ä—Ö–∏–≤)"
    ]
}

def extract_document_metadata(content):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    
    Args:
        content (str): –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    """
    metadata = {}
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    title_match = re.search(r"^\s*#\s+(.*?)$", content, re.MULTILINE)
    if title_match:
        metadata["title"] = title_match.group(1).strip()
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ key: value
    metadata_pattern = r"^\s*(?:\*\*)?([A-Za-z–ê-–Ø–∞-—è][A-Za-z–ê-–Ø–∞-—è\s]+?)(?:\*\*)?\s*:\s*(.+?)$"
    for match in re.finditer(metadata_pattern, content, re.MULTILINE):
        key = match.group(1).strip().lower()
        value = match.group(2).strip()
        metadata[key] = value
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–æ–≤ (–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è)
    sections = []
    section_pattern = r"^\s*##\s+(.*?)$"
    for match in re.finditer(section_pattern, content, re.MULTILINE):
        sections.append(match.group(1).strip())
    
    if sections:
        metadata["sections"] = sections
    
    return metadata

def check_criteria_match(content, file_path, criteria):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º.
    
    Args:
        content (str): –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        file_path (Path): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        criteria (dict): –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        bool: True, –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º, –∏–Ω–∞—á–µ False
    """
    str_path = str(file_path)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –ø—É—Ç–∏
    for pattern in criteria.get("path_patterns", []):
        if re.search(pattern, str_path, re.IGNORECASE):
            return True
    
    metadata = extract_document_metadata(content)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    if "title" in metadata:
        for pattern in criteria.get("title_patterns", []):
            if re.search(pattern, metadata["title"], re.IGNORECASE):
                return True
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
    if "sections" in metadata:
        required_sections = criteria.get("required_sections", [])
        if required_sections:
            section_matches = sum(1 for section in required_sections if any(
                re.search(f"{re.escape(section)}", s, re.IGNORECASE) for s in metadata["sections"]
            ))
            # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –±–æ–ª–µ–µ –ø–æ–ª–æ–≤–∏–Ω—ã —Ç—Ä–µ–±—É–µ–º—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤, —Å—á–∏—Ç–∞–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–º
            if section_matches >= len(required_sections) / 2:
                return True
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
    for pattern in criteria.get("content_patterns", []):
        if re.search(pattern, content, re.MULTILINE | re.IGNORECASE):
            return True
    
    return False

def is_archived(content, file_path):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –∞—Ä—Ö–∏–≤–Ω—ã–º.
    
    Args:
        content (str): –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        file_path (Path): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        
    Returns:
        bool: True, –µ—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –∞—Ä—Ö–∏–≤–Ω—ã–π, –∏–Ω–∞—á–µ False
    """
    str_path = str(file_path)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –ø—É—Ç–∏
    for pattern in ARCHIVE_CRITERIA.get("path_patterns", []):
        if re.search(pattern, str_path, re.IGNORECASE):
            return True
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
    for pattern in ARCHIVE_CRITERIA.get("content_patterns", []):
        if re.search(pattern, content, re.MULTILINE | re.IGNORECASE):
            return True
    
    return False

def determine_document_type(content, file_path):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏ –ø—É—Ç–∏.
    
    Args:
        content (str): –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        file_path (Path): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        
    Returns:
        str: –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (standard, task, incident, unknown) —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º archived_ –¥–ª—è –∞—Ä—Ö–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –∞—Ä—Ö–∏–≤–Ω—ã–º
    archived = is_archived(content, file_path)
    prefix = "archived_" if archived else ""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞
    for doc_type, criteria in DOCUMENT_CRITERIA.items():
        if check_criteria_match(content, file_path, criteria):
            return f"{prefix}{doc_type}"
    
    # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –∞—Ä—Ö–∏–≤–Ω—ã–π, –Ω–æ —Ç–∏–ø –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, —Å—á–∏—Ç–∞–µ–º –µ–≥–æ –∞—Ä—Ö–∏–≤–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
    if archived:
        return "archived_document"
    
    # –ï—Å–ª–∏ —Ç–∏–ø –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∞—Ä—Ö–∏–≤–Ω—ã–π, —Å—á–∏—Ç–∞–µ–º –µ–≥–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º
    return "unknown"

def scan_documents(directory, results):
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    
    Args:
        directory (Path): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        results (dict): –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    if not directory.exists():
        print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    print(f"–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {directory}")
    
    for item in directory.iterdir():
        if item.is_dir():
            scan_documents(item, results)
        elif item.is_file() and item.suffix.lower() in ['.md', '.markdown']:
            try:
                with open(item, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                doc_type = determine_document_type(content, item)
                results[doc_type]["files"].append(item)
                results[doc_type]["count"] += 1
                
                print(f"  {item.name}: {doc_type}")
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞ {item}: {e}")
                results["error"]["files"].append(item)
                results["error"]["count"] += 1

def compare_with_indexer(results):
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞—É–¥–∏—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞.
    
    Args:
        results (dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞ —á–µ—Ä–µ–∑ API
    try:
        import requests
        response = requests.get("http://localhost:5001/api/indexer/statistics")
        if response.status_code != 200:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞: {response.status_code}")
            return None
        
        indexer_stats = response.json()
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        audit_total = sum(data["count"] for data in results.values())
        indexer_total = indexer_stats.get("total_documents", 0)
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ —Ç–∏–ø–∞–º
        comparison = {
            "total": {
                "audit": audit_total,
                "indexer": indexer_total,
                "difference": audit_total - indexer_total
            },
            "types": {}
        }
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞—É–¥–∏—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        audit_by_type = {}
        for doc_type, data in results.items():
            audit_by_type[doc_type] = data["count"]
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞
        indexer_by_type = indexer_stats.get("document_types", {})
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        all_types = set(audit_by_type.keys()) | set(indexer_by_type.keys())
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø
        for doc_type in all_types:
            audit_count = audit_by_type.get(doc_type, 0)
            indexer_count = indexer_by_type.get(doc_type, 0)
            
            comparison["types"][doc_type] = {
                "audit": audit_count,
                "indexer": indexer_count,
                "difference": audit_count - indexer_count
            }
        
        return comparison
    
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–æ–º: {e}")
        return None

def generate_report(results, comparison=None):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∞—É–¥–∏—Ç–∞.
    
    Args:
        results (dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        comparison (dict, optional): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–æ–º
        
    Returns:
        str: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç—á–µ—Ç–∞
    """
    report_date = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = ROOT_DIR / f"classification_audit_report_{report_date}.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"# –û—Ç—á–µ—Ç –ø–æ –∞—É–¥–∏—Ç—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n\n")
        f.write(f"–î–∞—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_docs = sum(data["count"] for data in results.values())
        f.write(f"## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        f.write(f"–í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_docs}\n\n")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
        f.write("## –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º\n\n")
        f.write("| –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ | –ü—Ä–æ—Ü–µ–Ω—Ç |\n")
        f.write("|---------------|------------|--------|\n")
        
        for doc_type, data in sorted(results.items(), key=lambda x: x[1]["count"], reverse=True):
            count = data["count"]
            percent = (count / total_docs) * 100 if total_docs > 0 else 0
            f.write(f"| {doc_type} | {count} | {percent:.2f}% |\n")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–æ–º
        if comparison:
            f.write("\n## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–æ–º\n\n")
            
            # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            total_diff = comparison["total"]["difference"]
            diff_symbol = "‚úì" if total_diff == 0 else ("+" if total_diff > 0 else "-")
            
            f.write("### –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n\n")
            f.write(f"* –ê—É–¥–∏—Ç: {comparison['total']['audit']}\n")
            f.write(f"* –ò–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä: {comparison['total']['indexer']}\n")
            f.write(f"* –†–∞–∑–Ω–∏—Ü–∞: {diff_symbol} {abs(total_diff)}\n\n")
            
            # –ü–æ —Ç–∏–ø–∞–º
            f.write("### –ü–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n\n")
            f.write("| –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ | –ê—É–¥–∏—Ç | –ò–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä | –†–∞–∑–Ω–∏—Ü–∞ |\n")
            f.write("|---------------|-------|------------|--------|\n")
            
            for doc_type, data in sorted(comparison["types"].items(), key=lambda x: abs(x[1]["difference"]), reverse=True):
                diff = data["difference"]
                diff_symbol = "‚úì" if diff == 0 else ("+" if diff > 0 else "-")
                f.write(f"| {doc_type} | {data['audit']} | {data['indexer']} | {diff_symbol} {abs(diff)} |\n")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            f.write("\n## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")
            
            if total_diff == 0 and all(d["difference"] == 0 for d in comparison["types"].values()):
                f.write("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –¥–∞–Ω–Ω—ã–º –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞. –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.\n")
            else:
                f.write("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –º–µ–∂–¥—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞—É–¥–∏—Ç–∞ –∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞:\n\n")
                
                for doc_type, data in comparison["types"].items():
                    if data["difference"] != 0:
                        if data["difference"] > 0:
                            f.write(f"* **{doc_type}**: –ê—É–¥–∏—Ç –æ–±–Ω–∞—Ä—É–∂–∏–ª –Ω–∞ {data['difference']} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±–æ–ª—å—à–µ. ")
                            f.write("–í–æ–∑–º–æ–∂–Ω–æ, –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä –Ω–µ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —ç—Ç–æ–≥–æ —Ç–∏–ø–∞.\n")
                        else:
                            f.write(f"* **{doc_type}**: –ò–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä —É—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–∞ {abs(data['difference'])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±–æ–ª—å—à–µ. ")
                            f.write("–í–æ–∑–º–æ–∂–Ω–æ, –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∞—É–¥–∏—Ç–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞.\n")
                
                f.write("\n–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:\n\n")
                f.write("1. –û–±–Ω–æ–≤–∏—Ç—å –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–µ\n")
                f.write("2. –ü—Ä–∏–≤–µ—Å—Ç–∏ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É\n")
                f.write("3. –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n")
        
        # –î–µ—Ç–∞–ª–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —Ç–∏–ø—É
        f.write("\n## –î–µ—Ç–∞–ª–∏ –ø–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n\n")
        
        for doc_type, data in sorted(results.items(), key=lambda x: x[1]["count"], reverse=True):
            if data["count"] > 0:
                f.write(f"### {doc_type} ({data['count']})\n\n")
                
                for file_path in sorted(data["files"]):
                    rel_path = file_path.relative_to(ROOT_DIR)
                    f.write(f"* `{rel_path}`\n")
                
                f.write("\n")
    
    print(f"\n–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_file}")
    return str(report_file)

def generate_csv_report(results, comparison=None):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç CSV-–æ—Ç—á–µ—Ç –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    
    Args:
        results (dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        comparison (dict, optional): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–æ–º
        
    Returns:
        str: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç—á–µ—Ç–∞
    """
    report_date = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = ROOT_DIR / f"classification_audit_report_{report_date}.csv"
    
    with open(report_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        writer.writerow(["File Path", "Document Type", "Relative Path"])
        
        # –î–∞–Ω–Ω—ã–µ –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É
        for doc_type, data in results.items():
            for file_path in sorted(data["files"]):
                rel_path = str(file_path.relative_to(ROOT_DIR))
                writer.writerow([str(file_path), doc_type, rel_path])
    
    print(f"\nCSV-–æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_file}")
    return str(report_file)

def save_statistics(results, comparison=None):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ JSON-—Ñ–∞–π–ª.
    
    Args:
        results (dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        comparison (dict, optional): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–æ–º
        
    Returns:
        str: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    """
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è JSON
    stats = {
        "timestamp": datetime.now().isoformat(),
        "total_documents": sum(data["count"] for data in results.values()),
        "document_types": {doc_type: data["count"] for doc_type, data in results.items()},
        "comparison": comparison
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    stats["documents_by_type"] = {}
    for doc_type, data in results.items():
        stats["documents_by_type"][doc_type] = [str(file_path.relative_to(ROOT_DIR)) for file_path in data["files"]]
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats_file = ROOT_DIR / "classification_statistics.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {stats_file}")
    return str(stats_file)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    print("–ó–∞–ø—É—Å–∫ –∞—É–¥–∏—Ç–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results = defaultdict(lambda: {"files": [], "count": 0})
    
    # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    scan_documents(STANDARDS_DIR, results)
    scan_documents(TASKS_DIR, results)
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–æ–º
    comparison = compare_with_indexer(results)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
    generate_report(results, comparison)
    generate_csv_report(results)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    save_statistics(results, comparison)
    
    print("\n–ê—É–¥–∏—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")

if __name__ == "__main__":
    main()