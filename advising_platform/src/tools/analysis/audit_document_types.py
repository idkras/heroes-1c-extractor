#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞—É–¥–∏—Ç–∞ —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ.

–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ —Ç–∏–ø–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:
1. –°–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
2. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã
3. –í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é
"""

import os
import re
import sys
import json
from pathlib import Path
from datetime import datetime
from collections import defaultdict

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
ROOT_DIR = Path(__file__).parent.parent.parent.parent.parent

# –ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
STANDARDS_DIR = ROOT_DIR / "[standards .md]"
TASKS_DIR = ROOT_DIR / "[todo ¬∑ incidents]"

# –®–∞–±–ª–æ–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
PATTERNS = {
    "standard": [
        r"^#\s+.*?–°—Ç–∞–Ω–¥–∞—Ä—Ç",
        r"status:\s*(Active|–ê–∫—Ç–∏–≤–µ–Ω|–î–µ–π—Å—Ç–≤—É—é—â–∏–π)",
        r"version:\s*\d+\.\d+",
        r"updated:\s*\d{1,2}\s+\w+\s+\d{4}",
        r"based on:\s*.*?Standard"
    ],
    "task": [
        r"^#\s+üìã\s+ToDo",
        r"^##\s+üîú\s+–°–ª–µ–¥—É—é—â–∏–µ –¥–µ–π—Å—Ç–≤–∏—è",
        r"^##\s+ToDo",
        r"^##\s+–ó–∞–¥–∞—á–∏"
    ],
    "incident": [
        r"^#\s+üö®\s+–ò–Ω—Ü–∏–¥–µ–Ω—Ç",
        r"^##\s+üîç\s+–û–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞",
        r"^##\s+–û–ø–∏—Å–∞–Ω–∏–µ –∏–Ω—Ü–∏–¥–µ–Ω—Ç–∞",
        r"^##\s+‚ùå\s+–ü–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è"
    ],
    "archived": [
        r"archive",
        r"–∞—Ä—Ö–∏–≤",
        r"–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ"
    ]
}

def detect_document_type(file_path):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏ –ø—É—Ç–∏.
    
    Args:
        file_path (Path): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        
    Returns:
        str: –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (standard, task, incident, archived_standard, archived_task, archived_incident, unknown)
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç
        is_standard = any(re.search(pattern, content, re.MULTILINE) for pattern in PATTERNS["standard"])
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–¥–∞—á—É
        is_task = any(re.search(pattern, content, re.MULTILINE) for pattern in PATTERNS["task"])
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–Ω—Ü–∏–¥–µ–Ω—Ç
        is_incident = any(re.search(pattern, content, re.MULTILINE) for pattern in PATTERNS["incident"])
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∞—Ä—Ö–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
        is_archived = any(re.search(pattern, file_path.name.lower()) for pattern in PATTERNS["archived"]) or \
                     any(re.search(pattern, content, re.MULTILINE) for pattern in PATTERNS["archived"])
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä–æ–∫
        if is_standard:
            return "archived_standard" if is_archived else "standard"
        elif is_task:
            return "archived_task" if is_archived else "task"
        elif is_incident:
            return "archived_incident" if is_archived else "incident"
        else:
            return "archived_document" if is_archived else "unknown"
    
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return "error"

def scan_documents(directory, results):
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    
    Args:
        directory (Path): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        results (dict): –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    if not directory.exists():
        print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    print(f"–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {directory}")
    
    for item in directory.iterdir():
        if item.is_dir():
            scan_documents(item, results)
        elif item.is_file() and item.suffix.lower() in ['.md', '.markdown']:
            doc_type = detect_document_type(item)
            results[doc_type].append(item)
            print(f"  {item.name}: {doc_type}")

def analyze_results(results):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
    
    Args:
        results (dict): –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    statistics = {
        "total": sum(len(docs) for docs in results.values()),
        "types": {doc_type: len(docs) for doc_type, docs in results.items()},
        "timestamp": datetime.now().isoformat()
    }
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"  –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {statistics['total']}")
    print("  –¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
    for doc_type, count in statistics["types"].items():
        print(f"    {doc_type}: {count}")
    
    return statistics

def generate_report(results, statistics):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∞—É–¥–∏—Ç–∞.
    
    Args:
        results (dict): –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        statistics (dict): –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        
    Returns:
        str: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç—á–µ—Ç–∞
    """
    report_date = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = ROOT_DIR / f"audit_report_{report_date}.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"# –û—Ç—á–µ—Ç –ø–æ –∞—É–¥–∏—Ç—É —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n\n")
        f.write(f"–î–∞—Ç–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        f.write(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {statistics['total']}\n\n")
        f.write("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:\n\n")
        
        for doc_type, count in statistics["types"].items():
            f.write(f"- {doc_type}: {count}\n")
        
        f.write("\n## –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º\n\n")
        
        for doc_type, docs in results.items():
            if docs:
                f.write(f"### {doc_type}\n\n")
                for doc in docs:
                    rel_path = doc.relative_to(ROOT_DIR)
                    f.write(f"- `{rel_path}`\n")
                f.write("\n")
    
    print(f"\n–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_file}")
    return str(report_file)

def save_statistics(statistics):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ JSON-—Ñ–∞–π–ª.
    
    Args:
        statistics (dict): –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        
    Returns:
        str: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    """
    stats_file = ROOT_DIR / "document_type_statistics.json"
    
    # –ß–∏—Ç–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    history = []
    if stats_file.exists():
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
                if not isinstance(history, list):
                    history = [history]
        except:
            history = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    history.append(statistics)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2, ensure_ascii=False)
    
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {stats_file}")
    return str(stats_file)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞."""
    print("–ó–∞–ø—É—Å–∫ –∞—É–¥–∏—Ç–∞ —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results = defaultdict(list)
    
    # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    scan_documents(STANDARDS_DIR, results)
    scan_documents(TASKS_DIR, results)
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    statistics = analyze_results(results)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    generate_report(results, statistics)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    save_statistics(statistics)
    
    print("\n–ê—É–¥–∏—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")

if __name__ == "__main__":
    main()