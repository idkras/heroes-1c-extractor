"""
–ú–æ–¥—É–ª—å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:
1. –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
2. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞—Ö
3. –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
4. –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –º–µ–∂–¥—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 19 May 2025
"""

import os
import re
import sys
import glob
import logging
import datetime
import difflib
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
from . import STANDARDS_DIR

# –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
PROTECTED_SECTION_BEGIN = r'<!--\s*üîí\s*PROTECTED SECTION:\s*BEGIN\s*-->'
PROTECTED_SECTION_END = r'<!--\s*üîí\s*PROTECTED SECTION:\s*END\s*-->'
UPDATED_REGEX = r'updated:\s*(\d{1,2}\s+[A-Za-z]+\s+\d{4}),\s*(\d{1,2}:\d{2})\s+CET\s+by\s+(.+)'
PREVIOUS_VERSION_REGEX = r'previous\s+version:\s*(\d{1,2}\s+[A-Za-z]+\s+\d{4})'
VERSION_REGEX = r'version:\s*(\d+\.\d+)'
STATUS_REGEX = r'status:\s*(Active|Draft|Archived|Deprecated)'
FILENAME_REGEX = r'^(\d+\.\d+)\s+(.+)\s+(\d{1,2}\s+[a-z]+\s+\d{4})\s+(\d{2}:\d{2})\s+CET\s+by\s+(.+)\.md$'

# –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
REQUIRED_SECTIONS = [
    "## üéØ –¶–µ–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞",
]

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
DIRECTORY_CATEGORIES = {
    "0. core standards": "0.",
    "1. process ¬∑ goalmap ¬∑ task ¬∑ incidents ¬∑ tickets ¬∑ qa": "1.",
    "2. projects ¬∑ context ¬∑ next actions": "2.",
    "3. scenarium ¬∑ jtbd ¬∑ hipothises ¬∑ offering ¬∑ tone": "3.",
    "6. advising ¬∑ review ¬∑ supervising": "6.",
    "8. auto ¬∑ n8n": "8.",
    "9. development ¬∑ documentation": "9.",
}


class StandardValidator:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º.
    """
    def __init__(self, base_dir=None):
        self.base_dir = base_dir or STANDARDS_DIR
        self.issues = []
        self.warnings = []
        self.standards_checked = 0
        self.standards_with_issues = 0
        self.standards_ok = 0
    
    def validate_all(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
        logger.info(f"–ù–∞—á–∏–Ω–∞—é –ø—Ä–æ–≤–µ—Ä–∫—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {self.base_dir}")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã .md —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
        standard_files = []
        for root, dirs, files in os.walk(self.base_dir):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ [archive]
            if '[archive]' in root or '/archive/' in root:
                continue
                
            for file in files:
                if file.endswith('.md'):
                    full_path = os.path.join(root, file)
                    standard_files.append(full_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        for standard_file in standard_files:
            self.validate_standard(standard_file)
            
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤: {self.standards_checked}")
        logger.info(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –±–µ–∑ –ø—Ä–æ–±–ª–µ–º: {self.standards_ok}")
        logger.info(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏: {self.standards_with_issues}")
        logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(self.issues)}")
        logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(self.warnings)}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        return len(self.issues)
    
    def validate_standard(self, file_path):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º."""
        self.standards_checked += 1
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∏ –∏–º—è —Ñ–∞–π–ª–∞
        rel_path = os.path.relpath(file_path, self.base_dir)
        file_name = os.path.basename(file_path)
        
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞: {rel_path}")
        
        issues_before = len(self.issues)
        
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            self.issues.append(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {rel_path}: {str(e)}")
            self.standards_with_issues += 1
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
        self._check_protected_section(content, file_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        self._check_filename(file_name, file_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self._check_standard_number_and_directory(file_name, file_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
        self._check_required_sections(content, file_path)
        
        # –ï—Å–ª–∏ –Ω–µ –¥–æ–±–∞–≤–∏–ª–æ—Å—å –Ω–æ–≤—ã—Ö –ø—Ä–æ–±–ª–µ–º, —Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤ –ø–æ—Ä—è–¥–∫–µ
        if len(self.issues) == issues_before:
            self.standards_ok += 1
            logger.info(f"  ‚úì –°—Ç–∞–Ω–¥–∞—Ä—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º")
        else:
            self.standards_with_issues += 1
            logger.info(f"  ‚úó –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã")
    
    def _check_protected_section(self, content, file_path):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞."""
        rel_path = os.path.relpath(file_path, self.base_dir)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
        begin_match = re.search(PROTECTED_SECTION_BEGIN, content)
        end_match = re.search(PROTECTED_SECTION_END, content)
        
        if not begin_match:
            self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞—á–∞–ª–æ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ '<!-- üîí PROTECTED SECTION: BEGIN -->' –≤ {rel_path}")
        
        if not end_match:
            self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω–µ—Ü –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ '<!-- üîí PROTECTED SECTION: END -->' –≤ {rel_path}")
        
        if begin_match and end_match:
            protected_section = content[begin_match.end():end_match.start()]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            if not re.search(UPDATED_REGEX, protected_section):
                self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'updated' –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ —Ñ–∞–π–ª–∞ {rel_path}")
            
            if not re.search(VERSION_REGEX, protected_section):
                self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'version' –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ —Ñ–∞–π–ª–∞ {rel_path}")
            
            if not re.search(STATUS_REGEX, protected_section):
                self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'status' –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ —Ñ–∞–π–ª–∞ {rel_path}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–æ–ª—è previous version (–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –Ω–µ –æ—à–∏–±–∫–∞)
            if not re.search(PREVIOUS_VERSION_REGEX, protected_section):
                self.warnings.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'previous version' –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ —Ñ–∞–π–ª–∞ {rel_path}")
    
    def _check_filename(self, file_name, file_path):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞."""
        rel_path = os.path.relpath(file_path, self.base_dir)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∏–º—è —Ñ–∞–π–ª–∞ –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã (–∫—Ä–æ–º–µ –∏–º–µ–Ω —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö)
        english_words = re.findall(r'\b[A-Z][a-z]+\b', file_name)
        for word in english_words:
            if word not in ["CET", "AI", "JTBD"] and not any(month in word for month in ["January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"]):
                self.issues.append(f"–ò–º—è —Ñ–∞–π–ª–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–ª–∞–≤–Ω—ã–µ –±—É–∫–≤—ã: '{word}' –≤ {rel_path}. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å lowercase.")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        if not re.match(r'^\d+\.\d+', file_name) and not file_name.startswith("README"):
            self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–æ–º–µ—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ {rel_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        date_match = re.search(r'(\d{1,2})\s+([a-zA-Z]+)\s+(\d{4})', file_name)
        if not date_match and not file_name.startswith("README"):
            self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ {rel_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ "by author" –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        if "by" not in file_name.lower() and not file_name.startswith("README"):
            self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —É–∫–∞–∑–∞–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ ('by author') –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ {rel_path}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∏–º–≤–æ–ª–∞ "|" –≤–º–µ—Å—Ç–æ "¬∑"
        if "|" in file_name:
            self.issues.append(f"–ò–º—è —Ñ–∞–π–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∏–º–≤–æ–ª '|' –≤–º–µ—Å—Ç–æ '¬∑' (middle dot) –≤ {rel_path}")
    
    def _check_standard_number_and_directory(self, file_name, file_path):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –µ–≥–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—é –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö."""
        rel_path = os.path.relpath(file_path, self.base_dir)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        number_match = re.match(r'(\d+)\.(\d+)', file_name)
        if not number_match:
            return  # –≠—Ç–∞ –ø—Ä–æ–±–ª–µ–º–∞ —É–∂–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ –≤ _check_filename
        
        category_number = number_match.group(1)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        directory = os.path.dirname(file_path)
        expected_category = None
        
        for dir_name, category in DIRECTORY_CATEGORIES.items():
            if dir_name in directory:
                expected_category = category.rstrip('.')
                break
        
        # –ï—Å–ª–∏ –º—ã –Ω–µ —Å–º–æ–≥–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–∂–∏–¥–∞–µ–º—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
        if expected_category is None:
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if category_number != expected_category:
            self.issues.append(f"–ù–æ–º–µ—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ ({category_number}) –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ({expected_category}) –¥–ª—è {rel_path}")
    
    def _check_required_sections(self, content, file_path):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–µ."""
        rel_path = os.path.relpath(file_path, self.base_dir)
        
        for section in REQUIRED_SECTIONS:
            if section not in content:
                self.issues.append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª '{section}' –≤ {rel_path}")


class StandardFixer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞—Ö.
    """
    def __init__(self, base_dir=None):
        self.base_dir = base_dir or STANDARDS_DIR
        self.files_fixed = 0
        self.issues_fixed = 0
    
    def fix_all(self, create_backups=True):
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
        logger.info(f"–ù–∞—á–∏–Ω–∞—é –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {self.base_dir}")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã .md —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
        standard_files = []
        for root, dirs, files in os.walk(self.base_dir):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ [archive]
            if '[archive]' in root or '/archive/' in root:
                continue
                
            for file in files:
                if file.endswith('.md'):
                    full_path = os.path.join(root, file)
                    standard_files.append(full_path)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        for standard_file in standard_files:
            self.fix_standard(standard_file, create_backups)
            
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        logger.info(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        logger.info(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.files_fixed}")
        logger.info(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {self.issues_fixed}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        return self.files_fixed
    
    def fix_standard(self, file_path, create_backup=True):
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ–¥–∏–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç."""
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∏ –∏–º—è —Ñ–∞–π–ª–∞
        rel_path = os.path.relpath(file_path, self.base_dir)
        file_name = os.path.basename(file_path)
        
        logger.info(f"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞: {rel_path}")
        
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {rel_path}: {str(e)}")
            return
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        original_content = content
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª
        content = self._fix_protected_section(content, file_path)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        new_file_path = self._fix_filename(file_path)
        
        # –ï—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, —Å–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        if content != original_content:
            if create_backup:
                backup_path = file_path + ".bak"
                try:
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        f.write(original_content)
                    logger.info(f"  –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {os.path.basename(backup_path)}")
                except Exception as e:
                    logger.error(f"  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ {os.path.basename(backup_path)}: {str(e)}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"  ‚úì –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω")
                self.files_fixed += 1
                self.issues_fixed += 1
            except Exception as e:
                logger.error(f"  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {rel_path}: {str(e)}")
        
        # –ï—Å–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∏–∑–º–µ–Ω–∏–ª—Å—è, –ø–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª
        if new_file_path and new_file_path != file_path:
            try:
                # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
                if create_backup:
                    backup_dir = os.path.join(os.path.dirname(file_path), "[archive]", "rename_backups")
                    os.makedirs(backup_dir, exist_ok=True)
                    backup_path = os.path.join(backup_dir, os.path.basename(file_path))
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    logger.info(f"  –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ–º: {os.path.basename(backup_path)}")
                
                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª
                os.rename(file_path, new_file_path)
                logger.info(f"  ‚úì –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω –≤: {os.path.basename(new_file_path)}")
                self.files_fixed += 1
                self.issues_fixed += 1
            except Exception as e:
                logger.error(f"  –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ {rel_path}: {str(e)}")
    
    def _fix_protected_section(self, content, file_path):
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–µ."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞ –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
        begin_match = re.search(PROTECTED_SECTION_BEGIN, content)
        end_match = re.search(PROTECTED_SECTION_END, content)
        
        # –ï—Å–ª–∏ –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
        if not begin_match or not end_match:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª
            now = datetime.datetime.now()
            date_str = now.strftime("%-d %B %Y")
            time_str = now.strftime("%-H:%M")
            author = "AI Assistant"
            
            protected_section = f"""<!-- üîí PROTECTED SECTION: BEGIN -->
type: standard
version: 1.0
status: Active
updated: {date_str}, {time_str} CET by {author}
tags: standard, documentation
<!-- üîí PROTECTED SECTION: END -->

"""
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
            content = protected_section + content
            logger.info(f"  –î–æ–±–∞–≤–ª–µ–Ω –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª")
            return content
        
        # –ï—Å–ª–∏ –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª –µ—Å—Ç—å, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –µ–≥–æ
        protected_section = content[begin_match.end():end_match.start()]
        modified_section = protected_section
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        if not re.search(r'type:\s*standard', protected_section, re.IGNORECASE):
            modified_section = "type: standard\n" + modified_section
        
        if not re.search(VERSION_REGEX, protected_section):
            modified_section = modified_section + "version: 1.0\n"
        
        if not re.search(STATUS_REGEX, protected_section):
            modified_section = modified_section + "status: Active\n"
        
        if not re.search(UPDATED_REGEX, protected_section):
            now = datetime.datetime.now()
            date_str = now.strftime("%-d %B %Y")
            time_str = now.strftime("%-H:%M")
            author = "AI Assistant"
            modified_section = modified_section + f"updated: {date_str}, {time_str} CET by {author}\n"
        
        if not re.search(r'tags:', protected_section, re.IGNORECASE):
            modified_section = modified_section + "tags: standard, documentation\n"
        
        # –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª –±—ã–ª –∏–∑–º–µ–Ω–µ–Ω, –æ–±–Ω–æ–≤–ª—è–µ–º –µ–≥–æ
        if modified_section != protected_section:
            content = content[:begin_match.end()] + modified_section + content[end_match.start():]
            logger.info(f"  –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –∑–∞—â–∏—â–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª")
        
        return content
    
    def _fix_filename(self, file_path):
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞."""
        file_name = os.path.basename(file_path)
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º README –∏ –¥—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
        if file_name.startswith("README") or '.' not in file_name:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –∏–º—è —Ñ–∞–π–ª–∞
        is_valid = True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
        number_match = re.match(r'^\d+\.\d+', file_name)
        if not number_match:
            is_valid = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
        date_match = re.search(r'(\d{1,2})\s+([a-zA-Z]+)\s+(\d{4})', file_name)
        if not date_match:
            is_valid = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞–≤—Ç–æ—Ä–∞
        if "by" not in file_name.lower():
            is_valid = False
        
        # –ï—Å–ª–∏ –∏–º—è —Ñ–∞–π–ª–∞ —É–∂–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if is_valid:
            return None
        
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            logger.error(f"  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏–º–µ–Ω–∏: {str(e)}")
            return None
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
        standard_number = "1.0"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        number_match = re.search(r'^\d+\.\d+', file_name)
        if number_match:
            standard_number = number_match.group(0)
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–æ–º–µ—Ä –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            first_line = content.split('\n')[0]
            number_match = re.search(r'^\d+\.\d+', first_line)
            if number_match:
                standard_number = number_match.group(0)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
        title = file_name.replace('.md', '')
        title_match = re.search(r'^\d+\.\d+\s+(.*?)(?:\s+\d{1,2}\s+[a-zA-Z]+\s+\d{4}|$)', file_name)
        if title_match:
            title = title_match.group(1).strip()
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            first_line = content.split('\n')[0]
            title_match = re.search(r'^\s*#\s+(.+)$', first_line)
            if title_match:
                title = title_match.group(1).strip()
                # –£–¥–∞–ª—è–µ–º –Ω–æ–º–µ—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                title = re.sub(r'^\d+\.\d+\s+', '', title)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏ –∞–≤—Ç–æ—Ä–∞
        now = datetime.datetime.now()
        date_str = now.strftime("%-d %B %Y").lower()
        time_str = now.strftime("%H%M")
        author = "ai assistant"
        
        # –ò—â–µ–º –¥–∞—Ç—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ –∑–∞—â–∏—â–µ–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ
        begin_match = re.search(PROTECTED_SECTION_BEGIN, content)
        end_match = re.search(PROTECTED_SECTION_END, content)
        if begin_match and end_match:
            protected_section = content[begin_match.end():end_match.start()]
            updated_match = re.search(UPDATED_REGEX, protected_section)
            if updated_match:
                date_str = updated_match.group(1).lower()
                time_parts = updated_match.group(2).split(':')
                time_str = time_parts[0] + time_parts[1]
                author = updated_match.group(3).lower()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        new_file_name = f"{standard_number} {title} {date_str} {time_str} cet by {author}.md"
        
        # –ó–∞–º–µ–Ω—è–µ–º "|" –Ω–∞ "¬∑" –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        new_file_name = new_file_name.replace("|", "¬∑")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –ø—É—Ç—å
        new_file_path = os.path.join(os.path.dirname(file_path), new_file_name)
        
        # –ï—Å–ª–∏ —Å—Ç–∞—Ä–æ–µ –∏ –Ω–æ–≤–æ–µ –∏–º—è —Å–æ–≤–ø–∞–¥–∞—é—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if file_path == new_file_path:
            return None
        
        return new_file_path


class StandardAnalyzer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –º–µ–∂–¥—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏.
    """
    def __init__(self, base_dir=None):
        self.base_dir = base_dir or STANDARDS_DIR
        self.standards = {}  # id -> (path, content)
        self.similarity_matrix = {}  # (id1, id2) -> similarity
    
    def analyze_all(self, threshold=0.3):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –≤—Å–µ–º–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
        logger.info(f"–ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –º–µ–∂–¥—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {self.base_dir}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã
        self._load_standards()
        
        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –º–µ–Ω–µ–µ 2 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        if len(self.standards) < 2:
            logger.warning(f"–ù–∞–π–¥–µ–Ω–æ –º–µ–Ω–µ–µ 2 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤, –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
            return {}
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É —Å—Ö–æ–¥—Å—Ç–≤–∞
        self._compute_similarity_matrix()
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–∞—Ä—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —Å—Ö–æ–¥—Å—Ç–≤–æ–º
        similar_pairs = []
        for (id1, id2), similarity in self.similarity_matrix.items():
            if similarity >= threshold:
                path1, _ = self.standards[id1]
                path2, _ = self.standards[id2]
                rel_path1 = os.path.relpath(path1, self.base_dir)
                rel_path2 = os.path.relpath(path2, self.base_dir)
                similar_pairs.append({
                    'standard1': rel_path1,
                    'standard2': rel_path2,
                    'similarity': similarity
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
        similar_pairs.sort(key=lambda pair: pair['similarity'], reverse=True)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(similar_pairs)} –ø–∞—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ —Å —Å—Ö–æ–¥—Å—Ç–≤–æ–º >= {threshold}.")
        for i, pair in enumerate(similar_pairs[:10], 1):
            logger.info(f"{i}. {pair['standard1']} <-> {pair['standard2']}: {pair['similarity']:.2f}")
        
        return similar_pairs
    
    def _load_standards(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
        self.standards = {}
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã .md —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
        for root, dirs, files in os.walk(self.base_dir):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ [archive]
            if '[archive]' in root or '/archive/' in root:
                continue
                
            for file in files:
                if file.endswith('.md'):
                    full_path = os.path.join(root, file)
                    
                    # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
                    try:
                        with open(full_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                            # –û—á–∏—â–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
                            content = self._clean_content(content)
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
                            standard_id = os.path.relpath(full_path, self.base_dir)
                            self.standards[standard_id] = (full_path, content)
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {full_path}: {str(e)}")
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.standards)} —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤.")
    
    def _clean_content(self, content):
        """–û—á–∏—â–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Ç –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö."""
        # –£–¥–∞–ª—è–µ–º –∑–∞—â–∏—â–µ–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã
        content = re.sub(f"{PROTECTED_SECTION_BEGIN}.*?{PROTECTED_SECTION_END}", "", content, flags=re.DOTALL)
        
        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        content = re.sub(r'\n\s*\n', '\n\n', content)
        
        return content
    
    def _compute_similarity_matrix(self):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–∞—Ç—Ä–∏—Ü—É —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏."""
        self.similarity_matrix = {}
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
        standard_ids = list(self.standards.keys())
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
        total_pairs = len(standard_ids) * (len(standard_ids) - 1) // 2
        processed_pairs = 0
        
        for i, id1 in enumerate(standard_ids):
            for id2 in standard_ids[i+1:]:
                # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ
                _, content1 = self.standards[id1]
                _, content2 = self.standards[id2]
                
                similarity = self._compute_similarity(content1, content2)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                self.similarity_matrix[(id1, id2)] = similarity
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫
                processed_pairs += 1
                if processed_pairs % 100 == 0:
                    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_pairs}/{total_pairs} –ø–∞—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤.")
        
        logger.info(f"–í—ã—á–∏—Å–ª–µ–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–ª—è {len(standard_ids)} —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤.")
    
    def _compute_similarity(self, content1, content2):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏."""
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã –Ω–∞ —Å—Ç—Ä–æ–∫–∏
        lines1 = content1.split('\n')
        lines2 = content2.split('\n')
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º difflib –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ö–æ–¥—Å—Ç–≤–∞
        matcher = difflib.SequenceMatcher(None, lines1, lines2)
        return matcher.ratio()


# –ü—É–±–ª–∏—á–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª—è—Ö

def validate_standards(base_dir=None):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º.
    
    Args:
        base_dir (str, optional): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
        
    Returns:
        int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
    """
    validator = StandardValidator(base_dir)
    return validator.validate_all()


def fix_standards_metadata(base_dir=None, create_backups=True):
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞—Ö.
    
    Args:
        base_dir (str, optional): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
        create_backups (bool): –°–æ–∑–¥–∞–≤–∞—Ç—å –ª–∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
        
    Returns:
        int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    """
    fixer = StandardFixer(base_dir)
    return fixer.fix_all(create_backups)


def rename_standards(base_dir=None, create_backups=True):
    """
    –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç —Ñ–∞–π–ª—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏.
    
    Args:
        base_dir (str, optional): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
        create_backups (bool): –°–æ–∑–¥–∞–≤–∞—Ç—å –ª–∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏
        
    Returns:
        int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    """
    fixer = StandardFixer(base_dir)
    return fixer.fix_all(create_backups)


def analyze_standards_overlap(base_dir=None, threshold=0.3):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –º–µ–∂–¥—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏.
    
    Args:
        base_dir (str, optional): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
        threshold (float): –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞
        
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ –ø–∞—Ä —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ —Å —Å—Ö–æ–¥—Å—Ç–≤–æ–º >= threshold
    """
    analyzer = StandardAnalyzer(base_dir)
    return analyzer.analyze_all(threshold)