#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤ —Å–∏–ª—å–Ω—ã–µ –µ–¥–∏–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã.

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞–ø–∫–∏ 3, 4 –∏ dev –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç
–ø–ª–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤.

–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 22 May 2025
"""

import os
from pathlib import Path
from typing import Dict, List, Set, Tuple
import re
import logging

logger = logging.getLogger(__name__)


class StandardsDuplicationAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤."""
    
    def __init__(self, standards_directory: str = '[standards .md]'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä.
        
        Args:
            standards_directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
        """
        self.standards_dir = Path(standards_directory)
        self.target_folders = [
            '3. communication',
            '4. interface ¬∑ design', 
            '2. dev'
        ]
        
        self.analysis_results = {
            'folders_analyzed': {},
            'detected_overlaps': [],
            'consolidation_plan': [],
            'statistics': {}
        }
        
    def analyze_all_folders(self) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ü–µ–ª–µ–≤—ã–µ –ø–∞–ø–∫–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è.
        
        Returns:
            Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –ø–∞–ø–∫—É
        for folder in self.target_folders:
            folder_path = self.standards_dir / folder
            if folder_path.exists():
                folder_analysis = self._analyze_folder(folder_path, folder)
                self.analysis_results['folders_analyzed'][folder] = folder_analysis
            else:
                logger.warning(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")
        
        # –í—ã—è–≤–ª—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –ø–∞–ø–∫–∞–º–∏
        self._detect_overlaps()
        
        # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏
        self._create_consolidation_plan()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._calculate_statistics()
        
        return self.analysis_results
    
    def _analyze_folder(self, folder_path: Path, folder_name: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤."""
        logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞–ø–∫—É: {folder_name}")
        
        md_files = list(folder_path.rglob('*.md'))
        folder_analysis = {
            'total_files': len(md_files),
            'standards': [],
            'key_themes': set(),
            'methodologies': set()
        }
        
        for md_file in md_files:
            if '[archive]' in str(md_file):
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞—Ä—Ö–∏–≤–Ω—ã–µ —Ñ–∞–π–ª—ã
                
            try:
                content = md_file.read_text(encoding='utf-8', errors='ignore')
                standard_info = self._extract_standard_info(md_file, content)
                folder_analysis['standards'].append(standard_info)
                
                # –°–æ–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã
                folder_analysis['key_themes'].update(standard_info['themes'])
                folder_analysis['methodologies'].update(standard_info['methodologies'])
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞ {md_file}: {e}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º sets –≤ lists –¥–ª—è JSON
        folder_analysis['key_themes'] = list(folder_analysis['key_themes'])
        folder_analysis['methodologies'] = list(folder_analysis['methodologies'])
        
        return folder_analysis
    
    def _extract_standard_info(self, file_path: Path, content: str) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–µ –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞."""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        title = self._extract_title(content)
        themes = self._extract_themes(content)
        methodologies = self._extract_methodologies(content)
        
        return {
            'file': str(file_path),
            'name': file_path.name,
            'title': title,
            'themes': themes,
            'methodologies': methodologies,
            'size': len(content),
            'lines': len(content.split('\n'))
        }
    
    def _extract_title(self, content: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞."""
        lines = content.split('\n')
        for line in lines[:10]:  # –ò—â–µ–º –≤ –ø–µ—Ä–≤—ã—Ö 10 —Å—Ç—Ä–æ–∫–∞—Ö
            if line.startswith('#'):
                return line.strip('# ').strip()
        return "Untitled Standard"
    
    def _extract_themes(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ."""
        themes = set()
        content_lower = content.lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
        theme_keywords = {
            'user-centric': ['–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å', 'user', '–∫–ª–∏–µ–Ω—Ç', 'ux', '—ç–º–ø–∞—Ç–∏—è'],
            'quality': ['–∫–∞—á–µ—Å—Ç–≤–æ', 'quality', 'qa', '—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ', '–ø—Ä–æ–≤–µ—Ä–∫–∞'],
            'communication': ['–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è', '–æ–±—â–µ–Ω–∏–µ', '—Ç–æ–Ω', '—Å—Ç–∏–ª—å', '–¥–∏–∞–ª–æ–≥'],
            'design': ['–¥–∏–∑–∞–π–Ω', '–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å', 'interface', 'ui', '–≤–∏–∑—É–∞–ª'],
            'development': ['—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', '–∫–æ–¥', 'tdd', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', 'dev'],
            'methodology': ['–º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è', '–ø–æ–¥—Ö–æ–¥', '–ø—Ä–æ—Ü–µ—Å—Å', '—Ñ—Ä–µ–π–º–≤–æ—Ä–∫', '—Å—Ç–∞–Ω–¥–∞—Ä—Ç'],
            'b2b': ['b2b', '–±–∏–∑–Ω–µ—Å', '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π', '–∫–æ–º–ø–∞–Ω–∏—è'],
            'automation': ['–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è', 'automation', '—Å–∫—Ä–∏–ø—Ç', 'bot']
        }
        
        for theme, keywords in theme_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                themes.add(theme)
        
        return list(themes)
    
    def _extract_methodologies(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ."""
        methodologies = set()
        content_lower = content.lower()
        
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏
        methodology_patterns = [
            'tdd', 'test-driven', 'red-green-refactor',
            'jtbd', 'jobs to be done',
            'radar', 'comprehensive',
            'registry standard', 'task master',
            'five why', '5 –ø–æ—á–µ–º—É',
            'web qa', 'quality assurance'
        ]
        
        for pattern in methodology_patterns:
            if pattern in content_lower:
                methodologies.add(pattern)
        
        return list(methodologies)
    
    def _detect_overlaps(self):
        """–í—ã—è–≤–ª—è–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –ø–∞–ø–∫–∞–º–∏."""
        logger.info("–í—ã—è–≤–ª—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É –ø–∞–ø–∫–∞–º–∏")
        
        folders = list(self.analysis_results['folders_analyzed'].keys())
        
        for i, folder1 in enumerate(folders):
            for folder2 in folders[i+1:]:
                overlap = self._find_folder_overlap(folder1, folder2)
                if overlap['overlap_score'] > 0.3:  # –ü–æ—Ä–æ–≥ –∑–Ω–∞—á–∏–º–æ–≥–æ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
                    self.analysis_results['detected_overlaps'].append(overlap)
    
    def _find_folder_overlap(self, folder1: str, folder2: str) -> Dict:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –º–µ–∂–¥—É –¥–≤—É–º—è –ø–∞–ø–∫–∞–º–∏."""
        data1 = self.analysis_results['folders_analyzed'][folder1]
        data2 = self.analysis_results['folders_analyzed'][folder2]
        
        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Ç–µ–º
        themes1 = set(data1['key_themes'])
        themes2 = set(data2['key_themes'])
        common_themes = themes1.intersection(themes2)
        
        # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–π
        methods1 = set(data1['methodologies'])
        methods2 = set(data2['methodologies'])
        common_methods = methods1.intersection(methods2)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ü–µ–Ω–∫—É –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
        total_themes = len(themes1.union(themes2))
        total_methods = len(methods1.union(methods2))
        
        overlap_score = 0
        if total_themes > 0:
            overlap_score += len(common_themes) / total_themes * 0.6
        if total_methods > 0:
            overlap_score += len(common_methods) / total_methods * 0.4
        
        return {
            'folder1': folder1,
            'folder2': folder2,
            'common_themes': list(common_themes),
            'common_methodologies': list(common_methods),
            'overlap_score': overlap_score,
            'recommendation': 'consolidate' if overlap_score > 0.5 else 'monitor'
        }
    
    def _create_consolidation_plan(self):
        """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤."""
        logger.info("–°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏")
        
        high_overlap = [o for o in self.analysis_results['detected_overlaps'] 
                       if o['overlap_score'] > 0.5]
        
        for overlap in high_overlap:
            plan_item = {
                'source_folders': [overlap['folder1'], overlap['folder2']],
                'common_elements': {
                    'themes': overlap['common_themes'],
                    'methodologies': overlap['common_methodologies']
                },
                'proposed_unified_standard': self._generate_unified_standard_name(overlap),
                'priority': 'high' if overlap['overlap_score'] > 0.7 else 'medium',
                'complexity': self._estimate_complexity(overlap)
            }
            
            self.analysis_results['consolidation_plan'].append(plan_item)
    
    def _generate_unified_standard_name(self, overlap: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞."""
        themes = overlap['common_themes']
        
        if 'user-centric' in themes and 'quality' in themes:
            return "User-Centric Quality Framework"
        elif 'communication' in themes and 'design' in themes:
            return "Communication & Interface Design Standard"
        elif 'development' in themes and 'methodology' in themes:
            return "Development Methodology Framework"
        else:
            return f"Unified {'-'.join(themes[:2]).title()} Standard"
    
    def _estimate_complexity(self, overlap: Dict) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤."""
        score = overlap['overlap_score']
        
        if score > 0.8:
            return "low"  # –í—ã—Å–æ–∫–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ = –ø—Ä–æ—Å—Ç–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        elif score > 0.6:
            return "medium"
        else:
            return "high"  # –ù–∏–∑–∫–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ = —Å–ª–æ–∂–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    
    def _calculate_statistics(self):
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞."""
        stats = {
            'total_folders_analyzed': len(self.analysis_results['folders_analyzed']),
            'total_standards_found': 0,
            'total_overlaps_detected': len(self.analysis_results['detected_overlaps']),
            'high_priority_consolidations': 0
        }
        
        for folder_data in self.analysis_results['folders_analyzed'].values():
            stats['total_standards_found'] += folder_data['total_files']
        
        stats['high_priority_consolidations'] = len([
            p for p in self.analysis_results['consolidation_plan'] 
            if p['priority'] == 'high'
        ])
        
        self.analysis_results['statistics'] = stats


def analyze_standards_duplication() -> Dict:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤.
    
    Returns:
        Dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    """
    analyzer = StandardsDuplicationAnalyzer()
    return analyzer.analyze_all_folders()


if __name__ == '__main__':
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
    print("=== –ê–ù–ê–õ–ò–ó –î–£–ë–õ–ò–†–£–Æ–©–ò–•–°–Ø –°–¢–ê–ù–î–ê–†–¢–û–í ===")
    
    results = analyze_standards_duplication()
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    stats = results['statistics']
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print(f"\nüîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è:")
    for overlap in results['detected_overlaps']:
        print(f"   {overlap['folder1']} ‚Üî {overlap['folder2']}: "
              f"–æ—Ü–µ–Ω–∫–∞ {overlap['overlap_score']:.2f}")
    
    print(f"\nüìã –ü–ª–∞–Ω –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏:")
    for plan in results['consolidation_plan']:
        print(f"   {plan['proposed_unified_standard']} "
              f"(–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {plan['priority']})")