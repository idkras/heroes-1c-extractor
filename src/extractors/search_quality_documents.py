#!/usr/bin/env python3

import logging
from typing import Any

from src.utils.base_extractor import BaseExtractor

logger = logging.getLogger(__name__)


class QualityDocumentsExtractor(BaseExtractor):
    """
    JTBD:
    –ö–∞–∫ —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞, —è —Ö–æ—á—É –Ω–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–æ–≤–∞—Ä–æ–≤,
    —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ü–≤–µ—Ç–æ–≤ –∏ —Ñ–ª–æ—Ä–∏—Å—Ç–∏–∫–∏.
    """

    def extract(self) -> dict[str, Any] | None:
        """
        JTBD:
        –ö–∞–∫ —Å–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞, —è —Ö–æ—á—É –Ω–∞–π—Ç–∏ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–æ–≤–∞—Ä–æ–≤,
        —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ü–≤–µ—Ç–æ–≤ –∏ —Ñ–ª–æ—Ä–∏—Å—Ç–∏–∫–∏.

        Returns:
            Optional[Dict[str, Any]]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞
        """
        print("üîç –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ '–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–æ–≤–∞—Ä–∞'")
        print("üéØ –¶–ï–õ–¨: –ù–∞–π—Ç–∏ –ø–µ—Ä–≤–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É —Ç–æ–≤–∞—Ä–æ–≤")
        print("=" * 60)

        results: dict[str, Any] = {
            "quality_documents": [],
            "found_keywords": [],
            "metadata": self.create_metadata(),
        }

        print("\nüîç –≠—Ç–∞–ø 1: –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print("-" * 60)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DocumentAnalyzer –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–±–ª–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        document_analysis_results = self.document_analyzer.analyze_document_tables(
            self.db,
            max_tables=15,
        )

        for table_analysis in document_analysis_results:
            table_name = table_analysis.table_name
            record_count = table_analysis.record_count

            print(f"\nüìã –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü—ã: {table_name}")
            print(f"üìä –ó–∞–ø–∏—Å–µ–π: {record_count:,}")

            # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∞–Ω–∞–ª–∏–∑–∞
            quality_records = []
            for doc_analysis in table_analysis.document_analysis:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º KeywordSearcher –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞
                keyword_result = self.keyword_searcher.search_quality_keywords(
                    doc_analysis.sample_data,
                )

                if keyword_result.found_keywords:
                    print(
                        f"    üéØ –ù–∞–π–¥–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keyword_result.found_keywords}",
                    )

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
                    record_index = 0
                    if doc_analysis.analysis_metadata:
                        record_index = doc_analysis.analysis_metadata.get(
                            "record_index",
                            0,
                        )

                    quality_record = {
                        "record_index": record_index,
                        "found_keywords": keyword_result.found_keywords,
                        "fields": doc_analysis.fields,
                        "blob_fields": doc_analysis.blob_fields,
                        "sample_data": doc_analysis.sample_data,
                    }
                    quality_records.append(quality_record)

                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                    for keyword in keyword_result.found_keywords:
                        if keyword not in results["found_keywords"]:
                            results["found_keywords"].append(keyword)

            if quality_records:
                print(
                    f"    ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(quality_records)} –∑–∞–ø–∏—Å–µ–π —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏",
                )

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–±–ª–∏—Ü—ã
                table_analysis_result = {
                    "table_name": table_name,
                    "record_count": record_count,
                    "quality_records": quality_records,
                }
                results["quality_documents"].append(table_analysis_result)

                # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ 5 —Ç–∞–±–ª–∏—Ü —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                if len(results["quality_documents"]) >= 5:
                    break

        print("\nüîç –≠—Ç–∞–ø 2: –ê–Ω–∞–ª–∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤")
        print("-" * 60)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º DocumentAnalyzer –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤
        reference_analysis_results = self.document_analyzer.analyze_reference_tables(
            self.db,
            max_tables=10,
        )

        for table_analysis in reference_analysis_results:
            table_name = table_analysis.table_name
            record_count = table_analysis.record_count

            print(f"üìã {table_name} ({record_count:,} –∑–∞–ø–∏—Å–µ–π)")

            # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∞–Ω–∞–ª–∏–∑–∞
            for doc_analysis in table_analysis.document_analysis:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º KeywordSearcher –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞
                keyword_result = self.keyword_searcher.search_quality_keywords(
                    doc_analysis.sample_data,
                )

                if keyword_result.found_keywords:
                    print(
                        f"    üéØ –ù–∞–π–¥–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keyword_result.found_keywords}",
                    )

                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                    for keyword in keyword_result.found_keywords:
                        if keyword not in results["found_keywords"]:
                            results["found_keywords"].append(keyword)

        print("\nüîç –≠—Ç–∞–ø 3: –ê–Ω–∞–ª–∏–∑ –∂—É—Ä–Ω–∞–ª–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        print("-" * 60)

        # –ò—â–µ–º –∂—É—Ä–Ω–∞–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (—Ç–∞–±–ª–∏—á–Ω—ã–µ —á–∞—Å—Ç–∏)
        if self.db:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç—É–ø–Ω–∞
            if self.db is None:
                logger.warning("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
                return None

            for table_name in self.db.tables.keys():
                table = self.db.tables[table_name]
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 20 –∑–∞–ø–∏—Å–µ–π
                quality_records = []
                for i in range(min(20, len(table))):
                    try:
                        row = table[i]
                        if not row.is_empty:
                            row_data = row.as_dict()

                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º KeywordSearcher –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞
                            keyword_result = (
                                self.keyword_searcher.search_quality_keywords(row_data)
                            )

                            if keyword_result.found_keywords:
                                print(
                                    f"    üéØ –ó–∞–ø–∏—Å—å {i + 1}: –Ω–∞–π–¥–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keyword_result.found_keywords}",
                                )

                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
                                quality_record = {
                                    "record_index": i,
                                    "found_keywords": keyword_result.found_keywords,
                                    "row_data": row_data,
                                }
                                quality_records.append(quality_record)

                                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                                for keyword in keyword_result.found_keywords:
                                    if keyword not in results["found_keywords"]:
                                        results["found_keywords"].append(keyword)

                                # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ –ø–µ—Ä–≤—ã—Ö 5 –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
                                if len(quality_records) >= 5:
                                    break

                    except Exception:
                        print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–∏ {i}: ")
                        continue

                if quality_records:
                    print(
                        f"    ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(quality_records)} –∑–∞–ø–∏—Å–µ–π —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏",
                    )

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∂—É—Ä–Ω–∞–ª–∞
                    journal_analysis = {
                        "table_name": table_name,
                        "record_count": record_count,
                        "quality_records": quality_records,
                    }
                    results["quality_documents"].append(journal_analysis)

                    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ 3 –∂—É—Ä–Ω–∞–ª–æ–≤ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                    if len(results["quality_documents"]) >= 8:
                        break
                else:
                    print("    ‚ö†Ô∏è –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        results["metadata"]["total_quality_documents"] = len(
            results["quality_documents"],
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.save_results("quality_documents_search.json", results)

        print(
            f"üìä –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∫–∞—á–µ—Å—Ç–≤–æ–º: {results['metadata']['total_quality_documents']}",
        )
        print(f"üéØ –ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(results['found_keywords'])}")

        if results["found_keywords"]:
            print(f"üîç –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(results['found_keywords'])}")

        return results


def search_quality_documents() -> dict[str, Any] | None:
    """
    JTBD:
    Returns:
        Optional[Dict[str, Any]]: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞
    """
    extractor = QualityDocumentsExtractor()
    return extractor.run()


if __name__ == "__main__":
    search_quality_documents()
