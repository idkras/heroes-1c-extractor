#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from onec_dtools.database_reader import DatabaseReader
import json
import sys
import os
from datetime import datetime

def safe_get_blob_content(value):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ BLOB –ø–æ–ª—è
    """
    try:
        if hasattr(value, 'value'):
            content = value.value
            if content and len(str(content)) > 0:
                return str(content)
        elif hasattr(value, '__iter__'):
            try:
                iterator = iter(value)
                content = next(iterator)
                if content and len(str(content)) > 0:
                    return str(content)
            except StopIteration:
                pass
        elif hasattr(value, '__bytes__'):
            try:
                content = bytes(value)
                if content and len(content) > 0:
                    return str(content)
            except:
                pass
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è BLOB: {e}"
    
    return None

def analyze_documents_robust():
    """
    –ù–∞–¥–µ–∂–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
    """
    print("üîç –ù–∞–¥–µ–∂–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("=" * 60)
    
    try:
        with open('raw/1Cv8.1CD', 'rb') as f:
            db = DatabaseReader(f)
            
            print(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç–∞ —É—Å–ø–µ—à–Ω–æ!")
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            search_criteria = {
                '–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è': {
                    'conditions': ['–ü—Ä–æ–≤–µ–¥—ë–Ω = –ò—Å—Ç–∏–Ω–∞', '–°–∫–ª–∞–¥–û—Ä–¥–µ—Ä = –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Å–∫–ª–∞–¥', '–ù–æ–º–µ—Ä–ú–∞—à–∏–Ω—ã –∑–∞–ø–æ–ª–Ω–µ–Ω–æ'],
                    'keywords': ['–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ', '–ø—Ä–∏—Ö–æ–¥', '–ø–æ—Å—Ç–∞–≤—â–∏–∫', '–º–∞—à–∏–Ω–∞', '—Å–∫–ª–∞–¥', '–ø–æ—Å—Ç–∞–≤–∫–∞']
                },
                '—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏': {
                    'conditions': ['–ü—Ä–æ–≤–µ–¥—ë–Ω = –ò—Å—Ç–∏–Ω–∞', '–°–¥–µ–ª–∫–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ', '–°—Ç–∞—Ç—É—Å = –û—Ç–≥—Ä—É–∂–µ–Ω'],
                    'keywords': ['—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è', '–ø—Ä–æ–¥–∞–∂–∞', '—Å–¥–µ–ª–∫–∞', '–æ—Ç–≥—Ä—É–∑–∫–∞', '—Ä–æ–∑–Ω–∏—Ü–∞', '–ø—Ä–æ–¥–∞–∂']
                },
                '–æ—Ç—á–µ—Ç—ã_—Ä–æ–∑–Ω–∏—á–Ω—ã—Ö_–ø—Ä–æ–¥–∞–∂': {
                    'conditions': ['–ü—Ä–æ–≤–µ–¥—ë–Ω = –ò—Å—Ç–∏–Ω–∞'],
                    'keywords': ['–æ—Ç—á–µ—Ç', '—Ä–æ–∑–Ω–∏—á–Ω', '–ø—Ä–æ–¥–∞–∂', '–æ—Ä–ø', '—Ä–æ–∑–Ω–∏—Ü–∞']
                },
                '—á–µ–∫–∏_–∫–∫–º': {
                    'conditions': ['–ü—Ä–æ–≤–µ–¥—ë–Ω = –ò—Å—Ç–∏–Ω–∞', '–°—Ç–∞—Ç—É—Å —á–µ–∫–∞ –ö–ö–ú = –ü—Ä–æ–±–∏—Ç—ã–π'],
                    'keywords': ['—á–µ–∫', '–∫–∫–º', '–∫–∞—Å—Å–∞', '—Ä–æ–∑–Ω–∏—á–Ω', '–∫–∞—Å—Å–æ–≤—ã–π']
                },
                '–ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è': {
                    'conditions': ['–ü—Ä–æ–≤–µ–¥—ë–Ω = –ò—Å—Ç–∏–Ω–∞', '–°–∫–ª–∞–¥–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å = –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π —Å–∫–ª–∞–¥', '–°–∫–ª–∞–¥–ü–æ–ª—É—á–∞—Ç–µ–ª—å = –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω'],
                    'keywords': ['–ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ', '–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å', '–ø–æ–ª—É—á–∞—Ç–µ–ª—å', '—Å–∫–ª–∞–¥', '–ø–µ—Ä–µ–º–µ—â']
                },
                '—Å–ø–∏—Å–∞–Ω–∏—è': {
                    'conditions': ['–ü—Ä–æ–≤–µ–¥—ë–Ω = –ò—Å—Ç–∏–Ω–∞', '–°–∫–ª–∞–¥.–í–∏–¥–°–∫–ª–∞–¥–∞ = –†–æ–∑–Ω–∏—á–Ω—ã–π'],
                    'keywords': ['—Å–ø–∏—Å–∞–Ω–∏–µ', '—Ä–æ–∑–Ω–∏—á–Ω', '—Å–∫–ª–∞–¥', '—Å–ø–∏—Å—ã–≤']
                }
            }
            
            results = {
                'documents_found': {},
                'metadata': {
                    'extraction_date': datetime.now().isoformat(),
                    'total_tables_analyzed': 0,
                    'documents_analyzed': 0,
                    'source_file': 'raw/1Cv8.1CD'
                }
            }
            
            # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            document_tables = []
            for table_name in db.tables.keys():
                if '_DOCUMENT' in table_name and '_VT' not in table_name:
                    table = db.tables[table_name]
                    if len(table) > 0:
                        document_tables.append((table_name, len(table)))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
            document_tables.sort(key=lambda x: x[1], reverse=True)
            
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(document_tables)} —Ç–∞–±–ª–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 8 –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü...")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 8 –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
            for table_name, record_count in document_tables[:8]:
                print(f"\nüìã –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü—ã: {table_name}")
                print(f"üìä –ó–∞–ø–∏—Å–µ–π: {record_count:,}")
                
                table = db.tables[table_name]
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 15 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                sample_records = []
                for i in range(min(15, len(table))):
                    try:
                        row = table[i]
                        if not row.is_empty:
                            row_data = row.as_dict()
                            sample_records.append(row_data)
                    except Exception as e:
                        print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–∏ {i}: {e}")
                        continue
                
                if sample_records:
                    print(f"    ‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(sample_records)} –∑–∞–ø–∏—Å–µ–π")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª—è
                    fields = list(sample_records[0].keys())
                    print(f"    üìã –ü–æ–ª—è: {len(fields)}")
                    
                    # –ò—â–µ–º –ø–æ–ª—è —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
                    found_keywords = {}
                    for doc_type, criteria in search_criteria.items():
                        found_keywords[doc_type] = []
                        for keyword in criteria['keywords']:
                            matching_fields = [f for f in fields if keyword.lower() in f.lower()]
                            if matching_fields:
                                found_keywords[doc_type].extend(matching_fields)
                    
                    # –ò—â–µ–º –ø–æ–ª—è —Å —É—Å–ª–æ–≤–∏—è–º–∏
                    found_conditions = {}
                    for doc_type, criteria in search_criteria.items():
                        found_conditions[doc_type] = []
                        for condition in criteria['conditions']:
                            # –ò—â–µ–º –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —É—Å–ª–æ–≤–∏—è–º
                            for field in fields:
                                if any(keyword.lower() in field.lower() for keyword in condition.lower().split()):
                                    found_conditions[doc_type].append((condition, field))
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–µ–π
                    field_values = {}
                    for field in fields[:8]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 8 –ø–æ–ª–µ–π
                        values = []
                        for record in sample_records[:5]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π
                            if field in record:
                                value = record[field]
                                if value is not None and str(value) != '':
                                    values.append(str(value))
                        if values:
                            field_values[field] = list(set(values))[:5]  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    
                    # –ò—â–µ–º BLOB –ø–æ–ª—è
                    blob_fields = []
                    for field in fields:
                        if field.startswith('_FLD'):
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ BLOB –¥–∞–Ω–Ω—ã–µ –≤ —ç—Ç–æ–º –ø–æ–ª–µ
                            for record in sample_records[:3]:
                                if field in record:
                                    value = record[field]
                                    if hasattr(value, 'value') or hasattr(value, '__iter__'):
                                        blob_fields.append(field)
                                        break
                    
                    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
                    document_classification = {}
                    for doc_type, criteria in search_criteria.items():
                        score = 0
                        reasons = []
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –ø–æ–ª—è—Ö
                        if found_keywords[doc_type]:
                            score += len(found_keywords[doc_type]) * 2
                            reasons.append(f"–ù–∞–π–¥–µ–Ω—ã –ø–æ–ª—è: {found_keywords[doc_type]}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è
                        if found_conditions[doc_type]:
                            score += len(found_conditions[doc_type]) * 3
                            reasons.append(f"–ù–∞–π–¥–µ–Ω—ã —É—Å–ª–æ–≤–∏—è: {[c[0] for c in found_conditions[doc_type]]}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–µ–π
                        for field, values in field_values.items():
                            for keyword in criteria['keywords']:
                                if any(keyword.lower() in str(value).lower() for value in values):
                                    score += 1
                                    reasons.append(f"–ó–Ω–∞—á–µ–Ω–∏–µ –≤ –ø–æ–ª–µ {field}: {values}")
                        
                        if score > 0:
                            document_classification[doc_type] = {
                                'score': score,
                                'reasons': reasons,
                                'matching_fields': found_keywords[doc_type],
                                'matching_conditions': found_conditions[doc_type]
                            }
                    
                    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                    if document_classification:
                        print(f"    üéØ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
                        for doc_type, classification in document_classification.items():
                            print(f"      üìÑ {doc_type}: {classification['score']} –±–∞–ª–ª–æ–≤")
                            for reason in classification['reasons'][:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2 –ø—Ä–∏—á–∏–Ω—ã
                                print(f"        - {reason}")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º BLOB –ø–æ–ª—è
                    if blob_fields:
                        print(f"    üîó BLOB –ø–æ–ª—è: {blob_fields}")
                        
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ BLOB –ø–æ–ª–µ–π
                        for blob_field in blob_fields[:2]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 2 BLOB –ø–æ–ª—è
                            print(f"      üìÑ –ê–Ω–∞–ª–∏–∑ {blob_field}:")
                            for i, record in enumerate(sample_records[:3]):
                                try:
                                    value = record[blob_field]
                                    content = safe_get_blob_content(value)
                                    if content:
                                        print(f"        –ó–∞–ø–∏—Å—å {i+1}: {content[:100]}...")
                                except Exception as e:
                                    print(f"        ‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {blob_field}: {e}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    results['documents_found'][table_name] = {
                        'record_count': record_count,
                        'fields': fields,
                        'document_classification': document_classification,
                        'blob_fields': blob_fields,
                        'field_values': field_values,
                        'sample_records': sample_records[:2]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 2 –∑–∞–ø–∏—Å–∏
                    }
                    
                    results['metadata']['total_tables_analyzed'] += 1
                    results['metadata']['documents_analyzed'] += len(sample_records)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            output_file = 'robust_documents_analysis.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
            print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–∞–±–ª–∏—Ü: {results['metadata']['total_tables_analyzed']}")
            print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {results['metadata']['documents_analyzed']}")
            
            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
            print(f"\nüìã –ö–†–ê–¢–ö–ê–Ø –°–í–û–î–ö–ê:")
            for table_name, data in results['documents_found'].items():
                if data['document_classification']:
                    print(f"  üìÑ {table_name}:")
                    for doc_type, classification in data['document_classification'].items():
                        print(f"    - {doc_type}: {classification['score']} –±–∞–ª–ª–æ–≤")
            
            return results
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

if __name__ == "__main__":
    analyze_documents_robust() 