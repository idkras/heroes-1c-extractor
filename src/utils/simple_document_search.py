#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from onec_dtools.database_reader import DatabaseReader
import json
import sys
import os
from datetime import datetime

def simple_document_search():
    """
    –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ BLOB –¥–∞–Ω–Ω—ã—Ö
    """
    print("üîç –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("=" * 60)
    
    try:
        with open('raw/1Cv8.1CD', 'rb') as f:
            db = DatabaseReader(f)
            
            print(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç–∞ —É—Å–ø–µ—à–Ω–æ!")
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            search_criteria = {
                '–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è': {
                    'keywords': ['–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ', '–ø—Ä–∏—Ö–æ–¥', '–ø–æ—Å—Ç–∞–≤—â–∏–∫', '–º–∞—à–∏–Ω–∞', '—Å–∫–ª–∞–¥', '–ø–æ—Å—Ç–∞–≤–∫–∞', '–ø–æ—Å—Ç—É–ø–ª']
                },
                '—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏': {
                    'keywords': ['—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è', '–ø—Ä–æ–¥–∞–∂–∞', '—Å–¥–µ–ª–∫–∞', '–æ—Ç–≥—Ä—É–∑–∫–∞', '—Ä–æ–∑–Ω–∏—Ü–∞', '–ø—Ä–æ–¥–∞–∂', '—Ä–µ–∞–ª–∏–∑']
                },
                '–æ—Ç—á–µ—Ç—ã_—Ä–æ–∑–Ω–∏—á–Ω—ã—Ö_–ø—Ä–æ–¥–∞–∂': {
                    'keywords': ['–æ—Ç—á–µ—Ç', '—Ä–æ–∑–Ω–∏—á–Ω', '–ø—Ä–æ–¥–∞–∂', '–æ—Ä–ø', '—Ä–æ–∑–Ω–∏—Ü–∞', '–æ—Ç—á–µ—Ç']
                },
                '—á–µ–∫–∏_–∫–∫–º': {
                    'keywords': ['—á–µ–∫', '–∫–∫–º', '–∫–∞—Å—Å–∞', '—Ä–æ–∑–Ω–∏—á–Ω', '–∫–∞—Å—Å–æ–≤—ã–π', '—á–µ–∫']
                },
                '–ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è': {
                    'keywords': ['–ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ', '–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å', '–ø–æ–ª—É—á–∞—Ç–µ–ª—å', '—Å–∫–ª–∞–¥', '–ø–µ—Ä–µ–º–µ—â', '–ø–µ—Ä–µ–º–µ—â']
                },
                '—Å–ø–∏—Å–∞–Ω–∏—è': {
                    'keywords': ['—Å–ø–∏—Å–∞–Ω–∏–µ', '—Ä–æ–∑–Ω–∏—á–Ω', '—Å–∫–ª–∞–¥', '—Å–ø–∏—Å—ã–≤', '—Å–ø–∏—Å–∞–Ω–∏–µ']
                }
            }
            
            results = {
                'documents_found': {},
                'metadata': {
                    'extraction_date': datetime.now().isoformat(),
                    'total_tables_analyzed': 0,
                    'documents_analyzed': 0,
                    'source_file': 'raw/1Cv8.1CD'
                }
            }
            
            # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            document_tables = []
            for table_name in db.tables.keys():
                if '_DOCUMENT' in table_name and '_VT' not in table_name:
                    table = db.tables[table_name]
                    if len(table) > 0:
                        document_tables.append((table_name, len(table)))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
            document_tables.sort(key=lambda x: x[1], reverse=True)
            
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(document_tables)} —Ç–∞–±–ª–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü...")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
            for table_name, record_count in document_tables[:10]:
                print(f"\nüìã –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü—ã: {table_name}")
                print(f"üìä –ó–∞–ø–∏—Å–µ–π: {record_count:,}")
                
                table = db.tables[table_name]
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                sample_records = []
                for i in range(min(10, len(table))):
                    try:
                        row = table[i]
                        if not row.is_empty:
                            row_data = row.as_dict()
                            sample_records.append(row_data)
                    except Exception as e:
                        print(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–∏ {i}: {e}")
                        continue
                
                if sample_records:
                    print(f"    ‚úÖ –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(sample_records)} –∑–∞–ø–∏—Å–µ–π")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª—è
                    fields = list(sample_records[0].keys())
                    print(f"    üìã –ü–æ–ª—è: {len(fields)}")
                    
                    # –ò—â–µ–º –ø–æ–ª—è —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
                    found_keywords = {}
                    for doc_type, criteria in search_criteria.items():
                        found_keywords[doc_type] = []
                        for keyword in criteria['keywords']:
                            matching_fields = [f for f in fields if keyword.lower() in f.lower()]
                            if matching_fields:
                                found_keywords[doc_type].extend(matching_fields)
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–µ–π (—Ç–æ–ª—å–∫–æ –ø—Ä–æ—Å—Ç—ã–µ –ø–æ–ª—è)
                    field_values = {}
                    for field in fields[:10]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 –ø–æ–ª–µ–π
                        if not field.startswith('_FLD'):  # –ò—Å–∫–ª—é—á–∞–µ–º BLOB –ø–æ–ª—è
                            values = []
                            for record in sample_records[:5]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π
                                if field in record:
                                    value = record[field]
                                    if value is not None and str(value) != '' and not hasattr(value, 'value'):
                                        values.append(str(value))
                            if values:
                                field_values[field] = list(set(values))[:5]  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    
                    # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
                    document_classification = {}
                    for doc_type, criteria in search_criteria.items():
                        score = 0
                        reasons = []
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –ø–æ–ª—è—Ö
                        if found_keywords[doc_type]:
                            score += len(found_keywords[doc_type]) * 2
                            reasons.append(f"–ù–∞–π–¥–µ–Ω—ã –ø–æ–ª—è: {found_keywords[doc_type]}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª–µ–π
                        for field, values in field_values.items():
                            for keyword in criteria['keywords']:
                                if any(keyword.lower() in str(value).lower() for value in values):
                                    score += 1
                                    reasons.append(f"–ó–Ω–∞—á–µ–Ω–∏–µ –≤ –ø–æ–ª–µ {field}: {values}")
                        
                        if score > 0:
                            document_classification[doc_type] = {
                                'score': score,
                                'reasons': reasons,
                                'matching_fields': found_keywords[doc_type]
                            }
                    
                    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                    if document_classification:
                        print(f"    üéØ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
                        for doc_type, classification in document_classification.items():
                            print(f"      üìÑ {doc_type}: {classification['score']} –±–∞–ª–ª–æ–≤")
                            for reason in classification['reasons'][:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 2 –ø—Ä–∏—á–∏–Ω—ã
                                print(f"        - {reason}")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ –ø–æ–ª—è
                    simple_fields = [f for f in fields if not f.startswith('_FLD')]
                    if simple_fields:
                        print(f"    üìã –ü—Ä–æ—Å—Ç—ã–µ –ø–æ–ª—è: {len(simple_fields)}")
                        print(f"      –ü—Ä–∏–º–µ—Ä—ã: {simple_fields[:5]}")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π
                    key_fields = ['_NUMBER', '_DATE_TIME', '_POSTED', '_MARKED']
                    for key_field in key_fields:
                        if key_field in fields:
                            values = []
                            for record in sample_records[:3]:
                                if key_field in record:
                                    value = record[key_field]
                                    if value is not None and str(value) != '':
                                        values.append(str(value))
                            if values:
                                print(f"      {key_field}: {values}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    results['documents_found'][table_name] = {
                        'record_count': record_count,
                        'fields': fields,
                        'simple_fields': simple_fields,
                        'document_classification': document_classification,
                        'field_values': field_values,
                        'sample_records': sample_records[:2]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 2 –∑–∞–ø–∏—Å–∏
                    }
                    
                    results['metadata']['total_tables_analyzed'] += 1
                    results['metadata']['documents_analyzed'] += len(sample_records)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            output_file = 'simple_documents_search.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
            print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–∞–±–ª–∏—Ü: {results['metadata']['total_tables_analyzed']}")
            print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {results['metadata']['documents_analyzed']}")
            
            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
            print(f"\nüìã –ö–†–ê–¢–ö–ê–Ø –°–í–û–î–ö–ê:")
            for table_name, data in results['documents_found'].items():
                if data['document_classification']:
                    print(f"  üìÑ {table_name}:")
                    for doc_type, classification in data['document_classification'].items():
                        print(f"    - {doc_type}: {classification['score']} –±–∞–ª–ª–æ–≤")
            
            return results
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

if __name__ == "__main__":
    simple_document_search() 