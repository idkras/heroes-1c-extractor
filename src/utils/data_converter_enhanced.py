#!/usr/bin/env python3

"""
DataConverterEnhanced - —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö
–í—ã–¥–µ–ª–µ–Ω –∏–∑ extract_all_available_data.py –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–¥–∞
"""

# import json  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
import os
from typing import Any

import duckdb
import pandas as pd


class DataConverterEnhanced:
    """
    JTBD:
    –ö–∞–∫ —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö, —è —Ö–æ—á—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —É–ª—É—á—à–µ–Ω–Ω—É—é
    —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ
    —Ñ–æ—Ä–º–∞—Ç—ã, —á—Ç–æ–±—ã —É–ø—Ä–æ—Å—Ç–∏—Ç—å extract_all_available_data.py –∏ –æ–±–µ—Å–ø–µ—á–∏—Ç—å
    –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞.
    """

    def __init__(self) -> None:
        self.conversion_stats = {
            "parquet_files_created": 0,
            "duckdb_files_created": 0,
            "json_files_created": 0,
            "total_records_converted": 0,
        }

    def convert_to_parquet(
        self,
        results: dict[str, Any],
        output_dir: str = "data/results/parquet",
    ) -> bool:
        """
        JTBD:
        –ö–∞–∫ —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ Parquet, —è —Ö–æ—á—É –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤ Parquet —Ñ–æ—Ä–º–∞—Ç, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –±—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º
        –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
        """
        try:
            os.makedirs(output_dir, exist_ok=True)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            if results.get("documents"):
                documents_df = self._convert_documents_to_dataframe(
                    results["documents"],
                )
                parquet_file = os.path.join(output_dir, "documents_enhanced.parquet")
                documents_df.to_parquet(parquet_file, index=False)
                print(f"‚úÖ Parquet —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {parquet_file}")
                self.conversion_stats["parquet_files_created"] += 1
                self.conversion_stats["total_records_converted"] += len(documents_df)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏
            if results.get("references"):
                references_df = self._convert_references_to_dataframe(
                    results["references"],
                )
                parquet_file = os.path.join(output_dir, "references_enhanced.parquet")
                references_df.to_parquet(parquet_file, index=False)
                print(f"‚úÖ Parquet —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {parquet_file}")
                self.conversion_stats["parquet_files_created"] += 1
                self.conversion_stats["total_records_converted"] += len(references_df)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–≥–∏—Å—Ç—Ä—ã
            if results.get("registers"):
                registers_df = self._convert_registers_to_dataframe(
                    results["registers"],
                )
                parquet_file = os.path.join(output_dir, "registers_enhanced.parquet")
                registers_df.to_parquet(parquet_file, index=False)
                print(f"‚úÖ Parquet —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {parquet_file}")
                self.conversion_stats["parquet_files_created"] += 1
                self.conversion_stats["total_records_converted"] += len(registers_df)

            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ Parquet: {e}")
            return False

    def convert_to_duckdb(
        self,
        results: dict[str, Any],
        output_dir: str = "data/results/duckdb",
    ) -> bool:
        """
        JTBD:
        –ö–∞–∫ —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ DuckDB, —è —Ö–æ—á—É –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤ DuckDB –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –±—ã—Å—Ç—Ä—ã–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ
        –∑–∞–ø—Ä–æ—Å—ã.
        """
        try:
            os.makedirs(output_dir, exist_ok=True)

            duckdb_file = os.path.join(output_dir, "analysis_enhanced.duckdb")
            con = duckdb.connect(duckdb_file)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            if results.get("documents"):
                documents_df = self._convert_documents_to_dataframe(
                    results["documents"],
                )
                con.execute(
                    "CREATE OR REPLACE TABLE documents_enhanced AS SELECT * FROM documents_df",
                )
                print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ documents_enhanced —Å–æ–∑–¥–∞–Ω–∞ –≤ DuckDB")
                _ = documents_df  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è SQL –∑–∞–ø—Ä–æ—Å–∞

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏
            if results.get("references"):
                references_df = self._convert_references_to_dataframe(
                    results["references"],
                )
                con.execute(
                    "CREATE OR REPLACE TABLE references_enhanced AS SELECT * FROM references_df",
                )
                print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ references_enhanced —Å–æ–∑–¥–∞–Ω–∞ –≤ DuckDB")
                _ = references_df  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è SQL –∑–∞–ø—Ä–æ—Å–∞

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–≥–∏—Å—Ç—Ä—ã
            if results.get("registers"):
                registers_df = self._convert_registers_to_dataframe(
                    results["registers"],
                )
                con.execute(
                    "CREATE OR REPLACE TABLE registers_enhanced AS SELECT * FROM registers_df",
                )
                print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ registers_enhanced —Å–æ–∑–¥–∞–Ω–∞ –≤ DuckDB")
                _ = registers_df  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è SQL –∑–∞–ø—Ä–æ—Å–∞

            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            self._create_duckdb_indexes(con)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã
            self._run_analytical_queries(con)

            con.close()
            print(f"‚úÖ DuckDB –±–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞: {duckdb_file}")
            self.conversion_stats["duckdb_files_created"] += 1
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ DuckDB: {e}")
            return False

    def _convert_documents_to_dataframe(
        self,
        documents: list[dict[str, Any]],
    ) -> pd.DataFrame:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ DataFrame"""
        documents_data = []

        for doc in documents:
            doc_data = {
                "id": doc.get("id", ""),
                "table_name": doc.get("table_name", ""),
                "row_index": doc.get("row_index", 0),
                "document_type": doc.get("document_type", ""),
                "document_number": doc.get("document_number", ""),
                "document_date": doc.get("document_date", ""),
                "total_amount": doc.get("total_amount", 0.0),
                "store_name": doc.get("store_name", ""),
                "store_code": doc.get("store_code", ""),
                "total_blobs": doc.get("extraction_stats", {}).get("total_blobs", 0),
                "successful_blobs": doc.get("extraction_stats", {}).get(
                    "successful",
                    0,
                ),
                "failed_blobs": doc.get("extraction_stats", {}).get("failed", 0),
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—è –∏–∑ fields
            for field_name, value in doc.get("fields", {}).items():
                if isinstance(value, (str, int, float, bool)):
                    doc_data[f"field_{field_name}"] = value
                else:
                    doc_data[f"field_{field_name}"] = str(value)

            documents_data.append(doc_data)

        return pd.DataFrame(documents_data)

    def _convert_references_to_dataframe(
        self,
        references: list[dict[str, Any]],
    ) -> pd.DataFrame:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ –≤ DataFrame"""
        references_data = []

        for ref in references:
            ref_data = {
                "id": ref.get("id", ""),
                "table_name": ref.get("table_name", ""),
                "row_index": ref.get("row_index", 0),
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—è –∏–∑ fields
            for field_name, value in ref.get("fields", {}).items():
                if isinstance(value, (str, int, float, bool)):
                    ref_data[f"field_{field_name}"] = value
                else:
                    ref_data[f"field_{field_name}"] = str(value)

            references_data.append(ref_data)

        return pd.DataFrame(references_data)

    def _convert_registers_to_dataframe(
        self,
        registers: list[dict[str, Any]],
    ) -> pd.DataFrame:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä—ã –≤ DataFrame"""
        registers_data = []

        for reg in registers:
            reg_data = {
                "id": reg.get("id", ""),
                "table_name": reg.get("table_name", ""),
                "row_index": reg.get("row_index", 0),
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—è –∏–∑ fields
            for field_name, value in reg.get("fields", {}).items():
                if isinstance(value, (str, int, float, bool)):
                    reg_data[f"field_{field_name}"] = value
                else:
                    reg_data[f"field_{field_name}"] = str(value)

            registers_data.append(reg_data)

        return pd.DataFrame(registers_data)

    def _create_duckdb_indexes(self, con: duckdb.DuckDBPyConnection) -> None:
        """–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã –≤ DuckDB –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        try:
            # –ò–Ω–¥–µ–∫—Å –ø–æ table_name
            con.execute(
                "CREATE INDEX IF NOT EXISTS idx_table_name_enhanced ON documents_enhanced(table_name)",
            )

            # –ò–Ω–¥–µ–∫—Å –ø–æ document_type
            con.execute(
                "CREATE INDEX IF NOT EXISTS idx_document_type_enhanced ON documents_enhanced(document_type)",
            )

            # –ò–Ω–¥–µ–∫—Å –ø–æ total_amount
            con.execute(
                "CREATE INDEX IF NOT EXISTS idx_total_amount_enhanced ON documents_enhanced(total_amount)",
            )

            print("‚úÖ –ò–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã –≤ DuckDB")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: {e}")

    def _run_analytical_queries(self, con: duckdb.DuckDBPyConnection) -> None:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã"""
        try:
            print("\nüìä –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è):")

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º
            result = con.execute(
                """
                SELECT
                    table_name,
                    COUNT(*) as total_documents,
                    SUM(total_blobs) as total_blobs,
                    AVG(total_blobs) as avg_blobs_per_doc
                FROM documents_enhanced
                GROUP BY table_name
                ORDER BY total_documents DESC
            """,
            ).fetchdf()
            print("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º:")
            print(result)

            # –¢–æ–ø —Ç–∞–±–ª–∏—Ü –ø–æ BLOB –ø–æ–ª—è–º
            result = con.execute(
                """
                SELECT
                    table_name,
                    SUM(successful_blobs) as successful_blobs,
                    SUM(failed_blobs) as failed_blobs,
                    ROUND(SUM(successful_blobs) * 100.0 / (SUM(successful_blobs) + SUM(failed_blobs)), 2) as success_rate
                FROM documents_enhanced
                WHERE successful_blobs + failed_blobs > 0
                GROUP BY table_name
                ORDER BY successful_blobs DESC
                LIMIT 10
            """,
            ).fetchdf()
            print("\nüèÜ –¢–æ–ø —Ç–∞–±–ª–∏—Ü –ø–æ BLOB –ø–æ–ª—è–º:")
            print(result)

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")

    def get_conversion_stats(self) -> dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"""
        return self.conversion_stats.copy()

    def reset_stats(self) -> None:
        """–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"""
        self.conversion_stats = {
            "parquet_files_created": 0,
            "duckdb_files_created": 0,
            "json_files_created": 0,
            "total_records_converted": 0,
        }
