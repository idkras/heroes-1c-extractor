# Common Mistakes Prevention Guide

## Fatal Interview Mistakes & How to Avoid Them

### 1. The "Pitch Trap"
```
‚ùå MISTAKE: Explaining your solution too early
"We're building a tool that helps people like you manage their time better. What do you think?"

‚úÖ CORRECT APPROACH: Understand the problem first
"Tell me about the last time you felt overwhelmed by your schedule."

Prevention Strategy:
- Never mention your solution in the first 20 minutes
- Focus on understanding their current reality
- Ask about problems before presenting solutions
- Use the "documentary filmmaker" mindset
```

### 2. The "Leading Question Trap"
```
‚ùå MISTAKE: Asking questions that guide toward your desired answer
"Don't you think it would be great if you could automate this process?"

‚úÖ CORRECT APPROACH: Neutral, open-ended questions
"How do you currently handle this process?"

Prevention Strategy:
- Start questions with "What," "How," "When," "Where"
- Avoid "Don't you think..." or "Wouldn't you..."
- Never suggest answers within the question
- Practice question neutrality with your team
```

### 3. The "Hypothetical Trap"
```
‚ùå MISTAKE: Asking about future intentions
"Would you pay $50/month for a solution that does X?"

‚úÖ CORRECT APPROACH: Ask about past behavior
"Tell me about the last time you paid for a solution to this problem."

Prevention Strategy:
- Focus on recent, specific experiences
- Ask for concrete examples
- Avoid "would you" or "if you could" questions
- People can't predict their future behavior accurately
```

### 4. The "Feature Voting Trap"
```
‚ùå MISTAKE: Asking customers to prioritize features
"Which of these features would be most valuable to you?"

‚úÖ CORRECT APPROACH: Understand underlying needs
"What's the most important outcome you're trying to achieve?"

Prevention Strategy:
- Don't present feature lists for ranking
- Understand the job to be done first
- Let customers describe their ideal solution
- Focus on outcomes, not features
```

### 5. The "Talking Too Much Trap"
```
‚ùå MISTAKE: Filling silences with your own thoughts
Customer: "Well, I'm not sure..."
You: "I understand, let me explain how our solution works..."

‚úÖ CORRECT APPROACH: Embrace silence
Customer: "Well, I'm not sure..."
You: [Wait 3-5 seconds] "Take your time, what comes to mind?"

Prevention Strategy:
- Track your talk time (aim for <20%)
- Count to 5 before responding to silence
- Use clarifying questions instead of explanations
- Record interviews to review your talk time
```

---

## Survey Design Mistakes

### 1. The "Social Desirability Bias"
```
‚ùå MISTAKE: Questions that encourage "right" answers
"How satisfied are you with our excellent customer service?"

‚úÖ CORRECT APPROACH: Neutral question framing
"How would you rate your experience with our customer service?"

Prevention Strategy:
- Remove emotional language from questions
- Avoid leading adjectives (excellent, poor, amazing)
- Use balanced response scales
- Include neutral options
```

### 2. The "Acquiescence Bias"
```
‚ùå MISTAKE: All positive statements requiring agreement
"Our product is easy to use" (Strongly Agree ‚Üí Strongly Disagree)

‚úÖ CORRECT APPROACH: Mix positive and negative statements
"The product is easy to use" (one question)
"The product is difficult to use" (reverse-scored question)

Prevention Strategy:
- Reverse-score some questions
- Use balanced scales
- Include both positive and negative statements
- Test question order effects
```

### 3. The "Extreme Response Bias"
```
‚ùå MISTAKE: Scales that encourage extreme responses
"Rate from 1-10 where 1 is terrible and 10 is perfect"

‚úÖ CORRECT APPROACH: Meaningful scale points
"Rate from 1-5 where 1 is Very Poor, 3 is Average, 5 is Excellent"

Prevention Strategy:
- Use 5-7 point scales typically
- Label all scale points clearly
- Include neutral midpoints
- Avoid unnecessarily extreme language
```

### 4. The "Question Order Bias"
```
‚ùå MISTAKE: Questions that prime subsequent responses
Q1: "How important is customer service to you?"
Q2: "How satisfied are you with our customer service?"

‚úÖ CORRECT APPROACH: Neutral question ordering
Q1: "How satisfied are you with our customer service?"
Q2: "How important is customer service to you?"

Prevention Strategy:
- Start with specific before general
- Avoid priming sensitive topics
- Randomize question order when possible
- Test different question sequences
```

---

## Sampling Mistakes

### 1. The "Convenience Sample Trap"
```
‚ùå MISTAKE: Only surveying easily accessible customers
- Only current customers
- Only email subscribers
- Only social media followers
- Only satisfied customers

‚úÖ CORRECT APPROACH: Seek diverse perspectives
- Former customers
- Competitor customers
- Non-customers in target market
- Dissatisfied customers

Prevention Strategy:
- Actively recruit hard-to-reach segments
- Use multiple recruitment channels
- Incentivize participation from all groups
- Partner with others to reach new audiences
```

### 2. The "Self-Selection Bias"
```
‚ùå MISTAKE: Relying on volunteers
"Please fill out our survey if you're interested in providing feedback"

‚úÖ CORRECT APPROACH: Proactive recruitment
"We're reaching out to understand your experience with [problem area]"

Prevention Strategy:
- Personally invite specific people
- Use random sampling when possible
- Offer incentives for participation
- Follow up with non-respondents
```

### 3. The "Survivor Bias"
```
‚ùå MISTAKE: Only interviewing successful customers
- Only customers who completed onboarding
- Only customers who achieved success
- Only customers who are still active

‚úÖ CORRECT APPROACH: Include all outcomes
- Customers who churned
- Customers who struggled
- Customers who tried but failed
- Customers who never started

Prevention Strategy:
- Track all customer segments
- Reach out to churned customers
- Interview failed trials
- Understand non-adoption reasons
```

---

## Analysis Mistakes

### 1. The "Confirmation Bias Trap"
```
‚ùå MISTAKE: Looking for evidence that supports your hypothesis
"This quote supports our assumption that price is the main issue"

‚úÖ CORRECT APPROACH: Look for disconfirming evidence
"What evidence contradicts our price hypothesis?"

Prevention Strategy:
- Actively seek contradictory evidence
- Have someone else review your analysis
- Test alternative explanations
- Use structured analysis frameworks
```

### 2. The "Anecdotal Evidence Trap"
```
‚ùå MISTAKE: Making decisions based on single data points
"One customer said they'd pay $100, so we should price at $100"

‚úÖ CORRECT APPROACH: Look for patterns across multiple sources
"5 out of 8 customers mentioned price concerns, with 3 citing $50 as reasonable"

Prevention Strategy:
- Require multiple data points for conclusions
- Track frequency of themes
- Look for consistency across interviews
- Distinguish between individual opinions and patterns
```

### 3. The "Attribution Error Trap"
```
‚ùå MISTAKE: Assuming customer explanations are complete
"They said they chose us because of our features"

‚úÖ CORRECT APPROACH: Dig deeper into decision factors
"What else was influencing your decision at that time?"

Prevention Strategy:
- Ask about context and timing
- Explore unstated factors
- Consider emotional and social influences
- Map the complete decision journey
```

---

## Practical Prevention Checklist

### Before Each Interview
```
‚ñ° Research objective is clear and written down
‚ñ° Questions are open-ended and neutral
‚ñ° Recording equipment is tested
‚ñ° Participant background is researched
‚ñ° Hypothesis list is documented (to check against)
‚ñ° Interview structure is planned but flexible
‚ñ° Follow-up questions are prepared
‚ñ° Success criteria for the interview are defined
```

### During Each Interview
```
‚ñ° Started with rapport building
‚ñ° Got permission to record
‚ñ° Followed 90/10 listening rule
‚ñ° Asked for specific examples
‚ñ° Followed emotional responses
‚ñ° Avoided explaining your solution
‚ñ° Used silence effectively
‚ñ° Took notes on body language and tone
‚ñ° Asked about alternatives and context
‚ñ° Closed with next steps
```

### After Each Interview
```
‚ñ° Reviewed recording within 24 hours
‚ñ° Extracted key quotes verbatim
‚ñ° Identified emotional moments
‚ñ° Noted surprising or contradictory information
‚ñ° Documented follow-up questions
‚ñ° Checked hypotheses against evidence
‚ñ° Identified patterns with previous interviews
‚ñ° Planned next interview improvements
```

---

## Red Flags to Watch For

### In Interviews
```
üö© Participant agrees with everything you say
üö© Responses are very short or vague
üö© No specific examples are provided
üö© Participant seems confused by questions
üö© You're doing most of the talking
üö© Participant is trying to sell you something
üö© You feel like you're not learning anything new
üö© Participant is giving "textbook" answers
```

### In Analysis
```
üö© All findings support your original hypothesis
üö© Findings are based on single data points
üö© You can't find any contradictory evidence
üö© Insights are too general to be actionable
üö© You're making assumptions about customer motivations
üö© Findings don't align with behavioral data
üö© You're explaining away negative feedback
üö© Conclusions require significant leaps of logic
```

---

## Quality Assurance Framework

### Interview Quality Check
```
Post-Interview Quality Score (1-10):
- Participant engagement level
- Specificity of examples shared
- Emotional depth of responses
- Your listening vs. talking ratio
- Quality of follow-up questions
- Actionable insights generated

Minimum Quality Standards:
- At least 5 specific examples gathered
- At least 3 emotional moments captured
- Less than 20% interviewer talk time
- No leading questions asked
- At least 2 surprising insights
```

### Data Quality Validation
```
For each finding:
‚ñ° Is it based on multiple data points?
‚ñ° Is it specific and actionable?
‚ñ° Does it align with observed behavior?
‚ñ° Can it be tested or validated?
‚ñ° Is it differentiated from obvious/common knowledge?
‚ñ° Does it provide new understanding?
‚ñ° Are there any contradictory data points?
‚ñ° What assumptions are we making?
```

---

## Recovery Strategies

### When an Interview Goes Wrong
```
If you realize you're making mistakes during the interview:

1. Acknowledge and reset:
"I realize I've been talking too much. Let me step back and hear your thoughts."

2. Redirect with open questions:
"I'm really interested in your experience. Can you tell me more about that?"

3. Use the remaining time effectively:
"I want to make sure I understand your situation. Walk me through [specific scenario]."

4. Follow up appropriately:
"I'd love to continue this conversation. Would you be open to a brief follow-up?"
```

### When Analysis Reveals Bias
```
If you discover bias in your analysis:

1. Acknowledge the bias:
Document what type of bias occurred and where

2. Reanalyze with awareness:
Review the data with the bias in mind

3. Seek additional perspectives:
Have someone else review your analysis

4. Collect additional data:
Conduct follow-up interviews to validate/challenge findings

5. Adjust your process:
Update your interview guide and analysis framework
```

---

## Training & Practice

### Role-Playing Exercises
```
Practice scenarios:
- Interviewing someone who disagrees with your hypothesis
- Handling a participant who only gives short answers
- Managing a participant who tries to sell you their solution
- Dealing with someone who says "I don't know" to everything
- Interviewing someone who gets emotional about their problem
```

### Skill Development
```
Essential skills to develop:
- Active listening techniques
- Question neutrality
- Silence management
- Emotional intelligence
- Pattern recognition
- Bias awareness
- Note-taking while listening
- Follow-up question generation
```

### Team Training
```
Regular team practices:
- Review interview recordings together
- Practice question techniques
- Role-play difficult scenarios
- Share mistakes and learnings
- Calibrate analysis approaches
- Discuss bias identification
- Review successful interview techniques
```