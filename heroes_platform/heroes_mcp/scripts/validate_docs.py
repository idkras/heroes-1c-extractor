#!/usr/bin/env python3
"""
Documentation Validator
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

JTBD: –ö–∞–∫ —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞, —è —Ö–æ—á—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é,
—á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –µ—ë –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º.
"""

import ast
import re
from datetime import datetime
from pathlib import Path
from typing import Any


class DocValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""

    def __init__(self, project_root: Path):
        """
        Initialize the DocValidator.

        Args:
            project_root: Path to the project root directory
        """
        self.project_root = project_root
        self.results = {
            "docstring_coverage": {},
            "broken_links": [],
            "outdated_docs": [],
            "missing_docs": [],
            "status": "passed",
        }

    def check_docstring_coverage(self) -> dict[str, float]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–∫—Ä—ã—Ç–∏–µ –∫–æ–¥–∞ docstrings"""
        python_files = list(self.project_root.rglob("*.py"))
        documented_functions = 0
        total_functions = 0
        undocumented_items = []

        for py_file in python_files:
            # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            exclude_patterns = [
                "test",
                "migrations",
                "__pycache__",
                ".venv",
                "venv",
                "site-packages",
                ".pytest_cache",
                ".ruff_cache",
                ".mypy_cache",
                ".vscode",
                "htmlcov",
                "test_results",
                "node_modules",
                ".DS_Store",
                "*.egg-info",
                "dist",
                "build",
                ".git",
            ]
            if any(exclude in str(py_file) for exclude in exclude_patterns):
                continue

            try:
                with open(py_file, encoding="utf-8") as f:
                    content = f.read()

                tree = ast.parse(content)

                for node in ast.walk(tree):
                    if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                        total_functions += 1

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ docstring
                        if ast.get_docstring(node):
                            documented_functions += 1
                        else:
                            undocumented_items.append(
                                {
                                    "file": py_file.name,
                                    "name": node.name,
                                    "type": type(node).__name__,
                                    "line": node.lineno,
                                }
                            )

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {py_file}: {e}")

        coverage = (
            (documented_functions / total_functions * 100) if total_functions > 0 else 0
        )

        self.results["docstring_coverage"] = {
            "coverage_percentage": coverage,
            "documented_functions": documented_functions,
            "total_functions": total_functions,
            "undocumented_items": undocumented_items,
        }

        return self.results["docstring_coverage"]  # type: ignore

    def check_broken_links(self) -> list[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–ª–æ–º–∞–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        broken_links = []

        for md_file in self.project_root.rglob("*.md"):
            try:
                with open(md_file, encoding="utf-8") as f:
                    content = f.read()

                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∞–π–ª—ã
                link_pattern = r"\[([^\]]+)\]\(([^)]+)\)"
                links = re.findall(link_pattern, content)

                for link_text, link_url in links:
                    if link_url.startswith(("http", "mailto:", "#")):
                        continue

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                    if link_url.startswith("/"):
                        target_path = self.project_root / link_url[1:]
                    else:
                        target_path = md_file.parent / link_url

                    # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –ø—É—Ç–µ–π —Å –ø—Ä–æ–±–µ–ª–∞–º–∏
                    try:
                        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω—ã–π –ø—É—Ç—å
                        if target_path.exists():
                            continue

                        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —Å URL-–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                        import urllib.parse

                        decoded_url = urllib.parse.unquote(link_url)
                        decoded_path = md_file.parent / decoded_url

                        if decoded_path.exists():
                            continue

                        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–±–µ–ª–æ–≤
                        escaped_url = link_url.replace(" ", "\\ ")
                        escaped_path = md_file.parent / escaped_url

                        if escaped_path.exists():
                            continue

                        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª —Å –∫–∞–≤—ã—á–∫–∞–º–∏
                        quoted_path = md_file.parent / f'"{link_url}"'

                        if quoted_path.exists():
                            continue

                        # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å, —Å—á–∏—Ç–∞–µ–º —Å—Å—ã–ª–∫—É —Å–ª–æ–º–∞–Ω–Ω–æ–π
                        broken_links.append(f"{md_file}: {link_text} -> {link_url}")

                    except Exception as e:
                        # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—É—Ç—å, —Å—á–∏—Ç–∞–µ–º –µ–≥–æ —Å–ª–æ–º–∞–Ω–Ω—ã–º
                        broken_links.append(
                            f"{md_file}: {link_text} -> {link_url} (Error: {e})"
                        )

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {md_file}: {e}")

        self.results["broken_links"] = broken_links
        return broken_links

    def check_outdated_docs(self) -> list[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é"""
        outdated_docs = []

        for md_file in self.project_root.rglob("*.md"):
            try:
                with open(md_file, encoding="utf-8") as f:
                    content = f.read()

                # –ò—â–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                date_pattern = r"Last updated:\s*(\d{4}-\d{2}-\d{2})"
                match = re.search(date_pattern, content)

                if match:
                    last_updated = datetime.strptime(match.group(1), "%Y-%m-%d")
                    days_old = (datetime.now() - last_updated).days

                    # –°—á–∏—Ç–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —É—Å—Ç–∞—Ä–µ–≤—à–µ–π, –µ—Å–ª–∏ –æ–Ω–∞ —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
                    if days_old > 30:
                        outdated_docs.append(f"{md_file}: {days_old} days old")

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥–∞—Ç—ã {md_file}: {e}")

        self.results["outdated_docs"] = outdated_docs
        return outdated_docs

    def check_missing_docs(self) -> list[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é"""
        missing_docs = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ README –≤ –∫–∞–∂–¥–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        exclude_dirs = [
            ".git",
            ".venv",
            "venv",
            "__pycache__",
            ".ruff_cache",
            ".mypy_cache",
            ".pytest_cache",
            ".vscode",
            "htmlcov",
            "test_results",
            "node_modules",
            ".DS_Store",
            "*.egg-info",
            "dist",
            "build",
            "site-packages",
        ]

        for directory in self.project_root.rglob("*"):
            if directory.is_dir() and not any(
                exclude in str(directory) for exclude in exclude_dirs
            ):
                readme_files = list(directory.glob("README*"))
                if not readme_files and directory != self.project_root:
                    missing_docs.append(f"Missing README in {directory}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
        src_path = self.project_root / "src"
        if src_path.exists():
            for py_file in src_path.rglob("*.py"):
                if py_file.name.startswith("_"):
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ docstring –≤ —Ñ–∞–π–ª–µ
                try:
                    with open(py_file, encoding="utf-8") as f:
                        content = f.read()

                    tree = ast.parse(content)
                    module_docstring = ast.get_docstring(tree)

                    if not module_docstring:
                        missing_docs.append(f"Missing module docstring in {py_file}")

                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ {py_file}: {e}")

        self.results["missing_docs"] = missing_docs
        return missing_docs

    def check_code_examples(self) -> list[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–¥–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        code_issues = []

        for md_file in self.project_root.rglob("*.md"):
            try:
                with open(md_file, encoding="utf-8") as f:
                    content = f.read()

                # –ò—â–µ–º –±–ª–æ–∫–∏ –∫–æ–¥–∞
                code_pattern = r"```(\w+)\n(.*?)```"
                matches = re.findall(code_pattern, content, re.DOTALL)

                for lang, code in matches:
                    if lang == "python":
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω—Ç–∞–∫—Å–∏—Å Python –∫–æ–¥–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞
                        # –ò—Å–∫–ª—é—á–∞–µ–º markdown —Ñ–∞–π–ª—ã –∏–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏
                        if not str(md_file).endswith(".md"):
                            try:
                                ast.parse(code)
                            except SyntaxError as e:
                                code_issues.append(
                                    f"{md_file}: Python syntax error - {e}"
                                )

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–æ–¥–∞ –≤ {md_file}: {e}")

        return code_issues

    def check_consistency(self) -> list[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        consistency_issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        for md_file in self.project_root.rglob("*.md"):
            try:
                with open(md_file, encoding="utf-8") as f:
                    content = f.read()

                lines = content.split("\n")
                for i, line in enumerate(lines):
                    if line.startswith("#"):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                        level = len(line) - len(line.lstrip("#"))
                        if level > 4:  # –ù–µ –±–æ–ª–µ–µ 4 —É—Ä–æ–≤–Ω–µ–π –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
                            consistency_issues.append(
                                f"{md_file}:{i + 1}: Too deep heading level ({level})"
                            )

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ {md_file}: {e}")

        return consistency_issues

    def validate_all(self) -> dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        print("üîç Validating documentation...")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        self.check_docstring_coverage()
        self.check_broken_links()
        self.check_outdated_docs()
        self.check_missing_docs()

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        code_issues = self.check_code_examples()
        consistency_issues = self.check_consistency()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        if (
            self.results["docstring_coverage"]["coverage_percentage"] < 80
            or self.results["broken_links"]  # type: ignore
            or len(self.results["outdated_docs"]) > 5  # type: ignore
        ):
            self.results["status"] = "failed"
        elif (
            self.results["docstring_coverage"]["coverage_percentage"] < 90
            or self.results["outdated_docs"]  # type: ignore
            or self.results["missing_docs"]
        ):
            self.results["status"] = "warning"

        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.results["code_issues"] = code_issues
        self.results["consistency_issues"] = consistency_issues

        return self.results

    def generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        report = ["# Documentation Validation Report\n"]
        report.append(f"*Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")

        # –û–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        status_emoji = {"passed": "‚úÖ", "warning": "‚ö†Ô∏è", "failed": "‚ùå"}
        report.append(
            f"## Overall Status: {status_emoji[self.results['status']]} {self.results['status'].upper()}\n"  # type: ignore
        )

        # Docstring coverage
        coverage = self.results["docstring_coverage"]
        report.append("## Docstring Coverage\n")  # type: ignore
        report.append(f"- **Coverage:** {coverage['coverage_percentage']:.1f}%\n")  # type: ignore
        report.append(
            f"- **Documented:** {coverage['documented_functions']}/{coverage['total_functions']}\n"  # type: ignore
        )

        if coverage["undocumented_items"]:  # type: ignore
            report.append("\n### Undocumented Items\n")  # type: ignore
            for item in coverage["undocumented_items"][  # type: ignore
                :10
            ]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10
                report.append(
                    f"- `{item['file']}:{item['line']}` - {item['type']} `{item['name']}`\n"  # type: ignore
                )
            if len(coverage["undocumented_items"]) > 10:  # type: ignore
                report.append(
                    f"- ... and {len(coverage['undocumented_items']) - 10} more\n"  # type: ignore
                )

        # Broken links
        if self.results["broken_links"]:
            report.append("\n## Broken Links\n")  # type: ignore
            for link in self.results["broken_links"][:10]:  # type: ignore
                report.append(f"- {link}\n")  # type: ignore
            if len(self.results["broken_links"]) > 10:  # type: ignore
                report.append(
                    f"- ... and {len(self.results['broken_links']) - 10} more\n"  # type: ignore
                )

        # Outdated docs
        if self.results["outdated_docs"]:
            report.append("\n## Outdated Documentation\n")  # type: ignore
            for doc in self.results["outdated_docs"][:10]:  # type: ignore
                report.append(f"- {doc}\n")  # type: ignore
            if len(self.results["outdated_docs"]) > 10:  # type: ignore
                report.append(
                    f"- ... and {len(self.results['outdated_docs']) - 10} more\n"  # type: ignore
                )

        # Missing docs
        if self.results["missing_docs"]:
            report.append("\n## Missing Documentation\n")  # type: ignore
            for doc in self.results["missing_docs"][:10]:  # type: ignore
                report.append(f"- {doc}\n")  # type: ignore
            if len(self.results["missing_docs"]) > 10:  # type: ignore
                report.append(
                    f"- ... and {len(self.results['missing_docs']) - 10} more\n"  # type: ignore
                )

        # Code issues
        if self.results.get("code_issues"):
            report.append("\n## Code Issues\n")  # type: ignore
            for issue in self.results["code_issues"][:5]:  # type: ignore
                report.append(f"- {issue}\n")  # type: ignore

        # Recommendations
        report.append("\n## Recommendations\n")  # type: ignore
        if coverage["coverage_percentage"] < 80:  # type: ignore
            report.append("- Add docstrings to undocumented functions and classes\n")  # type: ignore
        if self.results["broken_links"]:
            report.append("- Fix broken links in documentation\n")  # type: ignore
        if self.results["outdated_docs"]:
            report.append("- Update outdated documentation\n")  # type: ignore
        if self.results["missing_docs"]:
            report.append("- Add missing README files and module docstrings\n")  # type: ignore

        return "\n".join(report)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞
    script_dir = Path(__file__).parent
    project_root = script_dir.parent

    # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
    validator = DocValidator(project_root)

    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
    results = validator.validate_all()

    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä Documentation Validation Results:")
    print(f"Status: {results['status'].upper()}")
    print(
        f"Docstring Coverage: {results['docstring_coverage']['coverage_percentage']:.1f}%"
    )
    print(f"Broken Links: {len(results['broken_links'])}")
    print(f"Outdated Docs: {len(results['outdated_docs'])}")
    print(f"Missing Docs: {len(results['missing_docs'])}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_path = project_root / "docs" / "validation_report.md"
    report_path.parent.mkdir(exist_ok=True)
    report_path.write_text(validator.generate_report(), encoding="utf-8")

    print(f"\nüìÑ Full report saved to: {report_path}")

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –æ—à–∏–±–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
    if results["status"] == "failed":
        print("\n‚ùå Documentation validation failed!")
        exit(1)
    elif results["status"] == "warning":
        print("\n‚ö†Ô∏è Documentation validation passed with warnings")
    else:
        print("\n‚úÖ Documentation validation passed!")


if __name__ == "__main__":
    main()
