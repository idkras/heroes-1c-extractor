#!/usr/bin/env python3
"""
HeroesGPT Landing Analyzer - –æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ª–µ–Ω–¥–∏–Ω–≥–æ–≤

–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞: HeroesGPT Standard v1.8 + Legacy system analysis
–°—Ç–∞–Ω–¥–∞—Ä—Ç: TDD-doc v2.0 + From-The-End Standard v2.4
–ê–≤—Ç–æ—Ä: AI Assistant
–î–∞—Ç–∞: 15 Aug 2025
"""

import logging
import time
from typing import Any, Optional

import requests
from bs4 import BeautifulSoup

from .heroes_gpt_models import (
    HeroesGPTReport,
    JTBDScenario,
    LandingAnalysis,
    OfferAnalysis,
    create_heroes_gpt_report,
)


class HeroesGPTAnalyzer:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ª–µ–Ω–¥–∏–Ω–≥–æ–≤ HeroesGPT"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
        )

    def analyze_landing_page(self, url: str) -> HeroesGPTReport:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–µ–Ω–¥–∏–Ω–≥ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç"""

        start_time = time.time()

        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            content = self._extract_content(url)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–µ–Ω–¥–∏–Ω–≥
            landing_analysis = self._analyze_landing_basic(url, content, start_time)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ñ—Ñ–µ—Ä—ã
            offers_table = self._analyze_offers(content)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º JTBD —Å—Ü–µ–Ω–∞—Ä–∏–∏
            jtbd_scenarios = self._analyze_jtbd_scenarios(content)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
            segments = self._analyze_segments(content, offers_table)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥
            rating = self._calculate_rating(offers_table, segments)

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = self._generate_recommendations(offers_table, segments)

            # –°–æ–∑–¥–∞–µ–º reflection checkpoints
            reflections = self._create_reflections()

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º narrative coherence
            narrative_coherence = self._calculate_narrative_coherence(
                offers_table, segments
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º self compliance
            self_compliance = self._check_self_compliance(offers_table, segments)

            # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
            report = create_heroes_gpt_report(
                url=url,
                landing_analysis=landing_analysis,
                offers_table=offers_table,
                jtbd_scenarios=jtbd_scenarios,
                segments=segments,
                rating=rating,
                recommendations=recommendations,
                reflections=reflections,
                narrative_coherence_score=narrative_coherence,
                self_compliance_passed=self_compliance,
            )

            return report

        except Exception as e:
            self.logger.error(f"Error analyzing landing page {url}: {e}")
            raise

    def _extract_content(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å –ª–µ–Ω–¥–∏–Ω–≥–∞"""

        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, "html.parser")

            # –£–¥–∞–ª—è–µ–º —Å–∫—Ä–∏–ø—Ç—ã –∏ —Å—Ç–∏–ª–∏
            for script in soup(["script", "style"]):
                script.decompose()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
            text = soup.get_text()

            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = " ".join(chunk for chunk in chunks if chunk)

            return text

        except Exception as e:
            self.logger.error(f"Error extracting content from {url}: {e}")
            raise

    def _analyze_landing_basic(
        self, url: str, content: str, start_time: float
    ) -> LandingAnalysis:
        """–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –ª–µ–Ω–¥–∏–Ω–≥–∞"""

        analysis_time = time.time() - start_time
        content_length = len(content)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –±–∏–∑–Ω–µ—Å–∞
        business_type = self._determine_business_type(content)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å
        main_value_prop = self._extract_main_value_prop(content)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        target_segments = self._extract_target_segments(content)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        price_category = self._determine_price_category(content)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ü–µ–ª—å
        primary_goal = self._determine_primary_goal(content)

        return LandingAnalysis(
            url=url,
            business_type=business_type,
            main_value_prop=main_value_prop,
            target_segments=target_segments,
            analysis_time=analysis_time,
            content_length=content_length,
            price_category=price_category,
            primary_goal=primary_goal,
        )

    def _determine_business_type(self, content: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –±–∏–∑–Ω–µ—Å–∞"""

        content_lower = content.lower()

        # SaaS / Software
        if any(
            word in content_lower
            for word in ["software", "platform", "saas", "app", "tool"]
        ):
            return "B2B SaaS / Software Platform"

        # E-commerce
        if any(
            word in content_lower
            for word in ["shop", "store", "buy", "purchase", "cart"]
        ):
            return "E-commerce / Online Store"

        # Service
        if any(
            word in content_lower
            for word in ["service", "consulting", "agency", "help"]
        ):
            return "Service / Consulting"

        # Product
        if any(word in content_lower for word in ["product", "solution", "system"]):
            return "Product / Solution"

        return "General Business"

    def _extract_main_value_prop(self, content: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å"""

        # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã
        lines = content.split("\n")

        for line in lines[:20]:  # –ü–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫
            line = line.strip()
            if len(line) > 20 and len(line) < 200:
                if any(
                    word in line.lower()
                    for word in ["help", "solve", "provide", "offer", "enable"]
                ):
                    return line

        # Fallback
        return "–û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"

    def _extract_target_segments(self, content: str) -> list[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–ª–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã"""

        segments = []
        content_lower = content.lower()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        segment_keywords = {
            "business": ["business", "company", "enterprise", "corporate"],
            "individuals": ["individual", "person", "user", "customer"],
            "professionals": ["professional", "expert", "specialist"],
            "startups": ["startup", "small business", "entrepreneur"],
            "enterprises": ["enterprise", "large company", "corporation"],
        }

        for segment, keywords in segment_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                segments.append(segment.title())

        return segments if segments else ["General Audience"]

    def _determine_price_category(self, content: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ü–µ–Ω–æ–≤—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é"""

        content_lower = content.lower()

        # –í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–∞
        if any(
            word in content_lower
            for word in ["premium", "enterprise", "professional", "advanced"]
        ):
            return "High-tier"

        # –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞
        if any(word in content_lower for word in ["standard", "business", "pro"]):
            return "Mid-tier"

        # –ù–∏–∑–∫–∞—è —Ü–µ–Ω–∞
        if any(word in content_lower for word in ["basic", "starter", "free", "cheap"]):
            return "Low-tier"

        return "Mid-tier"

    def _determine_primary_goal(self, content: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω—É—é —Ü–µ–ª—å"""

        content_lower = content.lower()

        if any(
            word in content_lower
            for word in ["sign up", "register", "join", "subscribe"]
        ):
            return "–ü—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤"

        if any(word in content_lower for word in ["buy", "purchase", "order"]):
            return "–ü—Ä–æ–¥–∞–∂–∞ –ø—Ä–æ–¥—É–∫—Ç–∞/—É—Å–ª—É–≥–∏"

        if any(word in content_lower for word in ["contact", "call", "email"]):
            return "–ü—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ –ª–∏–¥–æ–≤"

        if any(word in content_lower for word in ["learn", "read", "download"]):
            return "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç"

        return "–ü—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ –≤–Ω–∏–º–∞–Ω–∏—è"

    def _analyze_offers(self, content: str) -> list[OfferAnalysis]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ñ—Ñ–µ—Ä—ã –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ"""

        offers = []
        lines = content.split("\n")

        # –ò—â–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –æ—Ñ—Ñ–µ—Ä—ã
        for line in lines:
            line = line.strip()
            if len(line) > 10 and len(line) < 500:
                if self._is_potential_offer(line):
                    offer = self._create_offer_analysis(line)
                    if offer:
                        offers.append(offer)

        return offers[:20]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 20 –æ—Ñ—Ñ–µ—Ä–∞–º–∏

    def _is_potential_offer(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º –æ—Ñ—Ñ–µ—Ä–æ–º"""

        text_lower = text.lower()

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –æ—Ñ—Ñ–µ—Ä–æ–≤
        offer_keywords = [
            "help",
            "solve",
            "provide",
            "offer",
            "enable",
            "give",
            "make",
            "save",
            "increase",
            "improve",
            "reduce",
            "eliminate",
            "create",
            "build",
            "develop",
            "design",
            "manage",
            "organize",
            "automate",
        ]

        return any(keyword in text_lower for keyword in offer_keywords)

    def _create_offer_analysis(self, text: str) -> Optional[OfferAnalysis]:
        """–°–æ–∑–¥–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –æ—Ñ—Ñ–µ—Ä–∞"""

        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—Ñ—Ñ–µ—Ä–∞
            offer_type = self._determine_offer_type(text)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            quantitative_data = self._extract_quantitative_data(text)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç
            target_segment = self._determine_offer_target_segment(text)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–∏–≥–≥–µ—Ä
            emotional_trigger = self._determine_emotional_trigger(text)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º value/tax rating
            value_tax_rating = self._determine_value_tax_rating(text)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è
            trust_level = self._determine_trust_level(text)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å—Ä–æ—á–Ω–æ—Å—Ç–∏
            urgency_level = self._determine_urgency_level(text)

            return OfferAnalysis(
                offer_text=text[:100] + "..." if len(text) > 100 else text,
                offer_type=offer_type,
                quantitative_data=quantitative_data,
                target_segment=target_segment,
                emotional_trigger=emotional_trigger,
                value_tax_rating=value_tax_rating,
                trust_level=trust_level,
                urgency_level=urgency_level,
            )

        except Exception as e:
            self.logger.warning(f"Error creating offer analysis: {e}")
            return None

    def _determine_offer_type(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –æ—Ñ—Ñ–µ—Ä–∞"""

        text_lower = text.lower()

        if any(word in text_lower for word in ["promise", "guarantee", "assure"]):
            return "–≥–∞—Ä–∞–Ω—Ç–∏—è"

        if any(word in text_lower for word in ["benefit", "advantage", "profit"]):
            return "–≤—ã–≥–æ–¥–∞"

        if any(word in text_lower for word in ["testimonial", "review", "customer"]):
            return "—Å–æ—Ü_–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ"

        if any(word in text_lower for word in ["position", "brand", "identity"]):
            return "–ø–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"

        if any(word in text_lower for word in ["function", "feature", "capability"]):
            return "—Ñ—É–Ω–∫—Ü–∏—è"

        return "–æ–±–µ—â–∞–Ω–∏–µ"

    def _extract_quantitative_data(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""

        import re

        # –ò—â–µ–º —á–∏—Å–ª–∞
        numbers = re.findall(r"\d+", text)
        if numbers:
            return f"{numbers[0]} units"

        # –ò—â–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        percentages = re.findall(r"\d+%", text)
        if percentages:
            return percentages[0]

        return "-"

    def _determine_offer_target_segment(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ü–µ–ª–µ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç –æ—Ñ—Ñ–µ—Ä–∞"""

        text_lower = text.lower()

        if any(word in text_lower for word in ["business", "company", "enterprise"]):
            return "–ë–∏–∑–Ω–µ—Å"

        if any(word in text_lower for word in ["individual", "person", "user"]):
            return "–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"

        if any(word in text_lower for word in ["professional", "expert"]):
            return "–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—ã"

        return "–û–±—â–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è"

    def _determine_emotional_trigger(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç—Ä–∏–≥–≥–µ—Ä"""

        text_lower = text.lower()

        if any(word in text_lower for word in ["fear", "worry", "problem", "issue"]):
            return "–°—Ç—Ä–∞—Ö/–ë–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ"

        if any(word in text_lower for word in ["desire", "want", "need", "wish"]):
            return "–ñ–µ–ª–∞–Ω–∏–µ/–ü–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—å"

        if any(word in text_lower for word in ["success", "achieve", "win"]):
            return "–£—Å–ø–µ—Ö/–î–æ—Å—Ç–∏–∂–µ–Ω–∏–µ"

        if any(word in text_lower for word in ["save", "money", "time", "effort"]):
            return "–≠–∫–æ–Ω–æ–º–∏—è/–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å"

        return "–û–±—â–∏–π –∏–Ω—Ç–µ—Ä–µ—Å"

    def _determine_value_tax_rating(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç value/tax rating"""

        text_lower = text.lower()

        if any(word in text_lower for word in ["free", "save", "gain", "benefit"]):
            return "–í—ã–≥–æ–¥–∞"

        if any(word in text_lower for word in ["cost", "price", "pay", "fee"]):
            return "–ù–∞–ª–æ–≥"

        return "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π"

    def _determine_trust_level(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è"""

        text_lower = text.lower()

        if any(
            word in text_lower for word in ["guarantee", "proven", "tested", "trusted"]
        ):
            return "–í—ã—Å–æ–∫–∞—è"

        if any(word in text_lower for word in ["maybe", "might", "could", "possibly"]):
            return "–ù–∏–∑–∫–∞—è"

        return "–°—Ä–µ–¥–Ω—è—è"

    def _determine_urgency_level(self, text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Å—Ä–æ—á–Ω–æ—Å—Ç–∏"""

        text_lower = text.lower()

        if any(word in text_lower for word in ["now", "today", "immediate", "urgent"]):
            return "–í—ã—Å–æ–∫–∞—è"

        if any(word in text_lower for word in ["soon", "quick", "fast"]):
            return "–°—Ä–µ–¥–Ω—è—è"

        return "–ù–∏–∑–∫–∞—è"

    def _analyze_jtbd_scenarios(self, content: str) -> list[JTBDScenario]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç JTBD —Å—Ü–µ–Ω–∞—Ä–∏–∏"""

        # –ë–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
        scenarios = []

        # –ü—Ä–∏–º–µ—Ä JTBD —Å—Ü–µ–Ω–∞—Ä–∏—è
        scenarios.append(
            JTBDScenario(
                big_jtbd="–£–ª—É—á—à–∏—Ç—å –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å—ã",
                when_trigger="–ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É",
                medium_jtbd="–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä—É—Ç–∏–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏",
                small_jtbd="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏",
                implementing_files="landing_page_analysis",
                status="identified",
                relevance_score=7,
            )
        )

        return scenarios

    def _analyze_segments(
        self, content: str, offers: list[OfferAnalysis]
    ) -> dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ü–µ–ª–µ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã"""

        segments = {}

        # –ë–∞–∑–æ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        segments["General Business"] = {
            "characteristics": "–û–±—â–∏–π –±–∏–∑–Ω–µ—Å-—Å–µ–≥–º–µ–Ω—Ç",
            "pain_points": ["–ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", "–ü–æ—Ç–µ—Ä—è –≤—Ä–µ–º–µ–Ω–∏"],
            "motivation": "–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤",
            "relevant_offers": [offer.offer_text for offer in offers[:3]],
            "relevance": "üü° –°—Ä–µ–¥–Ω—è—è",
        }

        return segments

    def _calculate_rating(
        self, offers: list[OfferAnalysis], segments: dict[str, Any]
    ) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥ –ª–µ–Ω–¥–∏–Ω–≥–∞"""

        # –ë–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞
        base_score: float = 3.0

        # –ë–æ–Ω—É—Å—ã –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ñ—Ñ–µ—Ä–æ–≤
        if len(offers) >= 10:
            base_score += 1
        elif len(offers) >= 5:
            base_score += 0.5

        # –ë–æ–Ω—É—Å—ã –∑–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ç–∏–ø–æ–≤ –æ—Ñ—Ñ–µ—Ä–æ–≤
        offer_types = {offer.offer_type for offer in offers}
        if len(offer_types) >= 4:
            base_score += 0.5

        # –ë–æ–Ω—É—Å—ã –∑–∞ —Å–µ–≥–º–µ–Ω—Ç—ã
        if len(segments) >= 2:
            base_score += 0.5

        return min(5, max(1, int(base_score)))

    def _generate_recommendations(
        self, offers: list[OfferAnalysis], segments: dict[str, Any]
    ) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""

        recommendations = []

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
        if len(offers) < 5:
            recommendations.append("–î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –æ—Ñ—Ñ–µ—Ä–æ–≤ –∏ –æ–±–µ—â–∞–Ω–∏–π")

        offer_types = {offer.offer_type for offer in offers}
        if len(offer_types) < 3:
            recommendations.append("–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—Ç—å —Ç–∏–ø—ã –æ—Ñ—Ñ–µ—Ä–æ–≤")

        if len(segments) < 2:
            recommendations.append("–†–∞—Å—à–∏—Ä–∏—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∞—É–¥–∏—Ç–æ—Ä–∏–∏")

        return recommendations

    def _create_reflections(self) -> list[Any]:
        """–°–æ–∑–¥–∞–µ—Ç reflection checkpoints"""

        # –ë–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
        return []

    def _calculate_narrative_coherence(
        self, offers: list[OfferAnalysis], segments: dict[str, Any]
    ) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç narrative coherence score"""

        # –ë–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞
        base_score = 5

        if len(offers) >= 5:
            base_score += 2

        if len(segments) >= 2:
            base_score += 1

        return min(10, max(1, base_score))

    def _check_self_compliance(
        self, offers: list[OfferAnalysis], segments: dict[str, Any]
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç self compliance"""

        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        return len(offers) > 0 and len(segments) > 0
