#!/usr/bin/env python3
"""
Typography Checker for ProductHeroes Content
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ tone-offers policy standard v2.2

JTBD: –ö–∞–∫ –∫–æ–Ω—Ç–µ–Ω—Ç-–º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥, —è —Ö–æ—á—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É —Ç–µ–∫—Å—Ç–∞,
—á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º ProductHeroes –∏ —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.

TDD Documentation Standard v2.5 Compliance:
- Atomic Functions Architecture (‚â§20 —Å—Ç—Ä–æ–∫ –Ω–∞ —Ñ—É–Ω–∫—Ü–∏—é)
- Security First (–≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
- Modern Python Development (type hints, dataclasses)
- Testing Pyramid Compliance (unit, integration, e2e)
"""

import logging
import re
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class TypographyIssue:
    """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫—É—é –æ—à–∏–±–∫—É"""

    issue_type: str
    position: int
    original: str
    suggestion: str
    severity: str  # "critical", "warning", "info"


@dataclass
class TypographyReport:
    """–û—Ç—á–µ—Ç –æ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫–∏"""

    text_length: int
    issues_found: list[TypographyIssue]
    issues_count: int
    critical_count: int
    warning_count: int
    info_count: int
    score: float  # 0-100
    suggestions: list[str]


class TypographyChecker:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É ProductHeroes
    """

    def __init__(self):
        # –ù–∞–±–æ—Ä –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤
        self.short_words = {
            # –†—É—Å—Å–∫–∏–π
            "ru": [
                "–≤",
                "–Ω–∞",
                "–∫",
                "—Å",
                "–æ",
                "—É",
                "–∏",
                "–∞",
                "–Ω–æ",
                "–ø–æ",
                "–±–µ–∑",
                "–¥–æ",
                "–∏–∑",
                "–æ—Ç",
                "–∑–∞",
                "–¥–ª—è",
                "–Ω–∞–¥",
                "–ø–æ–¥",
                "–ø—Ä–∏",
                "–æ–±",
                "–ø—Ä–æ",
                "—á–µ—Ä–µ–∑",
                "–º–µ–∂–¥—É",
                "–∂–µ",
                "–±—ã",
                "–ª–∏",
                "—Ç–æ",
                "–¥–µ",
            ],
            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
            "en": [
                "a",
                "an",
                "the",
                "of",
                "in",
                "on",
                "at",
                "by",
                "for",
                "and",
                "or",
                "but",
                "so",
                "yet",
                "to",
                "as",
            ],
            # –§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π
            "fr": [
                "√†",
                "de",
                "du",
                "des",
                "le",
                "la",
                "les",
                "et",
                "ou",
                "mais",
                "en",
                "au",
                "aux",
                "sur",
                "par",
                "pour",
            ],
            # –ò—Å–ø–∞–Ω—Å–∫–∏–π
            "es": [
                "a",
                "de",
                "del",
                "la",
                "el",
                "los",
                "las",
                "y",
                "o",
                "pero",
                "en",
                "por",
                "con",
                "sin",
                "para",
            ],
            # –ù–µ–º–µ—Ü–∫–∏–π
            "de": [
                "der",
                "die",
                "das",
                "ein",
                "eine",
                "und",
                "oder",
                "aber",
                "im",
                "am",
                "an",
                "zu",
                "vom",
                "aus",
                "bei",
                "mit",
            ],
            # –ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π
            "it": [
                "a",
                "da",
                "di",
                "del",
                "della",
                "dell",
                "dei",
                "degli",
                "e",
                "o",
                "ma",
                "per",
                "in",
                "su",
                "con",
                "senza",
            ],
        }

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–ª–∏–Ω–µ (–¥–ª–∏–Ω–Ω—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        self.all_short_words = sorted(
            set(sum(self.short_words.values(), [])), key=len, reverse=True
        )

        # –°—Ç—Ä–æ–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞
        self.short_words_pattern = (
            r"\b(" + "|".join(re.escape(word) for word in self.all_short_words) + r")\s"
        )

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫–∏
        self.patterns = {
            "quotes": {
                "external": r'"([^"]*)"',  # –í–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —ë–ª–æ—á–∫–∞–º–∏
                "internal": r"'([^']*)'",  # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ª–∞–ø–∫–∞–º–∏
                "wrong_quotes": r'["\']([^"\']*)["\']',  # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
            },
            "dashes": {
                "short_dash": r"\s+-\s+",  # –ö–æ—Ä–æ—Ç–∫–æ–µ —Ç–∏—Ä–µ –≤–º–µ—Å—Ç–æ –¥–ª–∏–Ω–Ω–æ–≥–æ
                "wrong_dash": r"[‚Äì‚Äî]",  # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏—Ä–µ
            },
            "brackets": {
                "spaces_inside": r"\(\s+|\s+\)",  # –ü—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —Å–∫–æ–±–æ–∫
                "missing_spaces": r"[–∞-—è—ëa-z]\(",  # –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–±–µ–ª–∞ –ø–µ—Ä–µ–¥ —Å–∫–æ–±–∫–æ–π
            },
            "numbers": {
                "percent_no_space": r"(\d+)\s*%",  # –ü—Ä–æ—Ü–µ–Ω—Ç—ã –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞
                "currency_no_space": r"(\d+)\s*[‚ÇΩ$‚Ç¨¬£]",  # –í–∞–ª—é—Ç–∞ –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞
                "units_no_space": r"(\d+)\s*(–∫–≥|–º|—Å–º|–º–º|–∫–º|–ª|–º–ª|–≥|–º–≥|–∫–≤\.–º|–∫—É–±\.–º)",  # –ï–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞
            },
            "initials": {
                "no_nbsp": r"([–ê-–Ø])\.\s+([–ê-–Ø])\.",  # –ò–Ω–∏—Ü–∏–∞–ª—ã –±–µ–∑ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
            },
        }

    def check_text(self, text: str) -> TypographyReport:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º –ø—Ä–∞–≤–∏–ª–∞–º

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

        Returns:
            TypographyReport —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        if not text or not isinstance(text, str):
            raise ValueError("Text must be a non-empty string")

        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–ø –æ—à–∏–±–æ–∫
        issues.extend(self._check_quotes(text))
        issues.extend(self._check_dashes(text))
        issues.extend(self._check_brackets(text))
        issues.extend(self._check_numbers(text))
        issues.extend(self._check_initials(text))
        issues.extend(self._check_short_words(text))

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        critical_count = sum(1 for issue in issues if issue.severity == "critical")
        warning_count = sum(1 for issue in issues if issue.severity == "warning")
        info_count = sum(1 for issue in issues if issue.severity == "info")

        # –í—ã—á–∏—Å–ª—è–µ–º –æ—Ü–µ–Ω–∫—É (0-100)
        total_issues = len(issues)
        if total_issues == 0:
            score = 100.0
        else:
            # –®—Ç—Ä–∞—Ñ—ã: critical = -10, warning = -5, info = -1
            penalty = critical_count * 10 + warning_count * 5 + info_count * 1
            score = max(0, 100 - penalty)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        suggestions = self._generate_suggestions(issues)

        return TypographyReport(
            text_length=len(text),
            issues_found=issues,
            issues_count=total_issues,
            critical_count=critical_count,
            warning_count=warning_count,
            info_count=info_count,
            score=score,
            suggestions=suggestions,
        )

    def fix_text(self, text: str) -> str:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

        Returns:
            –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not text or not isinstance(text, str):
            raise ValueError("Text must be a non-empty string")

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏
        text = re.sub(self.patterns["quotes"]["external"], r"¬´\1¬ª", text)
        text = re.sub(self.patterns["quotes"]["internal"], r'"\1"', text)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–∏—Ä–µ
        text = re.sub(self.patterns["dashes"]["short_dash"], r" ‚Äî ", text)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ —Å–∫–æ–±–∫–∞—Ö
        text = re.sub(r"\(\s+", r"(", text)
        text = re.sub(r"\s+\)", r")", text)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω–∏—Ü–∏–∞–ª—ã
        text = re.sub(
            self.patterns["initials"]["no_nbsp"], r"\1. " + "\u00a0" + r"\2.", text
        )

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤
        text = re.sub(
            self.short_words_pattern,
            lambda m: m.group(1) + "\u00a0",
            text,
            flags=re.IGNORECASE,
        )

        return text

    def _check_quotes(self, text: str) -> list[TypographyIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–≤—ã—á–µ–∫"""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
        for match in re.finditer(self.patterns["quotes"]["external"], text):
            issues.append(
                TypographyIssue(
                    issue_type="external_quotes",
                    position=match.start(),
                    original=match.group(0),
                    suggestion=f"¬´{match.group(1)}¬ª",
                    severity="warning",
                )
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
        for match in re.finditer(self.patterns["quotes"]["internal"], text):
            issues.append(
                TypographyIssue(
                    issue_type="internal_quotes",
                    position=match.start(),
                    original=match.group(0),
                    suggestion=f'"{match.group(1)}"',
                    severity="info",
                )
            )

        return issues

    def _check_dashes(self, text: str) -> list[TypographyIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–∏—Ä–µ"""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ —Ç–∏—Ä–µ
        for match in re.finditer(self.patterns["dashes"]["short_dash"], text):
            issues.append(
                TypographyIssue(
                    issue_type="short_dash",
                    position=match.start(),
                    original=match.group(0),
                    suggestion=" ‚Äî ",
                    severity="warning",
                )
            )

        return issues

    def _check_brackets(self, text: str) -> list[TypographyIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∫–æ–±–æ–∫"""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —Å–∫–æ–±–æ–∫
        for match in re.finditer(self.patterns["brackets"]["spaces_inside"], text):
            issues.append(
                TypographyIssue(
                    issue_type="bracket_spaces",
                    position=match.start(),
                    original=match.group(0),
                    suggestion=match.group(0).strip(),
                    severity="info",
                )
            )

        return issues

    def _check_numbers(self, text: str) -> list[TypographyIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è —á–∏—Å–µ–ª"""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        for match in re.finditer(self.patterns["numbers"]["percent_no_space"], text):
            issues.append(
                TypographyIssue(
                    issue_type="percent_format",
                    position=match.start(),
                    original=match.group(0),
                    suggestion=f"{match.group(1)}%",
                    severity="info",
                )
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª—é—Ç—É
        for match in re.finditer(self.patterns["numbers"]["currency_no_space"], text):
            issues.append(
                TypographyIssue(
                    issue_type="currency_format",
                    position=match.start(),
                    original=match.group(0),
                    suggestion=f"{match.group(1)}\u00a0{match.group(2)}",
                    severity="info",
                )
            )

        return issues

    def _check_initials(self, text: str) -> list[TypographyIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∏–Ω–∏—Ü–∏–∞–ª–æ–≤"""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–∏—Ü–∏–∞–ª—ã –±–µ–∑ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        for match in re.finditer(self.patterns["initials"]["no_nbsp"], text):
            issues.append(
                TypographyIssue(
                    issue_type="initials_nbsp",
                    position=match.start(),
                    original=match.group(0),
                    suggestion=f"{match.group(1)}.\u00a0{match.group(2)}.",
                    severity="warning",
                )
            )

        return issues

    def _check_short_words(self, text: str) -> list[TypographyIssue]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤"""
        issues = []

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ –±–µ–∑ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        for match in re.finditer(self.short_words_pattern, text, flags=re.IGNORECASE):
            word = match.group(1)
            if not text[match.end() - 1 : match.end()] == "\u00a0":
                issues.append(
                    TypographyIssue(
                        issue_type="short_word_nbsp",
                        position=match.start(),
                        original=f"{word} ",
                        suggestion=f"{word}\u00a0",
                        severity="info",
                    )
                )

        return issues

    def _generate_suggestions(self, issues: list[TypographyIssue]) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º"""
        suggestions = []

        if not issues:
            suggestions.append(
                "‚úÖ –¢–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º ProductHeroes"
            )
            return suggestions

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—ã –ø–æ —Ç–∏–ø–∞–º
        issue_types = {}
        for issue in issues:
            if issue.issue_type not in issue_types:
                issue_types[issue.issue_type] = []
            issue_types[issue.issue_type].append(issue)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if "external_quotes" in issue_types:
            suggestions.append(
                "üîß –ó–∞–º–µ–Ω–∏—Ç–µ –ø—Ä—è–º—ã–µ –∫–∞–≤—ã—á–∫–∏ –Ω–∞ —ë–ª–æ—á–∫–∏ (¬´¬ª) –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö —Ü–∏—Ç–∞—Ç"
            )

        if "short_dash" in issue_types:
            suggestions.append("üîß –ó–∞–º–µ–Ω–∏—Ç–µ –¥–µ—Ñ–∏—Å—ã –Ω–∞ –¥–ª–∏–Ω–Ω–æ–µ —Ç–∏—Ä–µ (‚Äî) –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏")

        if "initials_nbsp" in issue_types:
            suggestions.append("üîß –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É –∏–Ω–∏—Ü–∏–∞–ª–∞–º–∏")

        if "short_word_nbsp" in issue_types:
            suggestions.append("üîß –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤")

        if "bracket_spaces" in issue_types:
            suggestions.append("üîß –£–±–µ—Ä–∏—Ç–µ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ —Å–∫–æ–±–æ–∫")

        if "currency_format" in issue_types:
            suggestions.append(
                "üîß –î–æ–±–∞–≤—å—Ç–µ –Ω–µ—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É —á–∏—Å–ª–∞–º–∏ –∏ –≤–∞–ª—é—Ç–æ–π"
            )

        return suggestions


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
typography_checker = TypographyChecker()


def check_typography(text: str) -> TypographyReport:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É —Ç–µ–∫—Å—Ç–∞

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

    Returns:
        TypographyReport —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    return typography_checker.check_text(text)


def fix_typography(text: str) -> str:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è

    Returns:
        –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    return typography_checker.fix_text(text)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    test_text = (
        '–ê. –°. –ü—É—à–∫–∏–Ω –∂–∏–ª –≤ –ú–æ—Å–∫–≤–µ –∏ –ø–∏—Å–∞–ª –æ "–ª—é–±–≤–∏". 100 –∫–≥ –≤–µ—Å–∞ –∏ 200 –º–ª–Ω –¥–æ–ª–ª–∞—Ä–æ–≤.'
    )

    print("–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç:")
    print(test_text)
    print()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É
    report = check_typography(test_text)
    print(f"–û—Ü–µ–Ω–∫–∞ —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫–∏: {report.score:.1f}/100")
    print(f"–ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {report.issues_count}")
    print()

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    for suggestion in report.suggestions:
        print(suggestion)
    print()

    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
    fixed_text = fix_typography(test_text)
    print("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:")
    print(fixed_text)
