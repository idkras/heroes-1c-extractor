#!/usr/bin/env python3
"""
Expert Review for HeroesGPT Landing Analysis
–≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–Ω–¥–∏–Ω–≥–æ–≤

JTBD: –Ø —Ö–æ—á—É –ø–æ–ª—É—á–∞—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–Ω–¥–∏–Ω–≥–æ–≤,
—á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º.
"""

import asyncio
import logging
from datetime import datetime
from typing import Any

logger = logging.getLogger(__name__)


class ExpertReview:
    """–≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è HeroesGPT –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–Ω–¥–∏–Ω–≥–æ–≤"""

    def __init__(self):
        self.standard_version = "v1.8"
        self.review_criteria = [
            "quality_assessment",
            "standard_compliance",
            "expert_validation",
            "recommendations",
        ]

    async def execute_expert_review(
        self,
        analysis_data: dict[str, Any],
        review_standard: str = "Ilya Krasinsky Review Standard v1.2",
    ) -> dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –∞–Ω–∞–ª–∏–∑–∞

        Args:
            analysis_data: –î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–Ω–¥–∏–Ω–≥–∞
            review_standard: –°—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
        """
        try:
            logger.info(f"üîç Starting expert review with standard: {review_standard}")

            # Quality Assessment
            quality_assessment = await self._assess_quality(analysis_data)

            # Standard Compliance Check
            compliance_check = await self._check_standard_compliance(
                analysis_data, review_standard
            )

            # Expert Validation
            expert_validation = await self._perform_expert_validation(analysis_data)

            # Generate Recommendations
            recommendations = await self._generate_expert_recommendations(
                analysis_data, quality_assessment, compliance_check, expert_validation
            )

            # Calculate Overall Score
            overall_score = await self._calculate_overall_score(
                quality_assessment, compliance_check, expert_validation
            )

            result = {
                "success": True,
                "review_standard": review_standard,
                "overall_score": overall_score,
                "quality_assessment": quality_assessment,
                "compliance_check": compliance_check,
                "expert_validation": expert_validation,
                "recommendations": recommendations,
                "review_timestamp": datetime.now().isoformat(),
                "reviewer": "Ilya Krasinsky Review Standard v1.2",
            }

            logger.info(f"‚úÖ Expert review completed with score: {overall_score}")
            return result

        except Exception as e:
            logger.error(f"Error in execute_expert_review: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    async def _assess_quality(self, analysis_data: dict[str, Any]) -> dict[str, Any]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞"""

        logger.info("üìä Assessing analysis quality")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        landing_url = analysis_data.get("landing_url", "")
        stages = analysis_data.get("stages", {})
        offers = analysis_data.get("offers", [])
        segments = analysis_data.get("segments", [])
        reflections = analysis_data.get("reflections", [])

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø–æ–ª–Ω–æ—Ç—É –∞–Ω–∞–ª–∏–∑–∞
        completeness_score = self._calculate_completeness_score(
            stages, offers, segments
        )

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –≥–ª—É–±–∏–Ω—É –∞–Ω–∞–ª–∏–∑–∞
        depth_score = self._calculate_depth_score(analysis_data)

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
        structure_score = self._calculate_structure_score(analysis_data)

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ä–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω–æ—Å—Ç—å
        reflection_score = self._calculate_reflection_score(reflections)

        # –û–±—â–∏–π —Å–∫–æ—Ä –∫–∞—á–µ—Å—Ç–≤–∞
        quality_score = (
            completeness_score + depth_score + structure_score + reflection_score
        ) / 4

        return {
            "overall_quality_score": quality_score,
            "completeness_score": completeness_score,
            "depth_score": depth_score,
            "structure_score": structure_score,
            "reflection_score": reflection_score,
            "quality_grade": self._get_quality_grade(quality_score),
            "quality_notes": self._generate_quality_notes(
                quality_score, completeness_score, depth_score
            ),
        }

    def _calculate_completeness_score(
        self, stages: dict[str, Any], offers: list[dict[str, Any]], segments: list[str]
    ) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–∫–æ—Ä –ø–æ–ª–Ω–æ—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""

        # –ë–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä
        base_score = 0.0

        # –ë–æ–Ω—É—Å—ã –∑–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã
        completed_stages = len(
            [s for s in stages.values() if s.get("completed", False)]
        )
        if completed_stages >= 5:
            base_score += 0.3
        elif completed_stages >= 3:
            base_score += 0.2
        else:
            base_score += 0.1

        # –ë–æ–Ω—É—Å—ã –∑–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        if len(offers) >= 5:
            base_score += 0.3
        elif len(offers) >= 3:
            base_score += 0.2
        elif len(offers) >= 1:
            base_score += 0.1

        # –ë–æ–Ω—É—Å—ã –∑–∞ —Å–µ–≥–º–µ–Ω—Ç—ã
        if len(segments) >= 3:
            base_score += 0.2
        elif len(segments) >= 2:
            base_score += 0.15
        elif len(segments) >= 1:
            base_score += 0.1

        # –ë–æ–Ω—É—Å –∑–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏—é
        if len(stages) > 0:
            base_score += 0.2

        return min(base_score, 1.0)

    def _calculate_depth_score(self, analysis_data: dict[str, Any]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–∫–æ—Ä –≥–ª—É–±–∏–Ω—ã –∞–Ω–∞–ª–∏–∑–∞"""

        depth_indicators = 0
        total_indicators = 0

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        stages = analysis_data.get("stages", {})
        for stage_name, stage_data in stages.items():
            total_indicators += 1
            if stage_data.get("completed", False) and len(str(stage_data)) > 100:
                depth_indicators += 1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        offers = analysis_data.get("offers", [])
        if offers:
            total_indicators += 1
            detailed_offers = [offer for offer in offers if len(str(offer)) > 50]
            if len(detailed_offers) >= len(offers) * 0.7:
                depth_indicators += 1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        segments = analysis_data.get("segments", [])
        if segments:
            total_indicators += 1
            if len(segments) >= 2:
                depth_indicators += 1

        return depth_indicators / total_indicators if total_indicators > 0 else 0.0

    def _calculate_structure_score(self, analysis_data: dict[str, Any]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–∫–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏"""

        structure_indicators = 0
        total_indicators = 4

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        if analysis_data.get("landing_url"):
            structure_indicators += 1

        if analysis_data.get("stages"):
            structure_indicators += 1

        if analysis_data.get("offers"):
            structure_indicators += 1

        if analysis_data.get("segments"):
            structure_indicators += 1

        return structure_indicators / total_indicators

    def _calculate_reflection_score(self, reflections: list[dict[str, Any]]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–∫–æ—Ä —Ä–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω–æ—Å—Ç–∏"""

        if not reflections:
            return 0.0

        # –ë–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä –∑–∞ –Ω–∞–ª–∏—á–∏–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏
        base_score = 0.5

        # –ë–æ–Ω—É—Å—ã –∑–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏
        quality_reflections = 0
        for reflection in reflections:
            if reflection.get("notes") and len(reflection["notes"]) > 20:
                quality_reflections += 1

        if quality_reflections >= len(reflections) * 0.7:
            base_score += 0.3

        if len(reflections) >= 3:
            base_score += 0.2

        return min(base_score, 1.0)

    def _get_quality_grade(self, quality_score: float) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –±—É–∫–≤–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞"""

        if quality_score >= 0.9:
            return "A+"
        elif quality_score >= 0.8:
            return "A"
        elif quality_score >= 0.7:
            return "B+"
        elif quality_score >= 0.6:
            return "B"
        elif quality_score >= 0.5:
            return "C+"
        elif quality_score >= 0.4:
            return "C"
        else:
            return "D"

    def _generate_quality_notes(
        self, quality_score: float, completeness_score: float, depth_score: float
    ) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∑–∞–º–µ—Ç–∫–∏ –æ –∫–∞—á–µ—Å—Ç–≤–µ"""

        notes = []

        if quality_score >= 0.8:
            notes.append("–û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞")
        elif quality_score >= 0.6:
            notes.append("–•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞")
        else:
            notes.append("–¢—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞")

        if completeness_score >= 0.8:
            notes.append("–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–æ–ª–Ω–æ")
        elif completeness_score >= 0.6:
            notes.append("–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ–ª–Ω–æ")
        else:
            notes.append("–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è")

        if depth_score >= 0.7:
            notes.append("–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–≤–µ–¥–µ–Ω")
        else:
            notes.append("–¢—Ä–µ–±—É–µ—Ç—Å—è —É–≥–ª—É–±–ª–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞")

        return notes

    async def _check_standard_compliance(
        self, analysis_data: dict[str, Any], review_standard: str
    ) -> dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É"""

        logger.info(f"üìã Checking compliance with {review_standard}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞
        standard_requirements = await self._load_standard_requirements(review_standard)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–∂–¥–æ–º—É —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é
        compliance_results = {}
        total_requirements = len(standard_requirements)
        met_requirements = 0

        for requirement, criteria in standard_requirements.items():
            is_met = await self._check_requirement_compliance(
                analysis_data, requirement, criteria
            )
            compliance_results[requirement] = is_met
            if is_met:
                met_requirements += 1

        compliance_score = (
            met_requirements / total_requirements if total_requirements > 0 else 0.0
        )

        return {
            "compliance_score": compliance_score,
            "total_requirements": total_requirements,
            "met_requirements": met_requirements,
            "compliance_results": compliance_results,
            "compliance_grade": self._get_quality_grade(compliance_score),
            "compliance_notes": self._generate_compliance_notes(
                compliance_score, compliance_results
            ),
        }

    async def _load_standard_requirements(self, review_standard: str) -> dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞"""

        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        if "Ilya Krasinsky Review Standard v1.2" in review_standard:
            return {
                "mandatory_stages": {
                    "description": "–í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —ç—Ç–∞–ø—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω—ã",
                    "criteria": ["preprocessing", "inventory", "evaluation", "output"],
                },
                "reflection_checkpoints": {
                    "description": "Reflection checkpoints –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω—ã",
                    "criteria": ["checkpoint_after_each_stage"],
                },
                "quality_metrics": {
                    "description": "–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã",
                    "criteria": ["completeness", "depth", "structure"],
                },
                "documentation_standards": {
                    "description": "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º",
                    "criteria": [
                        "markdown_format",
                        "structured_content",
                        "clear_recommendations",
                    ],
                },
            }

        return {}

    async def _check_requirement_compliance(
        self, analysis_data: dict[str, Any], requirement: str, criteria: dict[str, Any]
    ) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é"""

        if requirement == "mandatory_stages":
            stages = analysis_data.get("stages", {})
            required_stages = criteria.get("criteria", [])
            return all(stage in stages for stage in required_stages)

        elif requirement == "reflection_checkpoints":
            reflections = analysis_data.get("reflections", [])
            return len(reflections) > 0

        elif requirement == "quality_metrics":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            return (
                "quality_score" in analysis_data
                or "completeness_score" in analysis_data
            )

        elif requirement == "documentation_standards":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
            return bool(analysis_data.get("stages") and analysis_data.get("offers"))

        return False

    def _generate_compliance_notes(
        self, compliance_score: float, compliance_results: dict[str, bool]
    ) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∑–∞–º–µ—Ç–∫–∏ –æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É"""

        notes = []

        if compliance_score >= 0.9:
            notes.append("–ü–æ–ª–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É")
        elif compliance_score >= 0.7:
            notes.append("–•–æ—Ä–æ—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É")
        else:
            notes.append("–¢—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É")

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è
        for requirement, is_met in compliance_results.items():
            if not is_met:
                notes.append(f"–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ '{requirement}' –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")

        return notes

    async def _perform_expert_validation(
        self, analysis_data: dict[str, Any]
    ) -> dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é"""

        logger.info("üë®‚Äçüíº Performing expert validation")

        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–∞
        expert_insights = await self._generate_expert_insights(analysis_data)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤
        professional_standards = await self._check_professional_standards(analysis_data)

        # –û—Ü–µ–Ω–∫–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏
        practical_applicability = await self._assess_practical_applicability(
            analysis_data
        )

        # –û–±—â–∞—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        expert_score = (
            expert_insights["score"]
            + professional_standards["score"]
            + practical_applicability["score"]
        ) / 3

        return {
            "expert_score": expert_score,
            "expert_insights": expert_insights,
            "professional_standards": professional_standards,
            "practical_applicability": practical_applicability,
            "expert_grade": self._get_quality_grade(expert_score),
            "expert_recommendations": await self._generate_expert_recommendations(
                analysis_data
            ),
        }

    async def _generate_expert_insights(
        self, analysis_data: dict[str, Any]
    ) -> dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã"""

        insights = []
        score = 0.0

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        offers = analysis_data.get("offers", [])
        if offers:
            high_priority_offers = [
                offer for offer in offers if offer.get("priority") == "high"
            ]
            if len(high_priority_offers) >= 2:
                insights.append("–•–æ—Ä–æ—à–∞—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
                score += 0.3
            else:
                insights.append("–¢—Ä–µ–±—É–µ—Ç—Å—è –ª—É—á—à–∞—è –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        segments = analysis_data.get("segments", [])
        if len(segments) >= 2:
            insights.append("–ê–¥–µ–∫–≤–∞—Ç–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏")
            score += 0.3
        else:
            insights.append("–¢—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ—Ñ–ª–µ–∫—Å–∏—é
        reflections = analysis_data.get("reflections", [])
        if len(reflections) >= 3:
            insights.append("–•–æ—Ä–æ—à–∞—è —Ä–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞")
            score += 0.2
        else:
            insights.append("–¢—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª—å—à–µ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        stages = analysis_data.get("stages", {})
        if len(stages) >= 4:
            insights.append("–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ –∞–Ω–∞–ª–∏–∑—É")
            score += 0.2
        else:
            insights.append("–¢—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª–µ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥")

        return {
            "score": min(score, 1.0),
            "insights": insights,
            "insights_count": len(insights),
        }

    async def _check_professional_standards(
        self, analysis_data: dict[str, Any]
    ) -> dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã"""

        standards_met = 0
        total_standards = 4

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç 1: –ü–æ–ª–Ω–æ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
        if analysis_data.get("stages") and analysis_data.get("offers"):
            standards_met += 1

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç 2: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
        if analysis_data.get("landing_url") and analysis_data.get("business_context"):
            standards_met += 1

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç 3: –†–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω–æ—Å—Ç—å
        if analysis_data.get("reflections"):
            standards_met += 1

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç 4: –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å
        if analysis_data.get("recommendations") or analysis_data.get("offers"):
            standards_met += 1

        score = standards_met / total_standards

        return {
            "score": score,
            "standards_met": standards_met,
            "total_standards": total_standards,
            "standards_details": [
                "–ü–æ–ª–Ω–æ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞",
                "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å",
                "–†–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω–æ—Å—Ç—å",
                "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å",
            ],
        }

    async def _assess_practical_applicability(
        self, analysis_data: dict[str, Any]
    ) -> dict[str, Any]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å"""

        applicability_score = 0.0
        factors = []

        # –§–∞–∫—Ç–æ—Ä 1: –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        offers = analysis_data.get("offers", [])
        if offers:
            applicability_score += 0.4
            factors.append("–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω—ã")
        else:
            factors.append("–¢—Ä–µ–±—É—é—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")

        # –§–∞–∫—Ç–æ—Ä 2: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–∏–Ω–≥–∞
        segments = analysis_data.get("segments", [])
        if len(segments) >= 2:
            applicability_score += 0.3
            factors.append("–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ç–∞—Ä–≥–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏—Ç–æ—Ä–∏—é")
        else:
            factors.append("–¢—Ä–µ–±—É–µ—Ç—Å—è –ª—É—á—à–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —Ç–∞—Ä–≥–µ—Ç–∏–Ω–≥–∞")

        # –§–∞–∫—Ç–æ—Ä 3: –ò–∑–º–µ—Ä–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if analysis_data.get("quality_score") or analysis_data.get("metrics"):
            applicability_score += 0.3
            factors.append("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–º–µ—Ä–∏–º—ã")
        else:
            factors.append("–¢—Ä–µ–±—É—é—Ç—Å—è –∏–∑–º–µ—Ä–∏–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏")

        return {
            "score": applicability_score,
            "factors": factors,
            "applicability_level": "high"
            if applicability_score >= 0.7
            else "medium"
            if applicability_score >= 0.4
            else "low",
        }

    async def _generate_expert_recommendations(
        self, analysis_data: dict[str, Any]
    ) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""

        recommendations = []

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
        offers = analysis_data.get("offers", [])
        if len(offers) < 3:
            recommendations.append("–î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

        segments = analysis_data.get("segments", [])
        if len(segments) < 2:
            recommendations.append("–ü—Ä–æ–≤–µ—Å—Ç–∏ –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∞—É–¥–∏—Ç–æ—Ä–∏–∏")

        reflections = analysis_data.get("reflections", [])
        if len(reflections) < 3:
            recommendations.append("–£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ reflection checkpoints")

        # –û–±—â–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations.extend(
            [
                "–ü—Ä–æ–≤–µ—Å—Ç–∏ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π",
                "–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∫–æ–Ω–≤–µ—Ä—Å–∏—é –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º",
                "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ 30 –¥–Ω–µ–π –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π",
                "–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑ —Å —Å–∏—Å—Ç–µ–º–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏",
            ]
        )

        return recommendations

    async def _generate_expert_recommendations(
        self,
        analysis_data: dict[str, Any],
        quality_assessment: dict[str, Any],
        compliance_check: dict[str, Any],
        expert_validation: dict[str, Any],
    ) -> list[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""

        recommendations = []

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞
        if quality_assessment["overall_quality_score"] < 0.7:
            recommendations.append("–£–ª—É—á—à–∏—Ç—å –æ–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É
        if compliance_check["compliance_score"] < 0.8:
            recommendations.append("–ü—Ä–∏–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–º")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        if expert_validation["expert_score"] < 0.7:
            recommendations.append("–£–ª—É—á—à–∏—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –∞–Ω–∞–ª–∏–∑–∞")

        # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations.extend(
            await self._generate_expert_recommendations(analysis_data)
        )

        return recommendations

    async def _calculate_overall_score(
        self,
        quality_assessment: dict[str, Any],
        compliance_check: dict[str, Any],
        expert_validation: dict[str, Any],
    ) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–∏–π —Å–∫–æ—Ä —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏"""

        quality_score = quality_assessment["overall_quality_score"]
        compliance_score = compliance_check["compliance_score"]
        expert_score = expert_validation["expert_score"]

        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
        overall_score = (
            quality_score * 0.4 + compliance_score * 0.3 + expert_score * 0.3
        )

        return round(overall_score, 2)


# MCP Command Interface Functions
async def execute_expert_review_mcp(
    analysis_data: dict[str, Any],
    review_standard: str = "Ilya Krasinsky Review Standard v1.2",
) -> dict[str, Any]:
    """MCP Command Interface –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏

    Args:
        analysis_data: –î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–Ω–¥–∏–Ω–≥–∞
        review_standard: –°—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
    """
    try:
        expert_review = ExpertReview()
        result = await expert_review.execute_expert_review(
            analysis_data, review_standard
        )
        return result

    except Exception as e:
        logger.error(f"Error in execute_expert_review_mcp: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": datetime.now().isoformat(),
        }


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""

    async def test_expert_review():
        test_analysis_data = {
            "landing_url": "https://test.com",
            "business_context": {"type": "saas", "target_audience": "b2b"},
            "stages": {
                "preprocessing": {"completed": True},
                "inventory": {"completed": True},
                "evaluation": {"completed": True},
                "output": {"completed": True},
            },
            "offers": [
                {"type": "free_trial", "priority": "high"},
                {"type": "demo", "priority": "medium"},
            ],
            "segments": ["startups", "enterprise"],
            "reflections": [
                {"checkpoint": "stage_1", "status": "completed"},
                {"checkpoint": "stage_2", "status": "completed"},
            ],
        }

        result = await execute_expert_review_mcp(test_analysis_data)

        print(f"Expert review result: {result['success']}")
        if result["success"]:
            print(f"Overall score: {result['overall_score']}")
            print(f"Quality grade: {result['quality_assessment']['quality_grade']}")
            print(f"Compliance grade: {result['compliance_check']['compliance_grade']}")

    asyncio.run(test_expert_review())


if __name__ == "__main__":
    main()
