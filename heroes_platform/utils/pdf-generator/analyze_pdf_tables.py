#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü –≤ PDF —Ñ–∞–π–ª–∞—Ö
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü –≤ —Ä–∞–∑–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞—Ö
"""

import PyPDF2
import re
from pathlib import Path

def extract_text_from_pdf(pdf_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF"""
    try:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ''
            for page in reader.pages:
                text += page.extract_text() + '\n'
            return text
    except Exception as e:
        return f'–û—à–∏–±–∫–∞: {e}'

def analyze_tables_in_text(text):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –≤ —Ç–µ–∫—Å—Ç–µ"""
    
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∞–±–ª–∏—Ü
    table_patterns = [
        r'‚Ññ.*AppMetrica.*Adjust',  # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        r'\|.*\|.*\|',  # –°—Ç—Ä–æ–∫–∏ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
        r'-------',  # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
        r'1\s+received adjust attribution',  # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        r'2\s+system adjust_id',  # –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    ]
    
    found_tables = []
    
    for pattern in table_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
        if matches:
            found_tables.extend(matches)
    
    # –ò—â–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    structured_data = []
    
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–º–µ—Ä–∞–º–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
    lines = text.split('\n')
    for line in lines:
        if re.match(r'^\d+\.?\s+', line.strip()):
            structured_data.append(line.strip())
    
    return {
        'table_patterns_found': len(found_tables),
        'structured_data_lines': len(structured_data),
        'sample_structured_data': structured_data[:5],
        'table_patterns': found_tables[:3]
    }

def compare_pdf_tables():
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ç–∞–±–ª–∏—Ü –≤ —Ä–∞–∑–Ω—ã—Ö PDF"""
    
    print("üîç –ê–ù–ê–õ–ò–ó –¢–ê–ë–õ–ò–¶ –í PDF –§–ê–ô–õ–ê–•")
    print("=" * 60)
    
    pdf_files = [
        'vipavenue-adjust-appmetrica_MODERN.pdf',
        'vipavenue-adjust-appmetrica_NODEJS.pdf',
        'vipavenue-adjust-appmetrica_NODEJS_ADVANCED.pdf'
    ]
    
    results = {}
    
    for pdf_file in pdf_files:
        if not Path(pdf_file).exists():
            print(f"‚ùå –§–∞–π–ª {pdf_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            continue
            
        print(f"\nüìÑ –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü –≤: {pdf_file}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        text = extract_text_from_pdf(pdf_file)
        
        if text.startswith('–û—à–∏–±–∫–∞:'):
            print(f"   ‚ùå {text}")
            continue
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—ã
        table_analysis = analyze_tables_in_text(text)
        
        print(f"   üìä –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ç–∞–±–ª–∏—Ü: {table_analysis['table_patterns_found']}")
        print(f"   üìã –°—Ç—Ä–æ–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {table_analysis['structured_data_lines']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
        if table_analysis['sample_structured_data']:
            print(f"   üìù –ü—Ä–∏–º–µ—Ä—ã —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
            for i, data in enumerate(table_analysis['sample_structured_data'][:3]):
                print(f"      {i+1}. {data[:80]}...")
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–∞–±–ª–∏—Ü
        quality_score = 0
        if table_analysis['table_patterns_found'] > 0:
            quality_score += 3
        if table_analysis['structured_data_lines'] > 10:
            quality_score += 4
        if table_analysis['structured_data_lines'] > 20:
            quality_score += 3
        
        quality_text = "‚ùå –ü–ª–æ—Ö–æ" if quality_score < 3 else "‚ö†Ô∏è –°—Ä–µ–¥–Ω–µ" if quality_score < 6 else "‚úÖ –•–æ—Ä–æ—à–æ" if quality_score < 8 else "üåü –û—Ç–ª–∏—á–Ω–æ"
        
        print(f"   üéØ –ö–∞—á–µ—Å—Ç–≤–æ —Ç–∞–±–ª–∏—Ü: {quality_text} ({quality_score}/10)")
        
        results[pdf_file] = {
            'text_length': len(text),
            'table_analysis': table_analysis,
            'quality_score': quality_score
        }
    
    return results

def analyze_details_blocks(text):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç details –±–ª–æ–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ"""
    
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã details –±–ª–æ–∫–æ–≤
    details_patterns = [
        r'QUICK START.*5 –º–∏–Ω—É—Ç',  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ details
        r'Flutter.*main\.dart',  # Flutter —Å–µ–∫—Ü–∏—è
        r'iOS.*AppDelegate\.swift',  # iOS —Å–µ–∫—Ü–∏—è
        r'Android.*MainActivity\.kt',  # Android —Å–µ–∫—Ü–∏—è
    ]
    
    found_details = []
    
    for pattern in details_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
        if matches:
            found_details.extend(matches)
    
    return {
        'details_patterns_found': len(found_details),
        'details_content': found_details[:3]
    }

def analyze_code_blocks(text):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–ª–æ–∫–∏ –∫–æ–¥–∞ –≤ —Ç–µ–∫—Å—Ç–µ"""
    
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–æ–¥–∞
    code_patterns = [
        r'```dart',  # Dart –∫–æ–¥
        r'```swift',  # Swift –∫–æ–¥
        r'```kotlin',  # Kotlin –∫–æ–¥
        r'```java',  # Java –∫–æ–¥
        r'```xml',  # XML –∫–æ–¥
    ]
    
    found_code = []
    
    for pattern in code_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)
        if matches:
            found_code.extend(matches)
    
    return {
        'code_blocks_found': len(found_code),
        'code_types': list(set(found_code))
    }

def comprehensive_analysis():
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∞—Å–ø–µ–∫—Ç–æ–≤"""
    
    print("\nüîç –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó PDF –ö–ê–ß–ï–°–¢–í–ê")
    print("=" * 60)
    
    pdf_files = [
        'vipavenue-adjust-appmetrica_MODERN.pdf',
        'vipavenue-adjust-appmetrica_NODEJS.pdf',
        'vipavenue-adjust-appmetrica_NODEJS_ADVANCED.pdf'
    ]
    
    comprehensive_results = {}
    
    for pdf_file in pdf_files:
        if not Path(pdf_file).exists():
            continue
            
        print(f"\nüìÑ –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {pdf_file}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        text = extract_text_from_pdf(pdf_file)
        
        if text.startswith('–û—à–∏–±–∫–∞:'):
            continue
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã
        table_analysis = analyze_tables_in_text(text)
        details_analysis = analyze_details_blocks(text)
        code_analysis = analyze_code_blocks(text)
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        total_score = 0
        
        # –û—Ü–µ–Ω–∫–∞ —Ç–∞–±–ª–∏—Ü (0-10)
        table_score = min(10, table_analysis['table_patterns_found'] * 2 + table_analysis['structured_data_lines'])
        total_score += table_score
        
        # –û—Ü–µ–Ω–∫–∞ details –±–ª–æ–∫–æ–≤ (0-5)
        details_score = min(5, details_analysis['details_patterns_found'] * 2)
        total_score += details_score
        
        # –û—Ü–µ–Ω–∫–∞ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞ (0-5)
        code_score = min(5, code_analysis['code_blocks_found'] * 2)
        total_score += code_score
        
        print(f"   üìä –¢–∞–±–ª–∏—Ü—ã: {table_score}/10")
        print(f"   üìã Details –±–ª–æ–∫–∏: {details_score}/5")
        print(f"   üíª –ë–ª–æ–∫–∏ –∫–æ–¥–∞: {code_score}/5")
        print(f"   üéØ –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {total_score}/20")
        
        comprehensive_results[pdf_file] = {
            'table_score': table_score,
            'details_score': details_score,
            'code_score': code_score,
            'total_score': total_score,
            'text_length': len(text)
        }
    
    return comprehensive_results

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üöÄ –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –¢–ê–ë–õ–ò–¶ –ò –°–¢–†–£–ö–¢–£–†–´ –í PDF")
    print("=" * 60)
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü
    table_results = compare_pdf_tables()
    
    # –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    comprehensive_results = comprehensive_analysis()
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print(f"\nüìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ü–û –ö–ê–ß–ï–°–¢–í–£")
    print("=" * 60)
    
    if comprehensive_results:
        best_file = max(comprehensive_results.items(), key=lambda x: x[1]['total_score'])
        print(f"üèÜ –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(f"   üìÑ –§–∞–π–ª: {best_file[0]}")
        print(f"   üéØ –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {best_file[1]['total_score']}/20")
        print(f"   üìä –¢–∞–±–ª–∏—Ü—ã: {best_file[1]['table_score']}/10")
        print(f"   üìã Details: {best_file[1]['details_score']}/5")
        print(f"   üíª –ö–æ–¥: {best_file[1]['code_score']}/5")
    
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ PDF —Ñ–∞–π–ª—ã –≤—Ä—É—á–Ω—É—é –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏")
    print("   - –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Ç–∞–±–ª–∏—Ü –∏ details –±–ª–æ–∫–æ–≤")
    print("   - –°—Ä–∞–≤–Ω–∏—Ç–µ —á–∏—Ç–∞–µ–º–æ—Å—Ç—å –∫–æ–¥–∞ –≤ —Ä–∞–∑–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞—Ö")

if __name__ == "__main__":
    main()
